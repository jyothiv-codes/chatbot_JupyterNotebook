{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvpUcoWbjC9b",
        "outputId": "967d1d27-e339-43bd-f625-4412caafa58c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n"
          ]
        }
      ],
      "source": [
        "print(\"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMSAh6Rs8ly-"
      },
      "source": [
        "# **Run prior to starting the server and chatbot**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Cuf_GVLt5368",
        "outputId": "a01242c0-62e2-4c3b-becb-7dbfcfbc0eb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-llms-openai\n",
            "  Downloading llama_index_llms_openai-0.1.29-py3-none-any.whl.metadata (650 bytes)\n",
            "Collecting llama-index-core<0.11.0,>=0.10.57 (from llama-index-llms-openai)\n",
            "  Downloading llama_index_core-0.10.65-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting openai<2.0.0,>=1.40.0 (from llama-index-llms-openai)\n",
            "  Downloading openai-1.40.6-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (3.10.2)\n",
            "Collecting dataclasses-json (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (2024.6.1)\n",
            "Collecting httpx (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (3.3)\n",
            "Collecting nltk>=3.8.2 (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai)\n",
            "  Downloading nltk-3.8.2-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (2.1.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.2.0 (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (4.12.2)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (1.16.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.7.0)\n",
            "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.40.0->llama-index-llms-openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (4.0.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (2024.5.15)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (2024.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (24.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (1.16.0)\n",
            "Downloading llama_index_llms_openai-0.1.29-py3-none-any.whl (11 kB)\n",
            "Downloading llama_index_core-0.10.65-py3-none-any.whl (15.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.40.6-py3-none-any.whl (361 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m361.3/361.3 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nltk-3.8.2-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dirtyjson, tenacity, nltk, mypy-extensions, marshmallow, jiter, h11, deprecated, typing-inspect, tiktoken, httpcore, httpx, dataclasses-json, openai, llama-index-core, llama-index-llms-openai\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.8.1\n",
            "    Uninstalling nltk-3.8.1:\n",
            "      Successfully uninstalled nltk-3.8.1\n",
            "Successfully installed dataclasses-json-0.6.7 deprecated-1.2.14 dirtyjson-1.0.8 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jiter-0.5.0 llama-index-core-0.10.65 llama-index-llms-openai-0.1.29 marshmallow-3.21.3 mypy-extensions-1.0.0 nltk-3.8.2 openai-1.40.6 tenacity-8.5.0 tiktoken-0.7.0 typing-inspect-0.9.0\n",
            "Collecting llama-index-readers-file\n",
            "  Downloading llama_index_readers_file-0.1.33-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file) (4.12.3)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.37.post1 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file) (0.10.65)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file)\n",
            "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file) (2.5)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (3.10.2)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2024.6.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (0.27.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (3.3)\n",
            "Requirement already satisfied: nltk>=3.8.2 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (3.8.2)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.26.4)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.40.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2.1.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (4.0.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2024.5.15)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.7.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (0.5.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (3.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (3.21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.2.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (24.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.16.0)\n",
            "Downloading llama_index_readers_file-0.1.33-py3-none-any.whl (38 kB)\n",
            "Downloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Installing collected packages: striprtf, pypdf, llama-index-readers-file\n",
            "Successfully installed llama-index-readers-file-0.1.33 pypdf-4.3.1 striprtf-0.0.26\n",
            "Collecting llama-index-embeddings-openai\n",
            "  Downloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl.metadata (655 bytes)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-openai) (0.10.65)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.10.2)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2024.6.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.27.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.3)\n",
            "Requirement already satisfied: nltk>=3.8.2 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.8.2)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.26.4)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.40.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.1.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (4.0.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2024.5.15)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.7.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.5.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.2.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (24.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.16.0)\n",
            "Downloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl (6.3 kB)\n",
            "Installing collected packages: llama-index-embeddings-openai\n",
            "Successfully installed llama-index-embeddings-openai-0.1.11\n"
          ]
        }
      ],
      "source": [
        "#Installations for constructing knowledge graph\n",
        "!pip install llama-index-llms-openai\n",
        "!pip install llama-index-readers-file\n",
        "!pip install llama-index-embeddings-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "W3hBnhIUAlVE",
        "outputId": "b161da92-0443-4c2e-b915-e9e4ec69971a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastapi\n",
            "  Downloading fastapi-0.112.0-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.20.1)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.38.0,>=0.37.2->fastapi) (3.7.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi) (1.2.2)\n",
            "Downloading fastapi-0.112.0-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.0-py3-none-any.whl (22 kB)\n",
            "Downloading uvicorn-0.30.6-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvicorn, pyngrok, starlette, fastapi\n",
            "Successfully installed fastapi-0.112.0 pyngrok-7.2.0 starlette-0.37.2 uvicorn-0.30.6\n",
            "add-authtoken - save authtoken to configuration file\n",
            "\n",
            "USAGE:\n",
            "  ngrok config add-authtoken TOKEN [flags]\n",
            "\n",
            "AUTHOR:\n",
            "  ngrok - <support@ngrok.com>\n",
            "\n",
            "COMMANDS: \n",
            "  config          update or migrate ngrok's configuration file\n",
            "  http            start an HTTP tunnel\n",
            "  tcp             start a TCP tunnel\n",
            "  tunnel          start a tunnel for use with a tunnel-group backend\n",
            "\n",
            "EXAMPLES: \n",
            "  ngrok http 80                                                 # secure public URL for port 80 web server\n",
            "  ngrok http --domain baz.ngrok.dev 8080                        # port 8080 available at baz.ngrok.dev\n",
            "  ngrok tcp 22                                                  # tunnel arbitrary TCP traffic to port 22\n",
            "  ngrok http 80 --oauth=google --oauth-allow-email=foo@foo.com  # secure your app with oauth\n",
            "\n",
            "Paid Features: \n",
            "  ngrok http 80 --domain mydomain.com                           # run ngrok with your own custom domain\n",
            "  ngrok http 80 --allow-cidr 2600:8c00::a03c:91ee:fe69:9695/32  # run ngrok with IP policy restrictions\n",
            "  Upgrade your account at https://dashboard.ngrok.com/billing/subscription to access paid features\n",
            "\n",
            "Upgrade your account at https://dashboard.ngrok.com/billing/subscription to access paid features\n",
            "\n",
            "Flags:\n",
            "  -h, --help      help for ngrok\n",
            "\n",
            "Use \"ngrok [command] --help\" for more information about a command.\n",
            "\n",
            "ERROR:  accepts 1 arg(s), received 0\n"
          ]
        }
      ],
      "source": [
        "#installations for Fast API\n",
        "!pip install fastapi nest-asyncio pyngrok uvicorn\n",
        "!ngrok config add-authtoken $NGROK_AUTHTOKEN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DKcxiaT24gsj"
      },
      "outputs": [],
      "source": [
        "# Needed for information extraction\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import networkx as nx\n",
        "import spacy\n",
        "from prettytable import PrettyTable\n",
        "import textwrap\n",
        "from google.colab import userdata\n",
        "\n",
        "# For Google custom search engine\n",
        "api_key = userdata.get('api_key')\n",
        "cse_id = userdata.get('cse_id')\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYjsMore5BgP",
        "outputId": "31a4e6ef-c0cd-4ae6-f623-7f8244238379"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# To store the extracted info in GDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NN-WZav06LZz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('openai_api-key')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "M8Gn1l4r6UcY"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import sys\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "b_vRwVgJ6Wh8"
      },
      "outputs": [],
      "source": [
        "# For constructing knowledge graph and displaying results\n",
        "from llama_index.core import SimpleDirectoryReader, KnowledgeGraphIndex\n",
        "from llama_index.core.graph_stores import SimpleGraphStore\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.core import Settings\n",
        "from IPython.display import Markdown, display\n",
        "from llama_index.core import StorageContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ep39Fn5g8_5q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Define the path to the specific folder in Google Drive\n",
        "folder_path = '/content/drive/My Drive/KG'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not os.path.exists(folder_path):\n",
        "    os.makedirs(folder_path)\n",
        "\n",
        "# Define the path for the file\n",
        "file_path = os.path.join(folder_path, 'results.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eywQpwVF9OBW"
      },
      "outputs": [],
      "source": [
        "# Default value\n",
        "curr_query = 'use cases of transformers in machine learning'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PHCnNFjpzVSX"
      },
      "outputs": [],
      "source": [
        "os.environ['NGROK_AUTHTOKEN'] = userdata.get('ngrok_auth_token')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRvPMMvI80VN"
      },
      "source": [
        "# **Chatbot calls these functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "laxfanKR3Es3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "a7fb74fb-76ee-42d4-c694-9bf9b475e305"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'def google_search(query, api_key, cse_id, num_results=5):\\n    search_url = f\"https://www.googleapis.com/customsearch/v1?q={query}&key={api_key}&cx={cse_id}&num={num_results}\"\\n    response = requests.get(search_url)\\n    results = response.json().get(\\'items\\', [])\\n    return [item[\\'link\\'] for item in results]\\n\\ndef extract_relevant_info(url):\\n    try:\\n        response = requests.get(url)\\n        response.raise_for_status()\\n        soup = BeautifulSoup(response.content, \\'html.parser\\')\\n        title = soup.find(\\'title\\').get_text()\\n        paragraphs = soup.find_all(\\'p\\')\\n        text = \"\\n\".join([p.get_text() for p in paragraphs])\\n        return {\"title\": title, \"text\": text}\\n    except requests.exceptions.RequestException as e:\\n        return {\"error\": str(e)}\\n\\n# Function to wrap text for table display\\ndef wrap_text(text, width):\\n    return \"\\n\".join(textwrap.wrap(text, width=width))\\n\\n# Function to format and print the output using PrettyTable\\ndef print_formatted_output(results):\\n    table = PrettyTable()\\n    table.field_names = [\"Title\", \"URL\", \"Text\"]\\n\\n    for result in results:\\n        wrapped_title = wrap_text(result[\\'title\\'], width=30)\\n        wrapped_url = wrap_text(result[\\'url\\'], width=30)\\n        wrapped_text = wrap_text(result[\\'text\\'], width=50)\\n        table.add_row([wrapped_title, wrapped_url, wrapped_text])\\n\\n    print(table)\\n\\n\\n\\ndef user_input_kg(query):\\n  if len(query)>0:\\n    curr_query = query\\n  else:\\n    curr_query = \\'use cases of transformers in machine learning\\'\\n  query = curr_query\\n  urls = google_search(query, api_key, cse_id)\\n  all_entities = set()\\n  all_relationships = []\\n  results = []\\n\\n  for url in urls:\\n      info = extract_relevant_info(url)\\n      if \"error\" not in info:\\n          info[\\'url\\'] = url\\n          results.append(info)\\n  print_formatted_output(results)\\n  return results\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# Extract information using the Google API key and Custom search engine id\n",
        "\"\"\"def google_search(query, api_key, cse_id, num_results=5):\n",
        "    search_url = f\"https://www.googleapis.com/customsearch/v1?q={query}&key={api_key}&cx={cse_id}&num={num_results}\"\n",
        "    response = requests.get(search_url)\n",
        "    results = response.json().get('items', [])\n",
        "    return [item['link'] for item in results]\n",
        "\n",
        "def extract_relevant_info(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        title = soup.find('title').get_text()\n",
        "        paragraphs = soup.find_all('p')\n",
        "        text = \"\\n\".join([p.get_text() for p in paragraphs])\n",
        "        return {\"title\": title, \"text\": text}\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "# Function to wrap text for table display\n",
        "def wrap_text(text, width):\n",
        "    return \"\\n\".join(textwrap.wrap(text, width=width))\n",
        "\n",
        "# Function to format and print the output using PrettyTable\n",
        "def print_formatted_output(results):\n",
        "    table = PrettyTable()\n",
        "    table.field_names = [\"Title\", \"URL\", \"Text\"]\n",
        "\n",
        "    for result in results:\n",
        "        wrapped_title = wrap_text(result['title'], width=30)\n",
        "        wrapped_url = wrap_text(result['url'], width=30)\n",
        "        wrapped_text = wrap_text(result['text'], width=50)\n",
        "        table.add_row([wrapped_title, wrapped_url, wrapped_text])\n",
        "\n",
        "    print(table)\n",
        "\n",
        "\n",
        "\n",
        "def user_input_kg(query):\n",
        "  if len(query)>0:\n",
        "    curr_query = query\n",
        "  else:\n",
        "    curr_query = 'use cases of transformers in machine learning'\n",
        "  query = curr_query\n",
        "  urls = google_search(query, api_key, cse_id)\n",
        "  all_entities = set()\n",
        "  all_relationships = []\n",
        "  results = []\n",
        "\n",
        "  for url in urls:\n",
        "      info = extract_relevant_info(url)\n",
        "      if \"error\" not in info:\n",
        "          info['url'] = url\n",
        "          results.append(info)\n",
        "  print_formatted_output(results)\n",
        "  return results\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For handling missing text\n",
        "# Extract information using the Google API key and Custom search engine id\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import spacy\n",
        "import textwrap\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "# Load the spaCy language model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "def google_search(query, api_key, cse_id, num_results=5):\n",
        "    search_url = f\"https://www.googleapis.com/customsearch/v1?q={query}&key={api_key}&cx={cse_id}&num={num_results}\"\n",
        "    response = requests.get(search_url)\n",
        "    results = response.json().get('items', [])\n",
        "    print(\"Google search completed\")\n",
        "    return [item['link'] for item in results]\n",
        "\n",
        "def extract_relevant_info(url):\n",
        "    try:\n",
        "        # Set a timeout for the request\n",
        "        response = requests.get(url, timeout=10)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        title_tag = soup.find('title')\n",
        "        if not title_tag:\n",
        "            print(f\"Skipping {url}: No title tag found.\")\n",
        "            return {\"error\": \"No title tag found\"}\n",
        "\n",
        "        title = title_tag.get_text()\n",
        "        paragraphs = soup.find_all('p')\n",
        "        text = \"\\n\".join([p.get_text() for p in paragraphs])\n",
        "\n",
        "        return {\"title\": title, \"text\": text}\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Skipping {url}: {str(e)}\")\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "# Function to wrap text for table display\n",
        "def wrap_text(text, width):\n",
        "    return \"\\n\".join(textwrap.wrap(text, width=width))\n",
        "\n",
        "# Function to format and print the output using PrettyTable\n",
        "def print_formatted_output(results):\n",
        "    table = PrettyTable()\n",
        "    table.field_names = [\"Title\", \"Text\"]\n",
        "\n",
        "    for result in results:\n",
        "        wrapped_title = wrap_text(result['title'], width=30)\n",
        "        wrapped_text = wrap_text(result['text'], width=50)\n",
        "        table.add_row([wrapped_title, wrapped_text])\n",
        "\n",
        "    print(table)\n",
        "\n",
        "# Function to save the extracted text and title to a file\n",
        "def save_to_file(results, filename=\"output.txt\"):\n",
        "    with open(filename, \"w\") as file:\n",
        "        for result in results:\n",
        "            file.write(result['title'] + \"\\n\\n\")\n",
        "            file.write(result['text'] + \"\\n\")\n",
        "            file.write(\"\\n\" + \"=\"*50 + \"\\n\\n\")  # Separator between entries\n",
        "\n",
        "def user_input_kg(query):\n",
        "    if len(query) > 0:\n",
        "        curr_query = query\n",
        "    else:\n",
        "        curr_query = 'use cases of transformers in machine learning'\n",
        "    query = curr_query\n",
        "    urls = google_search(query, api_key, cse_id)\n",
        "    all_entities = set()\n",
        "    all_relationships = []\n",
        "    results = []\n",
        "\n",
        "    for url in urls:\n",
        "        print(\"Currently processing\", url)\n",
        "        info = extract_relevant_info(url)\n",
        "        if \"error\" not in info:\n",
        "            results.append(info)\n",
        "\n",
        "    print_formatted_output(results)\n",
        "    return results\n",
        "\n",
        "\n",
        "user_input_kg(\"Altera infuses AI\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEF3AvnwOSMY",
        "outputId": "edbe4544-0505-4ea7-db11-e7bb53c0ce53"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google search completed\n",
            "Currently processing https://www.allaboutcircuits.com/news/altera-infuses-ai-into-new-mid-range-fpgas/\n",
            "Skipping https://www.allaboutcircuits.com/news/altera-infuses-ai-into-new-mid-range-fpgas/: 403 Client Error: Forbidden for url: https://www.allaboutcircuits.com/news/altera-infuses-ai-into-new-mid-range-fpgas/\n",
            "Currently processing https://www.intel.com/content/www/us/en/newsroom/news/intel-altera-bring-ai-to-embedded-world.html\n",
            "Currently processing https://www.eetimes.com/embedded-world-2024-sandra-rivera-talks-about-altera-and-ai/\n",
            "Skipping https://www.eetimes.com/embedded-world-2024-sandra-rivera-talks-about-altera-and-ai/: HTTPSConnectionPool(host='www.eetimes.com', port=443): Read timed out. (read timeout=10)\n",
            "Currently processing https://www.linkedin.com/posts/sandra-rivera-6a24291_women4ew-womenintech-wearealtera-activity-7183884756843999232-ZNMo\n",
            "Currently processing https://cfotech.in/story/intel-launches-standalone-fpga-company-to-revolutionise-ai\n",
            "Skipping https://cfotech.in/story/intel-launches-standalone-fpga-company-to-revolutionise-ai: 403 Client Error: Forbidden for url: https://cfotech.in/story/intel-launches-standalone-fpga-company-to-revolutionise-ai\n",
            "+--------------------------------+----------------------------------------------------+\n",
            "|             Title              |                        Text                        |\n",
            "+--------------------------------+----------------------------------------------------+\n",
            "| Intel and Altera Announce Edge | You can easily search the entire Intel.com site in |\n",
            "|  and FPGA Offerings for AI at  |   several ways. You can also try the quick links   |\n",
            "|          Embedded...           |  below to see results for most popular searches.   |\n",
            "|                                |      The browser version you are using is not      |\n",
            "|                                |     recommended for this site.Please consider      |\n",
            "|                                | upgrading to the latest version of your browser by |\n",
            "|                                |   clicking one of the following links. New edge-   |\n",
            "|                                | optimized processors and FPGAs bring AI everywhere |\n",
            "|                                |  across edge computing markets including retail,   |\n",
            "|                                | industrial and healthcare.  April 8, 2024 Contact  |\n",
            "|                                |     Intel PR  Follow Intel Newsroom on social:     |\n",
            "|                                | By  What’s New: Today at Embedded World, Intel and |\n",
            "|                                |   Altera, an Intel Company, announced new edge-    |\n",
            "|                                |    optimized processors, FPGAs and programmable    |\n",
            "|                                |    market-ready solutions extending powerful AI    |\n",
            "|                                |  capabilities into edge computing. These products  |\n",
            "|                                |  will power AI-enabled edge devices applicable to  |\n",
            "|                                | industries across retail, healthcare, industrial,  |\n",
            "|                                |     automotive, defense and aerospace.  What’s     |\n",
            "|                                | New: Today at Embedded World, Intel and Altera, an |\n",
            "|                                |    Intel Company, announced new edge-optimized     |\n",
            "|                                |  processors, FPGAs and programmable market-ready   |\n",
            "|                                | solutions extending powerful AI capabilities into  |\n",
            "|                                |   edge computing. These products will power AI-    |\n",
            "|                                |   enabled edge devices applicable to industries    |\n",
            "|                                | across retail, healthcare, industrial, automotive, |\n",
            "|                                |  defense and aerospace. “This next generation of   |\n",
            "|                                | Intel edge-optimized processors and discrete GPUs  |\n",
            "|                                |     unleashes powerful AI capabilities to help     |\n",
            "|                                |     businesses more seamlessly incorporate AI      |\n",
            "|                                |  alongside compute, media and graphics workloads.  |\n",
            "|                                |     From manufacturing to healthcare, Intel’s      |\n",
            "|                                | extensive edge AI experience and breadth and depth |\n",
            "|                                |    of edge-ready silicon and software help our     |\n",
            "|                                |  customers deliver AI where they need it most for  |\n",
            "|                                |   better business outcomes.”  Why It Matters for   |\n",
            "|                                |    Edge and AI: Why It Matters for Edge and AI:    |\n",
            "|                                |    Intel’s new series of edge-optimized Intel®     |\n",
            "|                                |     Core™ Ultra, Intel® Core™ and Intel Atom®      |\n",
            "|                                |    processors and discrete Intel® Arc™ graphics    |\n",
            "|                                |  processing units (GPUs) will advance innovation   |\n",
            "|                                | for artificial intelligence, visual computing and  |\n",
            "|                                |    media processing – in support of faster and     |\n",
            "|                                | smarter decisions with on-premise edge computing.  |\n",
            "|                                |  Agilex™ 5 FPGAs for mid-range applications with   |\n",
            "|                                | best-in-class performance per watt target a broad  |\n",
            "|                                | set of applications, including video, industrial,  |\n",
            "|                                | robotics, medical and others. Agilex 5 FPGAs with  |\n",
            "|                                |   AI infused into the fabric offer a high level    |\n",
            "|                                | of integration, low latency and improved computing |\n",
            "|                                |  capabilities for intelligent edge applications.   |\n",
            "|                                |   Expanding on Intel’s commitment to bringing AI   |\n",
            "|                                | everywhere, today's announcements utilize built-in |\n",
            "|                                | AI acceleration in the new series of processors to |\n",
            "|                                | power the next generation of edge devices.  Why It |\n",
            "|                                |  Matters for Edge and AI: Why It Matters for Edge  |\n",
            "|                                |    and AI: Intel’s new series of edge-optimized    |\n",
            "|                                |  Intel® Core™ Ultra, Intel® Core™ and Intel Atom®  |\n",
            "|                                |    processors and discrete Intel® Arc™ graphics    |\n",
            "|                                |  processing units (GPUs) will advance innovation   |\n",
            "|                                | for artificial intelligence, visual computing and  |\n",
            "|                                |    media processing – in support of faster and     |\n",
            "|                                | smarter decisions with on-premise edge computing.  |\n",
            "|                                |  Agilex™ 5 FPGAs for mid-range applications with   |\n",
            "|                                | best-in-class performance per watt target a broad  |\n",
            "|                                | set of applications, including video, industrial,  |\n",
            "|                                | robotics, medical and others. Agilex 5 FPGAs with  |\n",
            "|                                |   AI infused into the fabric offer a high level    |\n",
            "|                                | of integration, low latency and improved computing |\n",
            "|                                |  capabilities for intelligent edge applications.   |\n",
            "|                                |   Expanding on Intel’s commitment to bringing AI   |\n",
            "|                                | everywhere, today's announcements utilize built-in |\n",
            "|                                | AI acceleration in the new series of processors to |\n",
            "|                                |   power the next generation of edge devices. An    |\n",
            "|                                | image shows the FPGAi Altera company logo. Altera  |\n",
            "|                                | helps customers achieve their business goals with  |\n",
            "|                                |  new AI capabilities to support high-performance   |\n",
            "|                                |   and mid-range FPGA-based solutions, developer    |\n",
            "|                                |  usability and workload agility. (Credit: Altera,  |\n",
            "|                                |   an Intel Company) An image shows an Intel Atom   |\n",
            "|                                |   processor badge. Intel Atom processors x7000C    |\n",
            "|                                | Series delivers ramped-up processor base frequency |\n",
            "|                                |     in up to eight Efficient-cores. Intel Atom     |\n",
            "|                                |  processors x7000RE Series features built-in deep  |\n",
            "|                                |  learning inference capabilities. (Credit: Intel   |\n",
            "|                                |  Corporation) An image shows an Intel Core Ultra   |\n",
            "|                                |    processor badge. Intel Core Ultra processors    |\n",
            "|                                | combine the Intel Arc GPU and a neural processing  |\n",
            "|                                |   unit (NPU) with LGA socket flexibility into a    |\n",
            "|                                |  simplified system-on-chip (SoC). The new SoC is   |\n",
            "|                                |    designed to enable generative AI (GenAI) and    |\n",
            "|                                | demanding graphics workloads at the edge. (Credit: |\n",
            "|                                |  Intel Corporation) An image shows the Intel Arc   |\n",
            "|                                |  GPU for Edge badge. The Intel® Arc™ GPU for Edge  |\n",
            "|                                |   boosts performance and edge AI capabilities on   |\n",
            "|                                |    legacy Intel Core systems as a discrete GPU,    |\n",
            "|                                |    providing accelerated AI, media and graphics    |\n",
            "|                                |  processing power. (Credit: Intel Corporation) An  |\n",
            "|                                |  image shows an Intel Core processor badge. Intel  |\n",
            "|                                | Core processors combine the GPU power of 13th Gen  |\n",
            "|                                |    Intel Core mobile processors with LGA socket    |\n",
            "|                                |  flexibility to prioritize system scalability and  |\n",
            "|                                |  speed to deployment. (Credit: Intel Corporation)  |\n",
            "|                                |   An image shows the Agilex 5 field programmable   |\n",
            "|                                |      gate array. Agilex 5 FPGAs for mid-range      |\n",
            "|                                |  applications with best-in-class performance per   |\n",
            "|                                | watt target a broad set of applications, including |\n",
            "|                                |  video, industrial, robotics, medical and others.  |\n",
            "|                                |  (Credit: Altera, an Intel Company) Download all   |\n",
            "|                                |  images (ZIP, 2 MB)  Download all images (ZIP, 2   |\n",
            "|                                | MB) How Intel Expands AI to Embedded Edge Devices: |\n",
            "|                                |  Building on its expansive installed base of more  |\n",
            "|                                |   than 90,000 edge deployments, Intel delivers a   |\n",
            "|                                |   wave of edge-optimized processors and GPUs to    |\n",
            "|                                |    power the next generation of AI-enabled edge    |\n",
            "|                                | devices.    Intel Core Ultra processors for edge:  |\n",
            "|                                |  Offering up to 5.02x better image classification  |\n",
            "|                                | inference performance compared to 14th Gen Intel®  |\n",
            "|                                |    Core™ desktop processors,1 Intel Core Ultra     |\n",
            "|                                | processors combine the Intel Arc GPU2 and a neural |\n",
            "|                                | processing unit (NPU)3 with LGA socket flexibility |\n",
            "|                                |  into a simplified system-on-chip (SoC). The new   |\n",
            "|                                |  SoC is designed to enable generative AI (GenAI)   |\n",
            "|                                |  and demanding graphics workloads at the edge for  |\n",
            "|                                |   retail, education, smart cities and industrial   |\n",
            "|                                | customers, including GenAI-enabled kiosk and smart |\n",
            "|                                |     point-of-sale systems in brick-and-mortar      |\n",
            "|                                |  retailers, interactive whiteboards for enhanced   |\n",
            "|                                |  in-classroom experiences and AI vision-enhanced   |\n",
            "|                                | industrial devices for manufacturing and roadside  |\n",
            "|                                | units.  Intel Core processors for edge: Intel Core |\n",
            "|                                |    processors combine the GPU power of 13th Gen    |\n",
            "|                                |   Intel® Core® mobile processors with LGA socket   |\n",
            "|                                |  flexibility to prioritize system scalability and  |\n",
            "|                                |   speed to deployment. This series of processors   |\n",
            "|                                | optimized for the edge offers up to 2.57x greater  |\n",
            "|                                |  graphics performance compared to 13th Gen Intel®  |\n",
            "|                                |  Core™ desktop processors4 by leveraging up to 3   |\n",
            "|                                |   times more graphics execution units alongside    |\n",
            "|                                | performance hybrid architecture with Intel® Thread |\n",
            "|                                | Director5 and an LGA socket-based design offering  |\n",
            "|                                |  customers more edge AI and graphics performance   |\n",
            "|                                |  without sacrificing hardware setup flexibility.   |\n",
            "|                                |  Intel Atom® processors x7000C Series: Intel Atom  |\n",
            "|                                |    processors x7000C Series delivers ramped-up     |\n",
            "|                                | processor base frequency in up to eight Efficient- |\n",
            "|                                |    cores to drive exceptional packet processing    |\n",
            "|                                |      throughput for enterprise networking and      |\n",
            "|                                |      telecommunications devices. This enables      |\n",
            "|                                | telecommunications businesses to use built-in deep |\n",
            "|                                |   learning inference capabilities to support the   |\n",
            "|                                |  detection of zero-day threats, boost packet and   |\n",
            "|                                |  control plane processing for OpenSSL/IPSec using  |\n",
            "|                                |    native instruction sets, and leverage Intel     |\n",
            "|                                | security features to harden networks. Intel Atom®  |\n",
            "|                                |      processors x7000RE Series: Primarily for      |\n",
            "|                                | industrial and manufacturing end users, Intel Atom |\n",
            "|                                |  processors x7000RE Series features built-in deep  |\n",
            "|                                |    learning inference capabilities and up to 32    |\n",
            "|                                |  graphics execution units in a ruggedized, power-  |\n",
            "|                                | efficient 6W-12W BGA package offering up to 9.83x  |\n",
            "|                                |   image classification performance compared with   |\n",
            "|                                |   Intel Atom processors x6000RE Series6. The new   |\n",
            "|                                |    processor supports fanless designs to enable    |\n",
            "|                                |  Industry 4.0 automation for key use cases in AI-  |\n",
            "|                                |  automated tending, warehouse AMR, in-line visual  |\n",
            "|                                |   inspection for quality control and ruggedized    |\n",
            "|                                |   industrial PC scenarios.     Additionally, the   |\n",
            "|                                |  Intel® Arc™ GPU for Edge boosts performance and   |\n",
            "|                                | edge AI capabilities on legacy Intel Core systems  |\n",
            "|                                |  as a discrete GPU providing accelerated AI, and   |\n",
            "|                                |   media and graphics processing power. Intel Arc   |\n",
            "|                                |  GPUs also eliminate vendor lock-in with an open,  |\n",
            "|                                | standards-based software stack to offer choice and |\n",
            "|                                |   flexibility when building high-performance AI    |\n",
            "|                                |     applications and solutions.  How Altera’s      |\n",
            "|                                | Portfolio Will Accelerate Customer AI Innovations: |\n",
            "|                                |   Following the FPGA Vision Webcast in February,   |\n",
            "|                                |  Altera announced additional updates to its FPGA   |\n",
            "|                                |  portfolio, providing flexible solutions to help   |\n",
            "|                                | customers solve their challenges from the cloud to |\n",
            "|                                | network to the intelligent edge. “We announced the |\n",
            "|                                |  launch of the new Altera brand with the goal of   |\n",
            "|                                | bringing leading technologies and innovations more |\n",
            "|                                | quickly to the FPGA market. Today, we are excited  |\n",
            "|                                |  about the next phase in our 10-plus year journey  |\n",
            "|                                |   delivering flexible AI solutions,” said Sandra   |\n",
            "|                                | Rivera, Altera chief executive officer. “Altera is |\n",
            "|                                |   leading the new FPGAi era by tightly coupling    |\n",
            "|                                |    programmability with tensor capabilities and    |\n",
            "|                                |   infusing FPGA and AI tools for a best-in-class   |\n",
            "|                                |   developer experience. Agilex 5, the first FPGA   |\n",
            "|                                |   with AI-infused throughout the fabric, is now    |\n",
            "|                                |  broadly available.” Altera Leads the New Era of   |\n",
            "|                                |    FPGAi: Altera helps customers achieve their     |\n",
            "|                                | business goals with new AI capabilities to support |\n",
            "|                                |     high-performance and mid-range FPGA-based      |\n",
            "|                                |    solutions, developer usability and workload     |\n",
            "|                                | agility. FPGA AI Suite adds support for Agilex™ 5  |\n",
            "|                                |  SoC FPGAs. The AI tool flow allows developers to  |\n",
            "|                                | use existing and popular AI frameworks, along with |\n",
            "|                                |    the Intel® OpenVINO™ toolkit and the FPGA AI    |\n",
            "|                                |   Suite, to create AI intellectual property (IP)   |\n",
            "|                                | blocks and easily drop them into the FPGA design.  |\n",
            "|                                | More information is available at the FPGA AI Suite |\n",
            "|                                |  website.    Performance per Watt Leader Agilex 5  |\n",
            "|                                |   SoC FPGAs Broadly Available: Agilex 5 devices,   |\n",
            "|                                |     with best-in-class AI and up to 2x better      |\n",
            "|                                | performance per watt versus competing 7 nanometer  |\n",
            "|                                |  FPGAs7, are designed to deliver high performance  |\n",
            "|                                |  with lower power in a modern SoC subsystem with   |\n",
            "|                                |    small form factor package options, allowing     |\n",
            "|                                |  customers and developers to add AI capability to  |\n",
            "|                                |   their products without the need for dedicated    |\n",
            "|                                |     accelerators. Geared toward a broad set of     |\n",
            "|                                |    embedded applications, Agilex 5 devices and     |\n",
            "|                                |    development kits are broadly available with     |\n",
            "|                                |       Quartus® Prime software support. Broad       |\n",
            "|                                | availability also includes support by a large and  |\n",
            "|                                |    growing list of ecosystem partners providing    |\n",
            "|                                |  additional boards, system-on-modules (SOMs), IP   |\n",
            "|                                | and various value-added services. More information |\n",
            "|                                |    about Agilex 5 devices, including technical     |\n",
            "|                                |   details, is available at the Agilex 5 SoC FPGA   |\n",
            "|                                |  website. Unleash the Power of Agilex 5 E-Series   |\n",
            "|                                | Devices with Quartus Prime Pro Edition S/W Version |\n",
            "|                                | 24.1: The latest version of Altera’s cutting-edge  |\n",
            "|                                | software is available for download, offering free  |\n",
            "|                                |  access to the latest Agilex 5 E-Series SoC FPGAs  |\n",
            "|                                |    and selected complementary IP cores. Quartus    |\n",
            "|                                | offers a streamlined experience for an IP-centric  |\n",
            "|                                |   design flow, configurable example designs and    |\n",
            "|                                |  unprecedented capabilities including a powerful   |\n",
            "|                                | new Agilex 5 SoC subsystem (hard-processor system  |\n",
            "|                                | featuring dual-core Arm Cortex A76, dual-core Arm  |\n",
            "|                                |  Cortex A55 processors and various peripherals).   |\n",
            "|                                | This new SoC subsystem is also supported by third- |\n",
            "|                                |  party tools recently updated to support Agilex 5  |\n",
            "|                                |   devices. More information is available at the    |\n",
            "|                                |  Quartus Prime Pro website. Portfolio Breadth and  |\n",
            "|                                |  Industry-Leading Longevity: Altera continues to   |\n",
            "|                                |   deliver a broad portfolio, including industry-   |\n",
            "|                                | leading longevity with selected MAX® and Cyclone®  |\n",
            "|                                |  cost- and power-optimized product families’ life  |\n",
            "|                                |     cycles extended to 2040 and later, further     |\n",
            "|                                | improving supply chain resilience. Future Agilex™  |\n",
            "|                                |   3 devices, coming soon, will expand the Agilex   |\n",
            "|                                | portfolio to deliver even greater breadth.    Why  |\n",
            "|                                |    It Matters for Altera FPGAs: In an era where    |\n",
            "|                                | technological advancements are integral to staying |\n",
            "|                                | competitive, Intel’s new edge-optimized processors |\n",
            "|                                | and solutions deliver the capabilities enterprises |\n",
            "|                                | need to innovate, be efficient and improve time to |\n",
            "|                                |    market. Altera delivers flexibility and re-     |\n",
            "|                                |    programmability to accelerate innovators by     |\n",
            "|                                |    providing easy-to-design and easy-to-deploy     |\n",
            "|                                |      leadership programmable solutions. These      |\n",
            "|                                |  processors, FPGAs and associated solutions allow  |\n",
            "|                                |  enterprises to leverage the tremendous amount of  |\n",
            "|                                | data generated at the edge to deploy sophisticated |\n",
            "|                                | embedded AI devices across a variety of industries |\n",
            "|                                |     to streamline operations, improve customer     |\n",
            "|                                |    satisfaction and incorporate advanced visual    |\n",
            "|                                | workloads.  “The FPGA AI Suite from Altera allowed |\n",
            "|                                | the Tiami team to rapidly incorporate our IP into  |\n",
            "|                                |    an intricate digital signal processing (DSP)    |\n",
            "|                                |   pipeline,” said Amitav Mukherjee, CEO at Tiami   |\n",
            "|                                |   Networks. “This significantly reduced the time   |\n",
            "|                                |   required to integrate AI capabilities with 5G    |\n",
            "|                                | signal processing from an estimated six months to  |\n",
            "|                                |   just eight weeks. Our engineering team clearly   |\n",
            "|                                |  recognized the value proposition offered by the   |\n",
            "|                                |  FPGA in preprocessing wireless signals received   |\n",
            "|                                |     from the antenna and performing real-time      |\n",
            "|                                |  inference, resulting in a successful demo.” More  |\n",
            "|                                |   Context: Intel Core Ultra Processors for Edge    |\n",
            "|                                | (PDF) | Intel Processers for the Edge | Intel Arc  |\n",
            "|                                |   GPU for Edge |  Intel Launches Altera, Its New   |\n",
            "|                                |  Standalone FPGA Company  How Intel Expands AI to  |\n",
            "|                                |  Embedded Edge Devices: Building on its expansive  |\n",
            "|                                |      installed base of more than 90,000 edge       |\n",
            "|                                |    deployments, Intel delivers a wave of edge-     |\n",
            "|                                |  optimized processors and GPUs to power the next   |\n",
            "|                                |     generation of AI-enabled edge devices.         |\n",
            "|                                | Additionally, the Intel® Arc™ GPU for Edge boosts  |\n",
            "|                                |   performance and edge AI capabilities on legacy   |\n",
            "|                                |   Intel Core systems as a discrete GPU providing   |\n",
            "|                                | accelerated AI, and media and graphics processing  |\n",
            "|                                | power. Intel Arc GPUs also eliminate vendor lock-  |\n",
            "|                                | in with an open, standards-based software stack to |\n",
            "|                                |  offer choice and flexibility when building high-  |\n",
            "|                                |  performance AI applications and solutions.  How   |\n",
            "|                                |   Altera’s Portfolio Will Accelerate Customer AI   |\n",
            "|                                | Innovations: Following the FPGA Vision Webcast in  |\n",
            "|                                |  February, Altera announced additional updates to  |\n",
            "|                                |  its FPGA portfolio, providing flexible solutions  |\n",
            "|                                | to help customers solve their challenges from the  |\n",
            "|                                |   cloud to network to the intelligent edge. “We    |\n",
            "|                                | announced the launch of the new Altera brand with  |\n",
            "|                                |   the goal of bringing leading technologies and    |\n",
            "|                                |    innovations more quickly to the FPGA market.    |\n",
            "|                                | Today, we are excited about the next phase in our  |\n",
            "|                                |    10-plus year journey delivering flexible AI     |\n",
            "|                                |    solutions,” said Sandra Rivera, Altera chief    |\n",
            "|                                |   executive officer. “Altera is leading the new    |\n",
            "|                                | FPGAi era by tightly coupling programmability with |\n",
            "|                                | tensor capabilities and infusing FPGA and AI tools |\n",
            "|                                |  for a best-in-class developer experience. Agilex  |\n",
            "|                                |  5, the first FPGA with AI-infused throughout the  |\n",
            "|                                |  fabric, is now broadly available.” Altera Leads   |\n",
            "|                                |    the New Era of FPGAi: Altera helps customers    |\n",
            "|                                |      achieve their business goals with new AI      |\n",
            "|                                | capabilities to support high-performance and mid-  |\n",
            "|                                |  range FPGA-based solutions, developer usability   |\n",
            "|                                |  and workload agility. FPGA AI Suite adds support  |\n",
            "|                                |  for Agilex™ 5 SoC FPGAs. The AI tool flow allows  |\n",
            "|                                |     developers to use existing and popular AI      |\n",
            "|                                |    frameworks, along with the Intel® OpenVINO™     |\n",
            "|                                |    toolkit and the FPGA AI Suite, to create AI     |\n",
            "|                                | intellectual property (IP) blocks and easily drop  |\n",
            "|                                |   them into the FPGA design. More information is   |\n",
            "|                                | available at the FPGA AI Suite website.     Why It |\n",
            "|                                |     Matters for Altera FPGAs: In an era where      |\n",
            "|                                | technological advancements are integral to staying |\n",
            "|                                | competitive, Intel’s new edge-optimized processors |\n",
            "|                                | and solutions deliver the capabilities enterprises |\n",
            "|                                | need to innovate, be efficient and improve time to |\n",
            "|                                |    market. Altera delivers flexibility and re-     |\n",
            "|                                |    programmability to accelerate innovators by     |\n",
            "|                                |    providing easy-to-design and easy-to-deploy     |\n",
            "|                                |      leadership programmable solutions. These      |\n",
            "|                                |  processors, FPGAs and associated solutions allow  |\n",
            "|                                |  enterprises to leverage the tremendous amount of  |\n",
            "|                                | data generated at the edge to deploy sophisticated |\n",
            "|                                | embedded AI devices across a variety of industries |\n",
            "|                                |     to streamline operations, improve customer     |\n",
            "|                                |    satisfaction and incorporate advanced visual    |\n",
            "|                                | workloads.  “The FPGA AI Suite from Altera allowed |\n",
            "|                                | the Tiami team to rapidly incorporate our IP into  |\n",
            "|                                |    an intricate digital signal processing (DSP)    |\n",
            "|                                |   pipeline,” said Amitav Mukherjee, CEO at Tiami   |\n",
            "|                                |   Networks. “This significantly reduced the time   |\n",
            "|                                |   required to integrate AI capabilities with 5G    |\n",
            "|                                | signal processing from an estimated six months to  |\n",
            "|                                |   just eight weeks. Our engineering team clearly   |\n",
            "|                                |  recognized the value proposition offered by the   |\n",
            "|                                |  FPGA in preprocessing wireless signals received   |\n",
            "|                                |     from the antenna and performing real-time      |\n",
            "|                                |  inference, resulting in a successful demo.” More  |\n",
            "|                                |   Context: Intel Core Ultra Processors for Edge    |\n",
            "|                                | (PDF) | Intel Processers for the Edge | Intel Arc  |\n",
            "|                                |   GPU for Edge |  Intel Launches Altera, Its New   |\n",
            "|                                | Standalone FPGA Company The Small Print:  Altera,  |\n",
            "|                                |    the Altera logo, and other Altera marks are     |\n",
            "|                                | trademarks of Altera.   Other names and brands may |\n",
            "|                                |      be claimed as the property of others. 1       |\n",
            "|                                |   Performance varies by use, configuration, and    |\n",
            "|                                |            other factors. Learn more at            |\n",
            "|                                |   intel.com/processorclaims: Intel® Core™ Ultra    |\n",
            "|                                |   processors, Edge. Results may vary.   2 Intel®   |\n",
            "|                                |   Arc™ GPU is only available on select H-Series,   |\n",
            "|                                | Intel® Core™ Ultra processor-powered systems with  |\n",
            "|                                |  at least 16GB of system memory in a dual-channel  |\n",
            "|                                |  configuration. OEM enablement is required; check  |\n",
            "|                                |    with OEM for system configuration details.      |\n",
            "|                                |  3 Intel® AI Boost enablement limited at launch.   |\n",
            "|                                |  4 Performance varies by use, configuration, and   |\n",
            "|                                |            other factors. Learn more at            |\n",
            "|                                |         intel.com/processorclaims: Intel®          |\n",
            "|                                |     Core™ processors, Edge. Results may vary.      |\n",
            "|                                |  5 Support for Intel® Thread Director is expected  |\n",
            "|                                |   in Windows 11 IoT Enterprise LTSC and Linux  6   |\n",
            "|                                |   Performance varies by use, configuration, and    |\n",
            "|                                |            other factors. Learn more at            |\n",
            "|                                | intel.com/processorclaims: Intel Atom® Processors. |\n",
            "|                                | Results may vary.  7 FPGA performance per watt:  h |\n",
            "|                                | ttps://edc.intel.com/content/www/us/en/products/pe |\n",
            "|                                |   rformance/benchmarks/agilex-fpga/. Results may   |\n",
            "|                                |   vary.    The Small Print:  Altera, the Altera    |\n",
            "|                                |   logo, and other Altera marks are trademarks of   |\n",
            "|                                | Altera.   Other names and brands may be claimed as |\n",
            "|                                |  the property of others. 1 Performance varies by   |\n",
            "|                                | use, configuration, and other factors. Learn more  |\n",
            "|                                |  at intel.com/processorclaims: Intel® Core™ Ultra  |\n",
            "|                                |   processors, Edge. Results may vary.   2 Intel®   |\n",
            "|                                |   Arc™ GPU is only available on select H-Series,   |\n",
            "|                                | Intel® Core™ Ultra processor-powered systems with  |\n",
            "|                                |  at least 16GB of system memory in a dual-channel  |\n",
            "|                                |  configuration. OEM enablement is required; check  |\n",
            "|                                |    with OEM for system configuration details.      |\n",
            "|                                |  3 Intel® AI Boost enablement limited at launch.   |\n",
            "|                                |  4 Performance varies by use, configuration, and   |\n",
            "|                                |            other factors. Learn more at            |\n",
            "|                                |         intel.com/processorclaims: Intel®          |\n",
            "|                                |     Core™ processors, Edge. Results may vary.      |\n",
            "|                                |  5 Support for Intel® Thread Director is expected  |\n",
            "|                                |   in Windows 11 IoT Enterprise LTSC and Linux  6   |\n",
            "|                                |   Performance varies by use, configuration, and    |\n",
            "|                                |            other factors. Learn more at            |\n",
            "|                                | intel.com/processorclaims: Intel Atom® Processors. |\n",
            "|                                | Results may vary.  7 FPGA performance per watt:  h |\n",
            "|                                | ttps://edc.intel.com/content/www/us/en/products/pe |\n",
            "|                                |   rformance/benchmarks/agilex-fpga/. Results may   |\n",
            "|                                | vary.    Altera,  Internet of Things,  Artificial  |\n",
            "|                                | Intelligence  About Intel Intel (Nasdaq: INTC) is  |\n",
            "|                                |    an industry leader, creating world-changing     |\n",
            "|                                |    technology that enables global progress and     |\n",
            "|                                |    enriches lives. Inspired by Moore’s Law, we     |\n",
            "|                                |    continuously work to advance the design and     |\n",
            "|                                |  manufacturing of semiconductors to help address   |\n",
            "|                                |  our customers’ greatest challenges. By embedding  |\n",
            "|                                | intelligence in the cloud, network, edge and every |\n",
            "|                                | kind of computing device, we unleash the potential |\n",
            "|                                | of data to transform business and society for the  |\n",
            "|                                |  better. To learn more about Intel’s innovations,  |\n",
            "|                                |  go to newsroom.intel.com and intel.com. © Intel   |\n",
            "|                                | Corporation. Intel, the Intel logo and other Intel |\n",
            "|                                |  marks are trademarks of Intel Corporation or its  |\n",
            "|                                |    subsidiaries. Other names and brands may be     |\n",
            "|                                |      claimed as the property of others. Intel      |\n",
            "|                                |     technologies may require enabled hardware,     |\n",
            "|                                |  software or service activation. // No product or  |\n",
            "|                                | component can be absolutely secure. // Your costs  |\n",
            "|                                |   and results may vary. // Performance varies by   |\n",
            "|                                |  use, configuration and other factors. // See our  |\n",
            "|                                |  complete legal Notices and Disclaimers. // Intel  |\n",
            "|                                |    is committed to respecting human rights and     |\n",
            "|                                |    avoiding causing or contributing to adverse     |\n",
            "|                                | impacts on human rights. See Intel’s Global Human  |\n",
            "|                                |  Rights Principles. Intel’s products and software  |\n",
            "|                                | are intended only to be used in applications that  |\n",
            "|                                |  do not cause or contribute to adverse impacts on  |\n",
            "|                                |                   human rights.                    |\n",
            "|   Sandra Rivera on LinkedIn:   |                        Agree & Join LinkedIn       |\n",
            "|     #women4ew #womenintech     | By clicking Continue to join or sign in, you agree |\n",
            "| #wearealtera #ai | 13 comments |  to LinkedIn‚Äôs User Agreement, Privacy Policy,   |\n",
            "|                                | and Cookie Policy.      A great #women4ew event at |\n",
            "|                                |     embedded world Exhibition&Conference today     |\n",
            "|                                |   covering various topics from addressing gender   |\n",
            "|                                |  bias in AI algorithms to discussing the critical  |\n",
            "|                                |  role diversity plays in innovation. At Altera we  |\n",
            "|                                | create a culture that positively impacts the work  |\n",
            "|                                |  experience and development of women. So, it has   |\n",
            "|                                |  filled me with hope and optimism to see so many   |\n",
            "|                                |   women in this industry come together to share    |\n",
            "|                                |   their experience and pave the way for the next   |\n",
            "|                                | generation of #womenintech #WeAreAltera #AI  Loved |\n",
            "|                                |   the insights on gender bias & diversity in AI!   |\n",
            "|                                |  Plato said wisdom begins in wonder, reminding us  |\n",
            "|                                |  that diversity fuels innovation by widening our   |\n",
            "|                                | perspectives üåü #womenintech #innovation  I love |\n",
            "|                                | the topic - \"how diversity can impact innovation\"  |\n",
            "|                                | reminded me of why the military did not put all of |\n",
            "|                                | the same \"Human Dynamic\" people together on teams  |\n",
            "|                                |  ( higher injury rates) and Margaret Heffernan's   |\n",
            "|                                | super chickens TED talk! Martin Curley and I will  |\n",
            "|                                | release our second innovation book in Q4 \"Managing |\n",
            "|                                | Innovation in a Digital World\"- we will send you a |\n",
            "|                                |     copy!  Financial Cultural Operational and      |\n",
            "|                                |    Technical Consultant - Alpha Sense Financial    |\n",
            "|                                | Consulting Here's a remedy to the tribal feminism  |\n",
            "|                                |    agenda...  The solution is to unite around a    |\n",
            "|                                |    common set of principles and values, and the    |\n",
            "|                                |      Gordon Moore ethos and Grove Egalitarian      |\n",
            "|                                |   Meritocracy.    Glad to see Pat pushing this;    |\n",
            "|                                | Will you join him Sandra Rivera and create the One |\n",
            "|                                | Culture Bob Swan initiated.    There needs to be a |\n",
            "|                                |  lot of follow through.   What your espousing is   |\n",
            "|                                |  antithetical to good solid ethics and practices;  |\n",
            "|                                | don't you think?  https://www.linkedin.com/article |\n",
            "|                                |   /edit/7117624932322185216/   Thank you, Sandra   |\n",
            "|                                |      Rivera, for being an incredible part of       |\n",
            "|                                |  #women4ew!¬†üí™  We are absolutely honoured to   |\n",
            "|                                |      have such amazing women like you in the       |\n",
            "|                                |   #embeddedworld! Assembly Test Manufacturing GM   |\n",
            "|                                |  Communications & Chief of Staff Support | Senior  |\n",
            "|                                |  Technical Leader | IDM 2.0 & Foundry Programs |   |\n",
            "|                                |    Lean Six Sigma Blackbelt | Multicultural ERG    |\n",
            "|                                |  Alliance Chair at Intel Corporation This is way   |\n",
            "|                                |   too important thank you for being a leader in    |\n",
            "|                                |  this. Bias of any kind in AI algorithms at this   |\n",
            "|                                |     critical juncture of machine learning is a     |\n",
            "|                                |   continuation of status quo, which is not good    |\n",
            "|                                |  enough. Change can only happen with real actions  |\n",
            "|                                |  beyond intentions. Thanks for making it real and  |\n",
            "|                                |  hearing, supporting and hopefully responding to   |\n",
            "|                                |   these issues. Digital Marketing | Social Media   |\n",
            "|                                |      Management | Content Creation It's truly      |\n",
            "|                                |    empowering to see initiatives like #women4ew    |\n",
            "|                                |    fostering discussions on crucial topics like    |\n",
            "|                                | gender bias in AI and the importance of diversity  |\n",
            "|                                |  in innovation.   Great to see you pushing this.   |\n",
            "|                                | It's really needed and hitting a chord. I know of  |\n",
            "|                                |  one tech startup that had 10 men originally with  |\n",
            "|                                |  no women. Now it's up to 22 with 12 women and 10  |\n",
            "|                                |    men. But web talks are still all men. I help    |\n",
            "|                                | ambitious leaders build strong Executive Presence  |\n",
            "|                                |  so that they get rapid career growth and coveted  |\n",
            "|                                |     CXO roles I Executive & Leadership Coach I     |\n",
            "|                                |    Learning and Development | Training | Talent    |\n",
            "|                                |   Management That's fantastic to hear about your   |\n",
            "|                                |  experience! It's encouraging to see women coming  |\n",
            "|                                |  together to support each other and advocate for   |\n",
            "|                                |  positive change. Financial Cultural Operational   |\n",
            "|                                |  and Technical Consultant - Alpha Sense Financial  |\n",
            "|                                | Consulting A picture of true unity and diversity.  |\n",
            "|                                |     A place where diverse talents thinking and     |\n",
            "|                                |    experience makes the best and highest use of    |\n",
            "|                                |  scarce Human Resources...      The Gordon Moore   |\n",
            "|                                | ethos of Intels first 3 decades was a place where  |\n",
            "|                                |   everyone rallied around a common purpose and a   |\n",
            "|                                |     shared sense of identity. Solving digital      |\n",
            "|                                |  challenges for U.S companies @ RKTech | Dreamer   |\n",
            "|                                | who does @ Rikkeisoft | Forbes Tech Council Member |\n",
            "|                                |    Kudos to Altera for fostering a culture that    |\n",
            "|                                | supports and develops women in the tech industry!  |\n",
            "|                                |         To view or add a comment, sign in          |\n",
            "|                                |    Financial Cultural Operational and Technical    |\n",
            "|                                |   Consultant - Alpha Sense Financial Consulting    |\n",
            "|                                |  Here's a remedy to the tribal feminism agenda...  |\n",
            "|                                |  The solution is to unite around a common set of   |\n",
            "|                                | principles and values, and the Gordon Moore ethos  |\n",
            "|                                | and Grove Egalitarian Meritocracy.    Glad to see  |\n",
            "|                                | Pat pushing this;  Will you join him Sandra Rivera |\n",
            "|                                |   and create the One Culture Bob Swan initiated.   |\n",
            "|                                | There needs to be a lot of follow through.   What  |\n",
            "|                                |    your espousing is antithetical to good solid    |\n",
            "|                                |       ethics and practices; don't you think?       |\n",
            "|                                |   https://lnkd.in/gg6wt2fU  Here's our pitch for   |\n",
            "|                                | Intel to live out the true spirit of the Open Door |\n",
            "|                                |  culture, and regain its position as the cultural  |\n",
            "|                                |        standard bearer for Silicon Valley.         |\n",
            "|                                |  https://lnkd.in/gbckTSTV A great #women4ew event  |\n",
            "|                                |   at embedded world Exhibition&Conference today    |\n",
            "|                                |   covering various topics from addressing gender   |\n",
            "|                                |  bias in AI algorithms to discussing the critical  |\n",
            "|                                |  role diversity plays in innovation. At Altera we  |\n",
            "|                                | create a culture that positively impacts the work  |\n",
            "|                                |  experience and development of women. So, it has   |\n",
            "|                                |  filled me with hope and optimism to see so many   |\n",
            "|                                |   women in this industry come together to share    |\n",
            "|                                |   their experience and pave the way for the next   |\n",
            "|                                |    generation of #womenintech #WeAreAltera #AI     |\n",
            "|                                |         To view or add a comment, sign in          |\n",
            "|                                |  1,230 followers              Empowering Women in  |\n",
            "|                                | AI: A Journey of Inclusivity & Innovation üöÄ  At |\n",
            "|                                |       Resonant Consulting, we believe in the       |\n",
            "|                                |  transformative power of artificial intelligence   |\n",
            "|                                |    (AI) and its potential to enrich lives when     |\n",
            "|                                |   inclusivity is at the forefront.   Our latest    |\n",
            "|                                |   carousel celebrates the journey towards gender   |\n",
            "|                                | inclusivity in AI, spotlighting the essential role |\n",
            "|                                | of male allies and the untapped potential of women |\n",
            "|                                |  in shaping the future of technology. üåü  We're  |\n",
            "|                                |      calling on everyone, especially our male      |\n",
            "|                                |  counterparts, to join us in this movement. Your   |\n",
            "|                                |   support is crucial in creating an environment    |\n",
            "|                                |    where women can excel and contribute to AI's    |\n",
            "|                                |  limitless possibilities. Together, let's ensure   |\n",
            "|                                |    the AI journey is inclusive, empowering, and    |\n",
            "|                                |   beneficial for all. Dive into our carousel to    |\n",
            "|                                | learn more and be part of the change.   #WomenInAI |\n",
            "|                                |   #InclusiveTech #ResonantConsulting #WomenInAI    |\n",
            "|                                |  #InclusiveAI #AIForAll #GenderInclusivityInTech   |\n",
            "|                                |  #EmpowerHerAI #AIInnovationForAll #DiversityInAI  |\n",
            "|                                |         #FutureIsFemaleAI #MaleAlliesForAI         |\n",
            "|                                |  #EmpoweringWomenInTech #TechForGood #AIEquality   |\n",
            "|                                |         To view or add a comment, sign in          |\n",
            "|                                |  100,560 followers              Generative AI is   |\n",
            "|                                | rapidly transforming the world as we know it, with |\n",
            "|                                |  C-suite executives anticipating that nearly half  |\n",
            "|                                |   of workers on average will require reskilling    |\n",
            "|                                | within the next three years.  A recent BCG report  |\n",
            "|                                | underscores that senior women in tech are leading  |\n",
            "|                                |     the way in #GenAI adoption, utilizing the      |\n",
            "|                                |  #technology at rates 14 percentage points higher  |\n",
            "|                                |  than their male counterparts. However, women in   |\n",
            "|                                |  non-technical roles and junior women across all   |\n",
            "|                                | functions are not keeping pace.  What drives these |\n",
            "|                                |  gender disparities in GenAI adoption and how can  |\n",
            "|                                |          leaders narrow the gap? Find out          |\n",
            "|                                |  here:¬†https://on.bcg.com/4b98ld0 #GenerativeAI   |\n",
            "|                                | #WomenInTech #ArtificialIntelligence           To  |\n",
            "|                                |           view or add a comment, sign in           |\n",
            "|                                | Digital Content Manager | Strategist | Gen AI | Ex |\n",
            "|                                |  Adani Digital Labs, Ogilvy, Wunderman Thompson,   |\n",
            "|                                |        FCB | Social Stars Gold, Digies Gold        |\n",
            "|                                |  This research says senior managers are adopting   |\n",
            "|                                | Gen AI fast. But why don't I see this happening in |\n",
            "|                                |  advertising and marketing? I hear people talking  |\n",
            "|                                |   about using AI and individuals flaunting their   |\n",
            "|                                |   knwoledge about it. But no effort to make AI a   |\n",
            "|                                |  part of daily jobs. Will this change? Hopefully,  |\n",
            "|                                |  it will trickle down from the senior managers to  |\n",
            "|                                | their teams soon enough.                  100,560  |\n",
            "|                                |  followers              Generative AI is rapidly   |\n",
            "|                                | transforming the world as we know it, with C-suite |\n",
            "|                                |    executives anticipating that nearly half of     |\n",
            "|                                | workers on average will require reskilling within  |\n",
            "|                                |     the next three years.  A recent BCG report     |\n",
            "|                                | underscores that senior women in tech are leading  |\n",
            "|                                |     the way in #GenAI adoption, utilizing the      |\n",
            "|                                |  #technology at rates 14 percentage points higher  |\n",
            "|                                |  than their male counterparts. However, women in   |\n",
            "|                                |  non-technical roles and junior women across all   |\n",
            "|                                | functions are not keeping pace.  What drives these |\n",
            "|                                |  gender disparities in GenAI adoption and how can  |\n",
            "|                                |          leaders narrow the gap? Find out          |\n",
            "|                                |  here:¬†https://on.bcg.com/4b98ld0 #GenerativeAI   |\n",
            "|                                | #WomenInTech #ArtificialIntelligence           To  |\n",
            "|                                |           view or add a comment, sign in           |\n",
            "|                                |  Global Leader - People & Organization Practice,   |\n",
            "|                                |   Senior Partner and Managing Director at Boston   |\n",
            "|                                |     Consulting Group (BCG)              As we      |\n",
            "|                                |  commemorate International Women‚Äôs Day, it's a   |\n",
            "|                                |     moment of reflection on our journey and a      |\n",
            "|                                | celebration of progress in the realm of technology |\n",
            "|                                | and leadership. I'm proud to share a glimpse into  |\n",
            "|                                |  @BCG‚Äôs latest report on GenAI‚Äôs integration   |\n",
            "|                                |   within the tech sector highlighting promising    |\n",
            "|                                | trends in gender diversity.     This report isn't  |\n",
            "|                                | just numbers; it's a narrative of change. It shows |\n",
            "|                                |    that women in senior tech roles are not just    |\n",
            "|                                |   pioneering the adoption of GenAI, but they are   |\n",
            "|                                | setting the pace, outperforming male counterparts  |\n",
            "|                                |     in GenAI adoption by 14 percentage points.     |\n",
            "|                                | Despite these gains, we acknowledge the persisting |\n",
            "|                                |  obstacles women continue to face. Bridging this   |\n",
            "|                                |   adoption gap is not just a tech issue; it's a    |\n",
            "|                                | business priority that demands a concerted effort  |\n",
            "|                                | across all levels of an organization.    Thank you |\n",
            "|                                | to my colleagues who drove this research: @Neveen  |\n",
            "|                                |   Awad, @Maria Barisano, @Adriana Dahik, @Julie    |\n",
            "|                                |   Bedard, @Uche Monu, and @Gunjan Mundhra. Their   |\n",
            "|                                | dedication echoes our shared mission‚Äîto build a  |\n",
            "|                                | culture where every woman's potential is realized, |\n",
            "|                                |    and their contributions are valued.    Let's    |\n",
            "|                                |   commit to the advancement of women and build a   |\n",
            "|                                |          more inclusive future together.           |\n",
            "|                                | #InternationalWomensday #GenerativeAI #WomeninTech |\n",
            "|                                |         To view or add a comment, sign in          |\n",
            "|                                |   3,074 followers              the vital role of   |\n",
            "|                                |  women in Artificial Intelligence (AI)! üåü Why   |\n",
            "|                                |  Female Representation in AI Matters: 1. Diverse   |\n",
            "|                                |     Perspectives 2. Ethical Considerations 3.      |\n",
            "|                                |   Inclusive Design 4. Inspiration and Mentorship   |\n",
            "|                                | Don't miss this chance to connect with AI experts  |\n",
            "|                                |      and innovators. #WomenInAI #AIInnovation      |\n",
            "|                                |  #womenempowerment #gwf23                   3,074  |\n",
            "|                                | followers              üì£ Exciting News! GLOBAL  |\n",
            "|                                |     WOMEN FORUM (GWF) Welcomes New Supporter:      |\n",
            "|                                |   International Group of Artificial Intelligence   |\n",
            "|                                |     highlighting the crucial role of women in      |\n",
            "|                                |  #ArtificialIntelligence.  Join us on Nov 15th in  |\n",
            "|                                | Berlin as we empower female #AI innovators, break  |\n",
            "|                                | gender barriers, and shape ethical AI. Let's drive |\n",
            "|                                |  the AI industry toward inclusivity and progress!  |\n",
            "|                                | Be part of the happening: https://lnkd.in/eAe4Y_KG |\n",
            "|                                |    Dr. Jassim Haji #WomenInAI #DiversityInTech     |\n",
            "|                                | #womeninstem #womenintechnology #womenempowerment  |\n",
            "|                                | #gwf23           To view or add a comment, sign in |\n",
            "|                                |     75 followers              AI for Women is      |\n",
            "|                                |    launching a brand new website - We are now a    |\n",
            "|                                |   professional networking platform for women AI    |\n",
            "|                                |  enthusiasts! The objective of this website is to  |\n",
            "|                                | promote networking among like-minded women who can |\n",
            "|                                | inspire, mentor, and help one another.   As a part |\n",
            "|                                | of the pre-launch campaign, I have decided to do a |\n",
            "|                                |  deep dive into how we can achieve equality in AI  |\n",
            "|                                | for women. I will be sharing my findings over the  |\n",
            "|                                |  next 3 days in the form of blog posts.   Today's  |\n",
            "|                                |        article talks about 'Gender Bias and        |\n",
            "|                                |        Stereotyping'. You can find it here:        |\n",
            "|                                |  https://lnkd.in/g3me3upH  Do you agree with the   |\n",
            "|                                |  article? Have you experienced / overcome similar  |\n",
            "|                                | challenges? Feel free to share your thoughts! üñã |\n",
            "|                                |  #AI #GenerativeAI #WomenEmpowerment #AIforWomen   |\n",
            "|                                | #WomeninAI #WomeninTech #WomeninSTEM #DataScience  |\n",
            "|                                |         To view or add a comment, sign in          |\n",
            "|                                |    Jubilant Pharmova | Former BCG | Former Egon    |\n",
            "|                                | Zehnder              This #InternationalWomensDay  |\n",
            "|                                |    is all about inspiring inclusion, and #GenAI    |\n",
            "|                                |  adoption holds tremendous opportunity.    A new   |\n",
            "|                                |       global BCG study featuring 6,500 tech        |\n",
            "|                                |  professionals reveals senior women in technical   |\n",
            "|                                | functions are leading the way in #GenAI adoption;  |\n",
            "|                                |   they are, 14 percentage points more likely to    |\n",
            "|                                |       embrace the technology than their male       |\n",
            "|                                | counterparts. But despite this progress, women in  |\n",
            "|                                | non-technical senior functions and junior women in |\n",
            "|                                |   all functions are lagging behind.    As GenAI    |\n",
            "|                                |  continues to transform the workplace and beyond,  |\n",
            "|                                |   it‚Äôs crucial that we band together to bridge   |\n",
            "|                                |  this divide and foster an inclusive environment.  |\n",
            "|                                |  Stay tuned for BCG‚Äôs new report, diving deeper  |\n",
            "|                                |  into the state of GenAI adoption and how we can   |\n",
            "|                                |   make a difference, launching soon.    #IWD2024   |\n",
            "|                                | #generativeAI #womenintech          To view or add |\n",
            "|                                |    a comment, sign in                   Global     |\n",
            "|                                |      Compensation Director at BCG | Strategic      |\n",
            "|                                |  Compensation Solutions Expert              This   |\n",
            "|                                |   #InternationalWomensDay is all about inspiring   |\n",
            "|                                |  inclusion, and #GenAI adoption holds tremendous   |\n",
            "|                                |  opportunity.    A new global BCG study featuring  |\n",
            "|                                |  6,500 tech professionals reveals senior women in  |\n",
            "|                                | technical functions are leading the way in #GenAI  |\n",
            "|                                |   adoption; they are, 14 percentage points more    |\n",
            "|                                |  likely to embrace the technology than their male  |\n",
            "|                                | counterparts. But despite this progress, women in  |\n",
            "|                                | non-technical senior functions and junior women in |\n",
            "|                                |   all functions are lagging behind.    As GenAI    |\n",
            "|                                |  continues to transform the workplace and beyond,  |\n",
            "|                                |   it‚Äôs crucial that we band together to bridge   |\n",
            "|                                |  this divide and foster an inclusive environment.  |\n",
            "|                                |  Stay tuned for BCG‚Äôs new report, diving deeper  |\n",
            "|                                |  into the state of GenAI adoption and how we can   |\n",
            "|                                |   make a difference, launching soon.    #IWD2024   |\n",
            "|                                | #generativeAI #womenintech          To view or add |\n",
            "|                                |    a comment, sign in                   Partner    |\n",
            "|                                |     As we mark International Women‚Äôs Day and     |\n",
            "|                                |   celebrate the remarkable achievements of women   |\n",
            "|                                |  worldwide, recent incidents in the tech industry  |\n",
            "|                                |  highlight the urgent need to address inadvertent  |\n",
            "|                                |    discrimination, particularly in the realm of    |\n",
            "|                                |  artificial intelligence (AI).  Let‚Äôs recommit   |\n",
            "|                                | ourselves to fostering inclusivity and equality in |\n",
            "|                                |       all aspects of technology and beyond.        |\n",
            "|                                |      #InternationalWomensDay #GenderEquality       |\n",
            "|                                | #TechInclusion #EthicalAI          To view or add  |\n",
            "|                                | a comment, sign in               49,355 followers  |\n",
            "|                                |  Create your free account or sign in to continue   |\n",
            "|                                |   your search                                 or   |\n",
            "|                                | By clicking Continue to join or sign in, you agree |\n",
            "|                                |  to LinkedIn‚Äôs User Agreement, Privacy Policy,   |\n",
            "|                                |  and Cookie Policy.                       New to   |\n",
            "|                                |     LinkedIn? Join now                     or      |\n",
            "|                                | By clicking Continue to join or sign in, you agree |\n",
            "|                                |  to LinkedIn‚Äôs User Agreement, Privacy Policy,   |\n",
            "|                                |   and Cookie Policy.                     New to    |\n",
            "|                                |                 LinkedIn? Join now                 |\n",
            "+--------------------------------+----------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'title': 'Intel and Altera Announce Edge and FPGA Offerings for AI at Embedded...',\n",
              "  'text': \"You can easily search the entire Intel.com site in several ways.\\nYou can also try the quick links below to see results for most popular searches.\\nThe browser version you are using is not recommended for this site.Please consider upgrading to the latest version of your browser by clicking one of the following links.\\nNew edge-optimized processors and FPGAs bring AI everywhere across edge computing markets including retail, industrial and healthcare.\\n\\nApril 8, 2024\\nContact Intel PR\\n\\nFollow Intel Newsroom on social:\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBy\\n\\nWhat’s New:\\xa0Today at Embedded World, Intel and Altera, an Intel Company, announced new edge-optimized processors, FPGAs and programmable market-ready solutions extending powerful AI capabilities into edge computing. These products will power AI-enabled edge devices applicable to industries across retail, healthcare, industrial, automotive, defense and aerospace.\\n\\nWhat’s New:\\xa0Today at Embedded World, Intel and Altera, an Intel Company, announced new edge-optimized processors, FPGAs and programmable market-ready solutions extending powerful AI capabilities into edge computing. These products will power AI-enabled edge devices applicable to industries across retail, healthcare, industrial, automotive, defense and aerospace.\\n“This next generation of Intel edge-optimized processors and discrete GPUs unleashes powerful AI capabilities to help businesses more seamlessly incorporate AI alongside compute, media and graphics workloads. From manufacturing to healthcare, Intel’s extensive edge AI experience and breadth and depth of edge-ready silicon and software help our customers deliver AI where they need it most for better business outcomes.” \\nWhy It Matters for Edge and AI: Why It Matters for Edge and AI: Intel’s new series of edge-optimized Intel® Core™\\u202fUltra, Intel® Core™ and Intel Atom® processors\\u202fand discrete Intel® Arc™ graphics processing units (GPUs) will advance innovation for artificial intelligence, visual computing and media processing – in support of faster and smarter decisions with on-premise edge computing. Agilex™ 5 FPGAs for mid-range applications with best-in-class performance per watt target a\\u202fbroad set of applications, including video, industrial, robotics, medical and others. Agilex\\u202f5 FPGAs with AI infused into the fabric offer a\\u202fhigh level of\\u202fintegration, low latency and improved computing capabilities\\u202ffor intelligent edge applications.\\nExpanding on Intel’s commitment to bringing AI everywhere, today's announcements utilize built-in AI acceleration in the new series of processors to power the next generation of edge devices.\\n\\nWhy It Matters for Edge and AI: Why It Matters for Edge and AI: Intel’s new series of edge-optimized Intel® Core™\\u202fUltra, Intel® Core™ and Intel Atom® processors\\u202fand discrete Intel® Arc™ graphics processing units (GPUs) will advance innovation for artificial intelligence, visual computing and media processing – in support of faster and smarter decisions with on-premise edge computing. Agilex™ 5 FPGAs for mid-range applications with best-in-class performance per watt target a\\u202fbroad set of applications, including video, industrial, robotics, medical and others. Agilex\\u202f5 FPGAs with AI infused into the fabric offer a\\u202fhigh level of\\u202fintegration, low latency and improved computing capabilities\\u202ffor intelligent edge applications.\\nExpanding on Intel’s commitment to bringing AI everywhere, today's announcements utilize built-in AI acceleration in the new series of processors to power the next generation of edge devices.\\nAn image shows the FPGAi Altera company logo. Altera helps customers achieve their business goals with new AI capabilities to support high-performance and mid-range FPGA-based solutions, developer usability and workload agility. (Credit: Altera, an Intel Company)\\nAn image shows an Intel Atom processor badge. Intel Atom processors x7000C Series delivers ramped-up processor base frequency in up to eight Efficient-cores. Intel Atom processors x7000RE Series features built-in deep learning inference capabilities. (Credit: Intel Corporation)\\nAn image shows an Intel Core Ultra processor badge. Intel Core Ultra processors combine the Intel Arc GPU and a neural processing unit (NPU) with LGA socket flexibility into a simplified system-on-chip (SoC). The new SoC is designed to enable generative AI (GenAI) and demanding graphics workloads at the edge. (Credit: Intel Corporation)\\nAn image shows the Intel Arc GPU for Edge badge. The Intel® Arc™ GPU for Edge boosts performance and edge AI capabilities on legacy Intel Core systems as a discrete GPU, providing accelerated AI, media and graphics processing power. (Credit: Intel Corporation)\\nAn image shows an Intel Core processor badge. Intel Core processors combine the GPU power of 13th Gen Intel Core mobile processors with LGA socket flexibility to prioritize system scalability and speed to deployment. (Credit: Intel Corporation)\\nAn image shows the Agilex 5 field programmable gate array. Agilex 5 FPGAs for mid-range applications with best-in-class performance per watt target a\\u202fbroad set of applications, including video, industrial, robotics, medical and others. (Credit: Altera, an Intel Company)\\nDownload all images (ZIP, 2 MB)\\n\\nDownload all images (ZIP, 2 MB)\\nHow Intel Expands AI to Embedded Edge Devices: Building on its expansive installed base of more than 90,000 edge deployments, Intel delivers a wave of edge-optimized processors and GPUs to power the next generation of AI-enabled edge devices.\\n\\xa0\\n\\nIntel Core\\u202fUltra processors for edge: Offering up to 5.02x better image classification inference performance compared to 14th Gen Intel® Core™ desktop processors,1 Intel Core Ultra processors combine the Intel Arc GPU2 and a neural processing unit (NPU)3 with LGA socket flexibility into a simplified system-on-chip (SoC). The new SoC is designed to enable generative AI (GenAI) and demanding graphics workloads at the edge for retail, education, smart cities and industrial customers, including GenAI-enabled kiosk and smart point-of-sale systems in brick-and-mortar retailers, interactive whiteboards for enhanced in-classroom experiences and AI vision-enhanced industrial devices for manufacturing and roadside units.\\xa0\\nIntel Core processors for edge: Intel Core processors combine the GPU power of 13th Gen Intel® Core® mobile processors with LGA socket flexibility to prioritize system scalability and speed to deployment. This series of processors optimized for the edge offers up to 2.57x greater graphics performance compared to 13th Gen Intel® Core™ desktop processors4 by leveraging up to 3 times more graphics execution units alongside performance hybrid architecture with Intel® Thread Director5 and an LGA socket-based design offering customers more edge AI and graphics performance without sacrificing hardware setup flexibility.\\nIntel Atom® processors x7000C Series: Intel Atom processors x7000C Series delivers ramped-up processor base frequency in up to eight Efficient-cores to drive exceptional packet processing throughput for enterprise networking and telecommunications devices. This enables telecommunications businesses to use built-in deep learning inference capabilities to support the detection of zero-day threats, boost packet and control plane processing for OpenSSL/IPSec using native instruction sets, and leverage Intel security features to harden networks.\\nIntel Atom® processors x7000RE Series: Primarily for industrial and manufacturing end users, Intel Atom processors x7000RE Series features built-in deep learning inference capabilities and up to 32 graphics execution units in a ruggedized, power-efficient 6W-12W BGA package offering up to 9.83x image classification performance compared with Intel Atom processors x6000RE Series6. The new processor supports fanless designs to enable Industry 4.0 automation for key use cases in AI-automated tending, warehouse AMR, in-line visual inspection for quality control and ruggedized industrial PC scenarios.\\xa0\\n\\n\\xa0\\nAdditionally, the Intel® Arc™ GPU for Edge boosts performance and edge AI capabilities on legacy Intel Core systems as a discrete GPU providing accelerated AI, and media and graphics processing power. Intel Arc GPUs also eliminate vendor lock-in with an open, standards-based software stack to offer choice and flexibility when building high-performance AI applications and solutions.\\xa0\\nHow Altera’s Portfolio Will Accelerate Customer AI Innovations: Following the FPGA Vision Webcast in February, Altera announced additional updates to its FPGA portfolio, providing flexible solutions to help customers solve their challenges from the cloud to network to the intelligent edge.\\n“We announced the launch of the new Altera brand with the goal of bringing leading technologies and innovations more quickly to the FPGA market. Today, we are excited about the next phase in our 10-plus year journey delivering flexible AI solutions,” said Sandra Rivera, Altera chief executive officer. “Altera is leading the new FPGAi era by tightly coupling programmability with tensor capabilities and infusing FPGA and AI tools for a best-in-class developer experience. Agilex 5, the first FPGA with AI-infused throughout the fabric, is now broadly available.”\\nAltera Leads the New Era of FPGAi: Altera helps customers achieve their business goals with new AI capabilities to support high-performance and mid-range FPGA-based solutions, developer usability and workload agility. FPGA AI Suite adds support for Agilex™ 5 SoC FPGAs. The AI tool flow allows developers to use existing and popular AI frameworks, along with the Intel® OpenVINO™ toolkit and the FPGA AI Suite, to create AI intellectual property (IP) blocks and easily drop them into the FPGA design. More information is available at the FPGA AI Suite website.\\n\\xa0\\n\\nPerformance per Watt Leader Agilex 5 SoC FPGAs Broadly Available: Agilex 5 devices, with best-in-class AI and up to 2x better performance per watt versus competing 7 nanometer FPGAs7, are designed to deliver high performance with lower power in a modern SoC subsystem with small form factor package options, allowing customers and developers to add AI capability to their products without the need for dedicated accelerators. Geared toward a broad set of embedded applications, Agilex 5 devices and development kits are broadly available with Quartus® Prime software support. Broad availability also includes support by a large and growing list of ecosystem partners providing additional boards, system-on-modules (SOMs), IP and various value-added services. More information about Agilex 5 devices, including technical details, is available at the Agilex 5 SoC FPGA website.\\nUnleash the Power of Agilex 5 E-Series Devices with Quartus Prime Pro Edition S/W Version 24.1: The latest version of Altera’s cutting-edge software is available for download, offering free access to the latest Agilex 5 E-Series SoC FPGAs and selected complementary IP cores. Quartus offers a streamlined experience for an IP-centric design flow, configurable example designs and unprecedented capabilities including a powerful new Agilex 5 SoC subsystem (hard-processor system featuring dual-core Arm Cortex A76, dual-core Arm Cortex A55 processors and various peripherals). This new SoC subsystem is also supported by third-party tools recently updated to support Agilex 5 devices. More information is available at the Quartus Prime Pro website.\\nPortfolio Breadth and Industry-Leading Longevity: Altera continues to deliver a broad portfolio, including industry-leading longevity with selected MAX® and Cyclone® cost- and power-optimized product families’ life cycles extended to 2040 and later, further improving supply chain resilience. Future Agilex™ 3 devices, coming soon, will expand the Agilex portfolio to deliver even greater breadth.\\n\\n\\xa0\\nWhy It Matters for Altera FPGAs: In an era where technological advancements are integral to staying competitive, Intel’s new edge-optimized processors and solutions deliver the capabilities enterprises need to innovate, be efficient and improve time to market. Altera delivers flexibility and re-programmability to accelerate innovators by providing easy-to-design and easy-to-deploy leadership programmable solutions.\\nThese processors, FPGAs and associated solutions allow enterprises to leverage the tremendous amount of data generated at the edge to deploy sophisticated embedded AI devices across a variety of industries to streamline operations, improve customer satisfaction and incorporate advanced visual workloads.\\xa0\\n“The FPGA AI Suite from Altera allowed the Tiami team to rapidly incorporate our IP into an intricate digital signal processing (DSP) pipeline,” said Amitav Mukherjee, CEO at Tiami Networks. “This significantly reduced the time required to integrate AI capabilities with 5G signal processing from an estimated six months to just eight weeks. Our engineering team clearly recognized the value proposition offered by the FPGA in preprocessing wireless signals received from the antenna and performing real-time inference, resulting in a successful demo.”\\nMore Context: Intel Core Ultra Processors for Edge (PDF) | Intel Processers for the Edge | Intel Arc GPU for Edge |\\xa0 Intel Launches Altera, Its New Standalone FPGA Company\\n\\nHow Intel Expands AI to Embedded Edge Devices: Building on its expansive installed base of more than 90,000 edge deployments, Intel delivers a wave of edge-optimized processors and GPUs to power the next generation of AI-enabled edge devices.\\n\\xa0\\n\\xa0\\nAdditionally, the Intel® Arc™ GPU for Edge boosts performance and edge AI capabilities on legacy Intel Core systems as a discrete GPU providing accelerated AI, and media and graphics processing power. Intel Arc GPUs also eliminate vendor lock-in with an open, standards-based software stack to offer choice and flexibility when building high-performance AI applications and solutions.\\xa0\\nHow Altera’s Portfolio Will Accelerate Customer AI Innovations: Following the FPGA Vision Webcast in February, Altera announced additional updates to its FPGA portfolio, providing flexible solutions to help customers solve their challenges from the cloud to network to the intelligent edge.\\n“We announced the launch of the new Altera brand with the goal of bringing leading technologies and innovations more quickly to the FPGA market. Today, we are excited about the next phase in our 10-plus year journey delivering flexible AI solutions,” said Sandra Rivera, Altera chief executive officer. “Altera is leading the new FPGAi era by tightly coupling programmability with tensor capabilities and infusing FPGA and AI tools for a best-in-class developer experience. Agilex 5, the first FPGA with AI-infused throughout the fabric, is now broadly available.”\\nAltera Leads the New Era of FPGAi: Altera helps customers achieve their business goals with new AI capabilities to support high-performance and mid-range FPGA-based solutions, developer usability and workload agility. FPGA AI Suite adds support for Agilex™ 5 SoC FPGAs. The AI tool flow allows developers to use existing and popular AI frameworks, along with the Intel® OpenVINO™ toolkit and the FPGA AI Suite, to create AI intellectual property (IP) blocks and easily drop them into the FPGA design. More information is available at the FPGA AI Suite website.\\n\\xa0\\n\\xa0\\nWhy It Matters for Altera FPGAs: In an era where technological advancements are integral to staying competitive, Intel’s new edge-optimized processors and solutions deliver the capabilities enterprises need to innovate, be efficient and improve time to market. Altera delivers flexibility and re-programmability to accelerate innovators by providing easy-to-design and easy-to-deploy leadership programmable solutions.\\nThese processors, FPGAs and associated solutions allow enterprises to leverage the tremendous amount of data generated at the edge to deploy sophisticated embedded AI devices across a variety of industries to streamline operations, improve customer satisfaction and incorporate advanced visual workloads.\\xa0\\n“The FPGA AI Suite from Altera allowed the Tiami team to rapidly incorporate our IP into an intricate digital signal processing (DSP) pipeline,” said Amitav Mukherjee, CEO at Tiami Networks. “This significantly reduced the time required to integrate AI capabilities with 5G signal processing from an estimated six months to just eight weeks. Our engineering team clearly recognized the value proposition offered by the FPGA in preprocessing wireless signals received from the antenna and performing real-time inference, resulting in a successful demo.”\\nMore Context: Intel Core Ultra Processors for Edge (PDF) | Intel Processers for the Edge | Intel Arc GPU for Edge |\\xa0 Intel Launches Altera, Its New Standalone FPGA Company\\nThe Small Print:\\xa0\\nAltera, the Altera logo, and other Altera marks are trademarks of Altera.\\xa0\\r\\nOther names and brands may be claimed as the property of others.\\n1 Performance varies by use, configuration, and other factors. Learn more at intel.com/processorclaims: Intel® Core™ Ultra processors, Edge. Results may vary.\\xa0\\xa0\\n2\\xa0Intel® Arc™ GPU\\xa0is only available on select H-Series, Intel® Core™ Ultra processor-powered\\xa0systems with at least 16GB of system memory in a dual-channel configuration.\\xa0OEM enablement\\xa0is\\xa0required; check with OEM for system configuration details.\\xa0\\n3\\xa0Intel® AI Boost enablement limited at launch.\\xa0\\n4\\xa0Performance varies by use, configuration, and other factors. Learn more at intel.com/processorclaims: Intel® Core™\\xa0processors, Edge.\\xa0Results may vary.\\xa0\\n5\\xa0Support for Intel® Thread Director is expected in Windows 11 IoT Enterprise LTSC and Linux\\xa0\\n6 Performance varies by use, configuration, and other factors. Learn more at intel.com/processorclaims:\\xa0Intel Atom® Processors. Results may vary.\\xa0\\n7\\xa0FPGA performance per watt:\\xa0\\xa0https://edc.intel.com/content/www/us/en/products/performance/benchmarks/agilex-fpga/. Results may vary.\\xa0\\xa0\\n\\nThe Small Print:\\xa0\\nAltera, the Altera logo, and other Altera marks are trademarks of Altera.\\xa0\\r\\nOther names and brands may be claimed as the property of others.\\n1 Performance varies by use, configuration, and other factors. Learn more at intel.com/processorclaims: Intel® Core™ Ultra processors, Edge. Results may vary.\\xa0\\xa0\\n2\\xa0Intel® Arc™ GPU\\xa0is only available on select H-Series, Intel® Core™ Ultra processor-powered\\xa0systems with at least 16GB of system memory in a dual-channel configuration.\\xa0OEM enablement\\xa0is\\xa0required; check with OEM for system configuration details.\\xa0\\n3\\xa0Intel® AI Boost enablement limited at launch.\\xa0\\n4\\xa0Performance varies by use, configuration, and other factors. Learn more at intel.com/processorclaims: Intel® Core™\\xa0processors, Edge.\\xa0Results may vary.\\xa0\\n5\\xa0Support for Intel® Thread Director is expected in Windows 11 IoT Enterprise LTSC and Linux\\xa0\\n6 Performance varies by use, configuration, and other factors. Learn more at intel.com/processorclaims:\\xa0Intel Atom® Processors. Results may vary.\\xa0\\n7\\xa0FPGA performance per watt:\\xa0\\xa0https://edc.intel.com/content/www/us/en/products/performance/benchmarks/agilex-fpga/. Results may vary.\\xa0\\xa0\\n\\nAltera, \\nInternet of Things, \\nArtificial Intelligence\\n\\nAbout Intel\\nIntel (Nasdaq: INTC) is an industry leader, creating world-changing technology that enables global progress and enriches lives. Inspired by Moore’s Law, we continuously work to advance the design and manufacturing of semiconductors to help address our customers’ greatest challenges. By embedding intelligence in the cloud, network, edge and every kind of computing device, we unleash the potential of data to transform business and society for the better. To learn more about Intel’s innovations, go to newsroom.intel.com and intel.com.\\n© Intel Corporation. Intel, the Intel logo and other Intel marks are trademarks of Intel Corporation or its subsidiaries. Other names and brands may be claimed as the property of others.\\nIntel technologies may require enabled hardware, software or service activation. // No product or component can be absolutely secure. // Your costs and results may vary. // Performance varies by use, configuration and other factors. // See our complete legal Notices and Disclaimers. //\\xa0Intel is committed to respecting human rights and avoiding causing or contributing to adverse impacts on human rights. See Intel’s Global Human Rights Principles. Intel’s products and software are intended only to be used in applications that do not cause or contribute to adverse impacts on human rights.\"},\n",
              " {'title': 'Sandra Rivera on LinkedIn: #women4ew #womenintech #wearealtera #ai | 13 comments',\n",
              "  'text': '\\n                Agree & Join LinkedIn\\n              \\n\\n      By clicking Continue to join or sign in, you agree to LinkedIn‚Äôs User Agreement, Privacy Policy, and Cookie Policy.\\n    \\nA great #women4ew event at embedded world Exhibition&Conference today covering various topics from addressing gender bias in AI algorithms to discussing the critical role diversity plays in innovation.\\nAt Altera we create a culture that positively impacts the work experience and development of women. So, it has filled me with hope and optimism to see so many women in this industry come together to share their experience and pave the way for the next generation of #womenintech #WeAreAltera #AI\\n\\nLoved the insights on gender bias & diversity in AI! Plato said wisdom begins in wonder, reminding us that diversity fuels innovation by widening our perspectives \\uf8ffüåü #womenintech #innovation\\n\\nI love the topic - \"how diversity can impact innovation\"  reminded me of why the military did not put all of the same \"Human Dynamic\" people together on teams ( higher injury rates) and Margaret Heffernan\\'s super chickens TED talk! Martin Curley and I will release our second innovation book in Q4 \"Managing Innovation in a Digital World\"- we will send you a copy! \\nFinancial Cultural Operational and Technical Consultant - Alpha Sense Financial Consulting\\nHere\\'s a remedy to the tribal feminism agenda...\\n\\nThe solution is to unite around a common set of principles and values, and the Gordon Moore ethos and Grove Egalitarian Meritocracy.    Glad to see Pat pushing this;  Will you join him Sandra Rivera and create the One Culture Bob Swan initiated.    There needs to be a lot of follow through. \\n\\nWhat your espousing is antithetical to good solid ethics and practices; don\\'t you think?\\n\\nhttps://www.linkedin.com/article/edit/7117624932322185216/\\n\\n\\nThank you, Sandra Rivera, for being an incredible part of #women4ew!¬†\\uf8ffüí™ \\nWe are absolutely honoured to have such amazing women like you in the #embeddedworld!\\nAssembly Test Manufacturing GM Communications & Chief of Staff Support | Senior Technical Leader | IDM 2.0 & Foundry Programs | Lean Six Sigma Blackbelt | Multicultural ERG Alliance Chair at Intel Corporation\\nThis is way too important thank you for being a leader in this. Bias of any kind in AI algorithms at this critical juncture of machine learning is a continuation of status quo, which is not good enough. Change can only happen with real actions beyond intentions. Thanks for making it real and hearing, supporting and hopefully responding to these issues.\\nDigital Marketing | Social Media Management | Content Creation\\nIt\\'s truly empowering to see initiatives like #women4ew fostering discussions on crucial topics like gender bias in AI and the importance of diversity in innovation. \\n\\nGreat to see you pushing this. It\\'s really needed and hitting a chord. I know of one tech startup that had 10 men originally with no women. Now it\\'s up to 22 with 12 women and 10 men. But web talks are still all men.\\nI help ambitious leaders build strong Executive Presence so that they get rapid career growth and coveted CXO roles I Executive & Leadership Coach I Learning and Development | Training | Talent Management\\nThat\\'s fantastic to hear about your experience! It\\'s encouraging to see women coming together to support each other and advocate for positive change.\\nFinancial Cultural Operational and Technical Consultant - Alpha Sense Financial Consulting\\nA picture of true unity and diversity.   A place where diverse talents thinking and experience makes the best and highest use of scarce Human Resources...    \\n\\nThe Gordon Moore ethos of Intels first 3 decades was a place where everyone rallied around a common purpose and a shared sense of identity.\\nSolving digital challenges for U.S companies @ RKTech | Dreamer who does @ Rikkeisoft | Forbes Tech Council Member\\nKudos to Altera for fostering a culture that supports and develops women in the tech industry! \\n\\n        To view or add a comment, sign in\\n\\n\\n                Financial Cultural Operational and Technical Consultant - Alpha Sense Financial Consulting\\n            \\nHere\\'s a remedy to the tribal feminism agenda...\\n\\nThe solution is to unite around a common set of principles and values, and the Gordon Moore ethos and Grove Egalitarian Meritocracy.    Glad to see Pat pushing this;  Will you join him Sandra Rivera and create the One Culture Bob Swan initiated.    There needs to be a lot of follow through. \\n\\nWhat your espousing is antithetical to good solid ethics and practices; don\\'t you think?\\n\\nhttps://lnkd.in/gg6wt2fU\\n\\nHere\\'s our pitch for Intel to live out the true spirit of the Open Door culture, and regain its position as the cultural standard bearer for Silicon Valley.\\n\\nhttps://lnkd.in/gbckTSTV\\nA great #women4ew event at embedded world Exhibition&Conference today covering various topics from addressing gender bias in AI algorithms to discussing the critical role diversity plays in innovation.\\nAt Altera we create a culture that positively impacts the work experience and development of women. So, it has filled me with hope and optimism to see so many women in this industry come together to share their experience and pave the way for the next generation of #womenintech #WeAreAltera #AI\\n\\n        To view or add a comment, sign in\\n\\n\\n                1,230 followers\\n            \\nEmpowering Women in AI: A Journey of Inclusivity & Innovation \\uf8ffüöÄ\\n\\nAt Resonant Consulting, we believe in the transformative power of artificial intelligence (AI) and its potential to enrich lives when inclusivity is at the forefront. \\n\\nOur latest carousel celebrates the journey towards gender inclusivity in AI, spotlighting the essential role of male allies and the untapped potential of women in shaping the future of technology. \\uf8ffüåü\\n\\nWe\\'re calling on everyone, especially our male counterparts, to join us in this movement. Your support is crucial in creating an environment where women can excel and contribute to AI\\'s limitless possibilities. Together, let\\'s ensure the AI journey is inclusive, empowering, and beneficial for all. Dive into our carousel to learn more and be part of the change. \\n\\n#WomenInAI #InclusiveTech #ResonantConsulting #WomenInAI\\n#InclusiveAI #AIForAll #GenderInclusivityInTech #EmpowerHerAI #AIInnovationForAll #DiversityInAI #FutureIsFemaleAI #MaleAlliesForAI #EmpoweringWomenInTech #TechForGood #AIEquality\\n\\n\\n        To view or add a comment, sign in\\n\\n\\n                100,560 followers\\n            \\nGenerative AI is rapidly transforming the world as we know it, with C-suite executives anticipating that nearly half of workers on average will require reskilling within the next three years.\\n\\nA recent BCG report underscores that senior women in tech are leading the way in #GenAI adoption, utilizing the #technology at rates 14 percentage points higher than their male counterparts. However, women in non-technical roles and junior women across all functions are not keeping pace.\\n\\nWhat drives these gender disparities in GenAI adoption and how can leaders narrow the gap? Find out here:¬†https://on.bcg.com/4b98ld0\\n#GenerativeAI #WomenInTech #ArtificialIntelligence\\n\\n\\n        To view or add a comment, sign in\\n\\n\\n                Digital Content Manager | Strategist | Gen AI | Ex Adani Digital Labs, Ogilvy, Wunderman Thompson, FCB | Social Stars Gold, Digies Gold\\n            \\nThis research says senior managers are adopting Gen AI fast. But why don\\'t I see this happening in advertising and marketing? I hear people talking about using AI and individuals flaunting their knwoledge about it. But no effort to make AI a part of daily jobs. Will this change? Hopefully, it will trickle down from the senior managers to their teams soon enough.\\n\\n                100,560 followers\\n            \\nGenerative AI is rapidly transforming the world as we know it, with C-suite executives anticipating that nearly half of workers on average will require reskilling within the next three years.\\n\\nA recent BCG report underscores that senior women in tech are leading the way in #GenAI adoption, utilizing the #technology at rates 14 percentage points higher than their male counterparts. However, women in non-technical roles and junior women across all functions are not keeping pace.\\n\\nWhat drives these gender disparities in GenAI adoption and how can leaders narrow the gap? Find out here:¬†https://on.bcg.com/4b98ld0\\n#GenerativeAI #WomenInTech #ArtificialIntelligence\\n\\n\\n        To view or add a comment, sign in\\n\\n\\n                Global Leader - People & Organization Practice, Senior Partner and Managing Director at Boston Consulting Group (BCG)\\n            \\nAs we commemorate International Women‚Äôs Day, it\\'s a moment of reflection on our journey and a celebration of progress in the realm of technology and leadership. I\\'m proud to share a glimpse into @BCG‚Äôs latest report on GenAI‚Äôs integration within the tech sector highlighting promising trends in gender diversity.  \\n \\nThis report isn\\'t just numbers; it\\'s a narrative of change. It shows that women in senior tech roles are not just pioneering the adoption of GenAI, but they are setting the pace, outperforming male counterparts in GenAI adoption by 14 percentage points.\\n \\nDespite these gains, we acknowledge the persisting obstacles women continue to face. Bridging this adoption gap is not just a tech issue; it\\'s a business priority that demands a concerted effort across all levels of an organization. \\n \\nThank you to my colleagues who drove this research: @Neveen Awad, @Maria Barisano, @Adriana Dahik, @Julie Bedard, @Uche Monu, and @Gunjan Mundhra. Their dedication echoes our shared mission‚Äîto build a culture where every woman\\'s potential is realized, and their contributions are valued. \\n \\nLet\\'s commit to the advancement of women and build a more inclusive future together. \\n  \\n#InternationalWomensday #GenerativeAI #WomeninTech \\n\\n        To view or add a comment, sign in\\n\\n\\n                3,074 followers\\n            \\nthe vital role of women in Artificial Intelligence (AI)!\\n\\uf8ffüåü Why Female Representation in AI Matters:\\n1. Diverse Perspectives\\n2. Ethical Considerations\\n3. Inclusive Design\\n4. Inspiration and Mentorship\\nDon\\'t miss this chance to connect with AI experts and innovators.\\n#WomenInAI #AIInnovation #womenempowerment #gwf23 \\n\\n                3,074 followers\\n            \\n\\uf8ffüì£ Exciting News! GLOBAL WOMEN FORUM (GWF) Welcomes New Supporter: International Group of Artificial Intelligence highlighting the crucial role of women in #ArtificialIntelligence. \\nJoin us on Nov 15th in Berlin as we empower female #AI innovators, break gender barriers, and shape ethical AI. Let\\'s drive the AI industry toward inclusivity and progress! \\n\\nBe part of the happening: https://lnkd.in/eAe4Y_KG\\nDr. Jassim Haji #WomenInAI #DiversityInTech #womeninstem #womenintechnology #womenempowerment #gwf23\\n\\n\\n        To view or add a comment, sign in\\n\\n\\n                75 followers\\n            \\nAI for Women is launching a brand new website - We are now a professional networking platform for women AI enthusiasts! The objective of this website is to promote networking among like-minded women who can inspire, mentor, and help one another. \\n\\nAs a part of the pre-launch campaign, I have decided to do a deep dive into how we can achieve equality in AI for women. I will be sharing my findings over the next 3 days in the form of blog posts. \\n\\nToday\\'s article talks about \\'Gender Bias and Stereotyping\\'. You can find it here: https://lnkd.in/g3me3upH\\n\\nDo you agree with the article? Have you experienced / overcome similar challenges? Feel free to share your thoughts! \\uf8ffüñã \\n\\n#AI #GenerativeAI #WomenEmpowerment #AIforWomen #WomeninAI #WomeninTech #WomeninSTEM #DataScience\\n\\n        To view or add a comment, sign in\\n\\n\\n                Jubilant Pharmova | Former BCG | Former Egon Zehnder\\n            \\nThis #InternationalWomensDay is all about inspiring inclusion, and #GenAI adoption holds tremendous opportunity.  \\n\\nA new global BCG study featuring 6,500 tech professionals reveals senior women in technical functions are leading the way in #GenAI adoption; they are, 14 percentage points more likely to embrace the technology than their male counterparts. But despite this progress, women in non-technical senior functions and junior women in all functions are lagging behind.  \\n\\nAs GenAI continues to transform the workplace and beyond, it‚Äôs crucial that we band together to bridge this divide and foster an inclusive environment. Stay tuned for BCG‚Äôs new report, diving deeper into the state of GenAI adoption and how we can make a difference, launching soon.  \\n\\n#IWD2024 #generativeAI #womenintech\\n\\n        To view or add a comment, sign in\\n\\n\\n                Global Compensation Director at BCG | Strategic Compensation Solutions Expert\\n            \\nThis #InternationalWomensDay is all about inspiring inclusion, and #GenAI adoption holds tremendous opportunity.  \\n\\nA new global BCG study featuring 6,500 tech professionals reveals senior women in technical functions are leading the way in #GenAI adoption; they are, 14 percentage points more likely to embrace the technology than their male counterparts. But despite this progress, women in non-technical senior functions and junior women in all functions are lagging behind.  \\n\\nAs GenAI continues to transform the workplace and beyond, it‚Äôs crucial that we band together to bridge this divide and foster an inclusive environment. Stay tuned for BCG‚Äôs new report, diving deeper into the state of GenAI adoption and how we can make a difference, launching soon.  \\n\\n#IWD2024 #generativeAI #womenintech\\n\\n        To view or add a comment, sign in\\n\\n\\n                Partner \\n            \\nAs we mark International Women‚Äôs Day and celebrate the remarkable achievements of women worldwide, recent incidents in the tech industry highlight the urgent need to address inadvertent discrimination, particularly in the realm of artificial intelligence (AI).\\n\\nLet‚Äôs recommit ourselves to fostering inclusivity and equality in all aspects of technology and beyond.\\n\\n#InternationalWomensDay #GenderEquality #TechInclusion #EthicalAI\\n\\n        To view or add a comment, sign in\\n\\n\\n            49,355 followers\\n          \\n\\n                Create your free account or sign in to continue your search\\n              \\n\\n\\n\\n              or\\n            \\n\\n      By clicking Continue to join or sign in, you agree to LinkedIn‚Äôs User Agreement, Privacy Policy, and Cookie Policy.\\n    \\n\\n                New to LinkedIn? Join now\\n\\n\\n                  or\\n                \\n\\n      By clicking Continue to join or sign in, you agree to LinkedIn‚Äôs User Agreement, Privacy Policy, and Cookie Policy.\\n    \\n\\n              New to LinkedIn? Join now\\n\\n'}]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fTbWZRxK3oar"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Function to save results to text file in Google Drive\n",
        "def save_results_to_text(results, filename=file_path):\n",
        "    try:\n",
        "        with open(filename, mode='w', encoding='utf-8') as file:\n",
        "            for result in results:\n",
        "                file.write(f\"Text: {result['text']}\\n\")\n",
        "        # Check if the file was created and is not empty\n",
        "        if os.path.exists(filename) and os.path.getsize(filename) > 0:\n",
        "            print(f\"File '{filename}' created successfully.\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"File '{filename}' not created or is empty.\")\n",
        "            return False\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "U4_amMD25fBJ"
      },
      "outputs": [],
      "source": [
        "# Stores the results in results.txt file in a GDrive folder titled 'KG'\n",
        "def store_extracted_info(results):\n",
        "\n",
        "  stored_result=save_results_to_text(results)\n",
        "  folder_path = '/content/drive/My Drive/KG'\n",
        "  files = os.listdir(folder_path)\n",
        "  print(files)\n",
        "  # Commenting the following line of code because the graph has already been constructed for the demo\n",
        "  # construct_knowledge_graph()\n",
        "  run_async_function()\n",
        "  if stored_result:\n",
        "    return 200\n",
        "  else:\n",
        "    return 400"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "hrJxKb9yP3xg"
      },
      "outputs": [],
      "source": [
        "# Load all the text files in the folder to construct knowledge graph\n",
        "\"\"\"\n",
        "Reads documents from the KG directory (GDrive) and creates KnowledgeGraphIndex with triplets,\n",
        "and the embeddings. The graph is stored in SimpleGraphStore\n",
        "\"\"\"\n",
        "\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "def construct_knowledge_graph():\n",
        "  documents = SimpleDirectoryReader(\n",
        "    \"/content/drive/My Drive/KG\"\n",
        "  ).load_data()\n",
        "  llm = OpenAI(temperature=0, model=\"gpt-4\")\n",
        "  Settings.llm = llm\n",
        "  Settings.chunk_size = 512\n",
        "  graph_store = SimpleGraphStore()\n",
        "  storage_context = StorageContext.from_defaults(graph_store=graph_store)\n",
        "  # Considering embeddings\n",
        "  global new_index\n",
        "  new_index = KnowledgeGraphIndex.from_documents(\n",
        "      documents,\n",
        "      max_triplets_per_chunk=2,\n",
        "      include_embeddings=True,\n",
        "  )\n",
        "  global query_engine\n",
        "  query_engine = new_index.as_query_engine(\n",
        "      include_text=True, response_mode=\"tree_summarize\"\n",
        "    )\n",
        "  print(\"Knowledge graph constructed\")\n",
        "  nodes = set()\n",
        "  edges = []\n",
        "\n",
        "  for triplet in new_index.get_triplets():\n",
        "      subject, predicate, obj = triplet\n",
        "      nodes.add(subject)\n",
        "      nodes.add(obj)\n",
        "      edges.append((subject, obj, predicate))\n",
        "  G = nx.DiGraph()\n",
        "  G.add_nodes_from(nodes)\n",
        "  for edge in edges:\n",
        "      G.add_edge(edge[0], edge[1], label=edge[2])\n",
        "\n",
        "  # Draw the graph\n",
        "  pos = nx.spring_layout(G)\n",
        "  nx.draw(G, pos, with_labels=True, node_color='lightblue', font_weight='bold', node_size=3000, edge_color='gray')\n",
        "  edge_labels = nx.get_edge_attributes(G, 'label')\n",
        "  nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "FB4Q7AZWcTnc"
      },
      "outputs": [],
      "source": [
        "# As the knowledge graph construction takes a longer time, and HTTP requests time out shortly, the knowledge graph function is called async\n",
        "import threading\n",
        "import time\n",
        "\n",
        "def run_async_function():\n",
        "    thread = threading.Thread(target=construct_knowledge_graph)\n",
        "    thread.start()\n",
        "    print(\"Sync function has been called\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not run now  : Note: This code block is for testing if the responses are received as expected\n",
        "# Expecting a correct response for this question\n",
        "query_engine = new_index.as_query_engine(\n",
        "    include_text=False, response_mode=\"tree_summarize\"\n",
        ")\n",
        "response = query_engine.query(\n",
        "    \"What is machine learning\",\n",
        ")\n",
        "display(Markdown(f\"{response}\"))\n",
        "# No information about this query will be received as the data doesn't exist in the document\n",
        "response = query_engine.query(\n",
        "    \"What is Jyothi studying\",\n",
        ")\n",
        "display(Markdown(f\"{response}\"))"
      ],
      "metadata": {
        "id": "qQ7XYHH-MvnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "CN4vAWPRu4Ci"
      },
      "outputs": [],
      "source": [
        "def fn_query_engine(question):\n",
        "  global query_engine\n",
        "  query_engine = new_index.as_query_engine(\n",
        "      include_text=False, response_mode=\"tree_summarize\"\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "EXwG5kgyAq1o"
      },
      "outputs": [],
      "source": [
        "# The chatbot accesses these APIs\n",
        "# Creating a FastAPI application\n",
        "from fastapi import FastAPI,Query\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=['*'],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=['*'],\n",
        "    allow_headers=['*'],\n",
        ")\n",
        "\n",
        "@app.get('/')\n",
        "async def root():\n",
        "    return {'hello': 'world'}\n",
        "\n",
        "# Called when the user logs in to the application and wants to talk to the chatbot\n",
        "@app.get('/answer_questions')\n",
        "async def answer_questions(question: str = Query(..., description=\"The question to be answered\")):\n",
        "    query_engine = new_index.as_query_engine(\n",
        "      include_text=False, response_mode=\"tree_summarize\"\n",
        "    )\n",
        "    response = query_engine.query(\n",
        "        question,\n",
        "    )\n",
        "    print(str(response))\n",
        "    return {'question': question, 'response': str(response)}\n",
        "\n",
        "# Get info from the user for the topic to generate a knowledge graph about\n",
        "@app.get('/generate_knowledge_graph')\n",
        "async def generate_knowledge_graph(kg_query: str = Query(..., description=\"Topic to generate the knowledge graph on\")):\n",
        "    print(\"generate knowledge graph\")\n",
        "    results = user_input_kg(kg_query)\n",
        "    print(results)\n",
        "    status = store_extracted_info(results)\n",
        "    print(status)\n",
        "    return {'question': kg_query, 'response': str(status)}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if new_index:  print(\"YES\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMZyZ38GPVZa",
        "outputId": "5d6ee001-3ae8-431d-8595-6369a63d589c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YES\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOe_-kKFAtSU",
        "outputId": "fad6874e-3495-41da-ce62-eabeddaad35c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "URL:  https://5302-34-87-191-170.ngrok-free.app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [233]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generate knowledge graph\n",
            "Google search completed\n",
            "Currently processing https://www.allaboutcircuits.com/news/altera-infuses-ai-into-new-mid-range-fpgas/\n",
            "Skipping https://www.allaboutcircuits.com/news/altera-infuses-ai-into-new-mid-range-fpgas/: 403 Client Error: Forbidden for url: https://www.allaboutcircuits.com/news/altera-infuses-ai-into-new-mid-range-fpgas/\n",
            "Currently processing https://www.intel.com/content/www/us/en/newsroom/news/intel-altera-bring-ai-to-embedded-world.html\n",
            "Currently processing https://www.eetimes.com/embedded-world-2024-sandra-rivera-talks-about-altera-and-ai/\n",
            "Skipping https://www.eetimes.com/embedded-world-2024-sandra-rivera-talks-about-altera-and-ai/: HTTPSConnectionPool(host='www.eetimes.com', port=443): Read timed out. (read timeout=10)\n",
            "Currently processing https://www.linkedin.com/posts/sandra-rivera-6a24291_women4ew-womenintech-wearealtera-activity-7183884756843999232-ZNMo\n",
            "Currently processing https://cfotech.in/story/intel-launches-standalone-fpga-company-to-revolutionise-ai\n",
            "Skipping https://cfotech.in/story/intel-launches-standalone-fpga-company-to-revolutionise-ai: 403 Client Error: Forbidden for url: https://cfotech.in/story/intel-launches-standalone-fpga-company-to-revolutionise-ai\n",
            "+--------------------------------+----------------------------------------------------+\n",
            "|             Title              |                        Text                        |\n",
            "+--------------------------------+----------------------------------------------------+\n",
            "| Intel and Altera Announce Edge | You can easily search the entire Intel.com site in |\n",
            "|  and FPGA Offerings for AI at  |   several ways. You can also try the quick links   |\n",
            "|          Embedded...           |  below to see results for most popular searches.   |\n",
            "|                                |      The browser version you are using is not      |\n",
            "|                                |     recommended for this site.Please consider      |\n",
            "|                                | upgrading to the latest version of your browser by |\n",
            "|                                |   clicking one of the following links. New edge-   |\n",
            "|                                | optimized processors and FPGAs bring AI everywhere |\n",
            "|                                |  across edge computing markets including retail,   |\n",
            "|                                | industrial and healthcare.  April 8, 2024 Contact  |\n",
            "|                                |     Intel PR  Follow Intel Newsroom on social:     |\n",
            "|                                | By  What’s New: Today at Embedded World, Intel and |\n",
            "|                                |   Altera, an Intel Company, announced new edge-    |\n",
            "|                                |    optimized processors, FPGAs and programmable    |\n",
            "|                                |    market-ready solutions extending powerful AI    |\n",
            "|                                |  capabilities into edge computing. These products  |\n",
            "|                                |  will power AI-enabled edge devices applicable to  |\n",
            "|                                | industries across retail, healthcare, industrial,  |\n",
            "|                                |     automotive, defense and aerospace.  What’s     |\n",
            "|                                | New: Today at Embedded World, Intel and Altera, an |\n",
            "|                                |    Intel Company, announced new edge-optimized     |\n",
            "|                                |  processors, FPGAs and programmable market-ready   |\n",
            "|                                | solutions extending powerful AI capabilities into  |\n",
            "|                                |   edge computing. These products will power AI-    |\n",
            "|                                |   enabled edge devices applicable to industries    |\n",
            "|                                | across retail, healthcare, industrial, automotive, |\n",
            "|                                |  defense and aerospace. “This next generation of   |\n",
            "|                                | Intel edge-optimized processors and discrete GPUs  |\n",
            "|                                |     unleashes powerful AI capabilities to help     |\n",
            "|                                |     businesses more seamlessly incorporate AI      |\n",
            "|                                |  alongside compute, media and graphics workloads.  |\n",
            "|                                |     From manufacturing to healthcare, Intel’s      |\n",
            "|                                | extensive edge AI experience and breadth and depth |\n",
            "|                                |    of edge-ready silicon and software help our     |\n",
            "|                                |  customers deliver AI where they need it most for  |\n",
            "|                                |   better business outcomes.”  Why It Matters for   |\n",
            "|                                |    Edge and AI: Why It Matters for Edge and AI:    |\n",
            "|                                |    Intel’s new series of edge-optimized Intel®     |\n",
            "|                                |     Core™ Ultra, Intel® Core™ and Intel Atom®      |\n",
            "|                                |    processors and discrete Intel® Arc™ graphics    |\n",
            "|                                |  processing units (GPUs) will advance innovation   |\n",
            "|                                | for artificial intelligence, visual computing and  |\n",
            "|                                |    media processing – in support of faster and     |\n",
            "|                                | smarter decisions with on-premise edge computing.  |\n",
            "|                                |  Agilex™ 5 FPGAs for mid-range applications with   |\n",
            "|                                | best-in-class performance per watt target a broad  |\n",
            "|                                | set of applications, including video, industrial,  |\n",
            "|                                | robotics, medical and others. Agilex 5 FPGAs with  |\n",
            "|                                |   AI infused into the fabric offer a high level    |\n",
            "|                                | of integration, low latency and improved computing |\n",
            "|                                |  capabilities for intelligent edge applications.   |\n",
            "|                                |   Expanding on Intel’s commitment to bringing AI   |\n",
            "|                                | everywhere, today's announcements utilize built-in |\n",
            "|                                | AI acceleration in the new series of processors to |\n",
            "|                                | power the next generation of edge devices.  Why It |\n",
            "|                                |  Matters for Edge and AI: Why It Matters for Edge  |\n",
            "|                                |    and AI: Intel’s new series of edge-optimized    |\n",
            "|                                |  Intel® Core™ Ultra, Intel® Core™ and Intel Atom®  |\n",
            "|                                |    processors and discrete Intel® Arc™ graphics    |\n",
            "|                                |  processing units (GPUs) will advance innovation   |\n",
            "|                                | for artificial intelligence, visual computing and  |\n",
            "|                                |    media processing – in support of faster and     |\n",
            "|                                | smarter decisions with on-premise edge computing.  |\n",
            "|                                |  Agilex™ 5 FPGAs for mid-range applications with   |\n",
            "|                                | best-in-class performance per watt target a broad  |\n",
            "|                                | set of applications, including video, industrial,  |\n",
            "|                                | robotics, medical and others. Agilex 5 FPGAs with  |\n",
            "|                                |   AI infused into the fabric offer a high level    |\n",
            "|                                | of integration, low latency and improved computing |\n",
            "|                                |  capabilities for intelligent edge applications.   |\n",
            "|                                |   Expanding on Intel’s commitment to bringing AI   |\n",
            "|                                | everywhere, today's announcements utilize built-in |\n",
            "|                                | AI acceleration in the new series of processors to |\n",
            "|                                |   power the next generation of edge devices. An    |\n",
            "|                                | image shows the FPGAi Altera company logo. Altera  |\n",
            "|                                | helps customers achieve their business goals with  |\n",
            "|                                |  new AI capabilities to support high-performance   |\n",
            "|                                |   and mid-range FPGA-based solutions, developer    |\n",
            "|                                |  usability and workload agility. (Credit: Altera,  |\n",
            "|                                |   an Intel Company) An image shows an Intel Atom   |\n",
            "|                                |   processor badge. Intel Atom processors x7000C    |\n",
            "|                                | Series delivers ramped-up processor base frequency |\n",
            "|                                |     in up to eight Efficient-cores. Intel Atom     |\n",
            "|                                |  processors x7000RE Series features built-in deep  |\n",
            "|                                |  learning inference capabilities. (Credit: Intel   |\n",
            "|                                |  Corporation) An image shows an Intel Core Ultra   |\n",
            "|                                |    processor badge. Intel Core Ultra processors    |\n",
            "|                                | combine the Intel Arc GPU and a neural processing  |\n",
            "|                                |   unit (NPU) with LGA socket flexibility into a    |\n",
            "|                                |  simplified system-on-chip (SoC). The new SoC is   |\n",
            "|                                |    designed to enable generative AI (GenAI) and    |\n",
            "|                                | demanding graphics workloads at the edge. (Credit: |\n",
            "|                                |  Intel Corporation) An image shows the Intel Arc   |\n",
            "|                                |  GPU for Edge badge. The Intel® Arc™ GPU for Edge  |\n",
            "|                                |   boosts performance and edge AI capabilities on   |\n",
            "|                                |    legacy Intel Core systems as a discrete GPU,    |\n",
            "|                                |    providing accelerated AI, media and graphics    |\n",
            "|                                |  processing power. (Credit: Intel Corporation) An  |\n",
            "|                                |  image shows an Intel Core processor badge. Intel  |\n",
            "|                                | Core processors combine the GPU power of 13th Gen  |\n",
            "|                                |    Intel Core mobile processors with LGA socket    |\n",
            "|                                |  flexibility to prioritize system scalability and  |\n",
            "|                                |  speed to deployment. (Credit: Intel Corporation)  |\n",
            "|                                |   An image shows the Agilex 5 field programmable   |\n",
            "|                                |      gate array. Agilex 5 FPGAs for mid-range      |\n",
            "|                                |  applications with best-in-class performance per   |\n",
            "|                                | watt target a broad set of applications, including |\n",
            "|                                |  video, industrial, robotics, medical and others.  |\n",
            "|                                |  (Credit: Altera, an Intel Company) Download all   |\n",
            "|                                |  images (ZIP, 2 MB)  Download all images (ZIP, 2   |\n",
            "|                                | MB) How Intel Expands AI to Embedded Edge Devices: |\n",
            "|                                |  Building on its expansive installed base of more  |\n",
            "|                                |   than 90,000 edge deployments, Intel delivers a   |\n",
            "|                                |   wave of edge-optimized processors and GPUs to    |\n",
            "|                                |    power the next generation of AI-enabled edge    |\n",
            "|                                | devices.    Intel Core Ultra processors for edge:  |\n",
            "|                                |  Offering up to 5.02x better image classification  |\n",
            "|                                | inference performance compared to 14th Gen Intel®  |\n",
            "|                                |    Core™ desktop processors,1 Intel Core Ultra     |\n",
            "|                                | processors combine the Intel Arc GPU2 and a neural |\n",
            "|                                | processing unit (NPU)3 with LGA socket flexibility |\n",
            "|                                |  into a simplified system-on-chip (SoC). The new   |\n",
            "|                                |  SoC is designed to enable generative AI (GenAI)   |\n",
            "|                                |  and demanding graphics workloads at the edge for  |\n",
            "|                                |   retail, education, smart cities and industrial   |\n",
            "|                                | customers, including GenAI-enabled kiosk and smart |\n",
            "|                                |     point-of-sale systems in brick-and-mortar      |\n",
            "|                                |  retailers, interactive whiteboards for enhanced   |\n",
            "|                                |  in-classroom experiences and AI vision-enhanced   |\n",
            "|                                | industrial devices for manufacturing and roadside  |\n",
            "|                                | units.  Intel Core processors for edge: Intel Core |\n",
            "|                                |    processors combine the GPU power of 13th Gen    |\n",
            "|                                |   Intel® Core® mobile processors with LGA socket   |\n",
            "|                                |  flexibility to prioritize system scalability and  |\n",
            "|                                |   speed to deployment. This series of processors   |\n",
            "|                                | optimized for the edge offers up to 2.57x greater  |\n",
            "|                                |  graphics performance compared to 13th Gen Intel®  |\n",
            "|                                |  Core™ desktop processors4 by leveraging up to 3   |\n",
            "|                                |   times more graphics execution units alongside    |\n",
            "|                                | performance hybrid architecture with Intel® Thread |\n",
            "|                                | Director5 and an LGA socket-based design offering  |\n",
            "|                                |  customers more edge AI and graphics performance   |\n",
            "|                                |  without sacrificing hardware setup flexibility.   |\n",
            "|                                |  Intel Atom® processors x7000C Series: Intel Atom  |\n",
            "|                                |    processors x7000C Series delivers ramped-up     |\n",
            "|                                | processor base frequency in up to eight Efficient- |\n",
            "|                                |    cores to drive exceptional packet processing    |\n",
            "|                                |      throughput for enterprise networking and      |\n",
            "|                                |      telecommunications devices. This enables      |\n",
            "|                                | telecommunications businesses to use built-in deep |\n",
            "|                                |   learning inference capabilities to support the   |\n",
            "|                                |  detection of zero-day threats, boost packet and   |\n",
            "|                                |  control plane processing for OpenSSL/IPSec using  |\n",
            "|                                |    native instruction sets, and leverage Intel     |\n",
            "|                                | security features to harden networks. Intel Atom®  |\n",
            "|                                |      processors x7000RE Series: Primarily for      |\n",
            "|                                | industrial and manufacturing end users, Intel Atom |\n",
            "|                                |  processors x7000RE Series features built-in deep  |\n",
            "|                                |    learning inference capabilities and up to 32    |\n",
            "|                                |  graphics execution units in a ruggedized, power-  |\n",
            "|                                | efficient 6W-12W BGA package offering up to 9.83x  |\n",
            "|                                |   image classification performance compared with   |\n",
            "|                                |   Intel Atom processors x6000RE Series6. The new   |\n",
            "|                                |    processor supports fanless designs to enable    |\n",
            "|                                |  Industry 4.0 automation for key use cases in AI-  |\n",
            "|                                |  automated tending, warehouse AMR, in-line visual  |\n",
            "|                                |   inspection for quality control and ruggedized    |\n",
            "|                                |   industrial PC scenarios.     Additionally, the   |\n",
            "|                                |  Intel® Arc™ GPU for Edge boosts performance and   |\n",
            "|                                | edge AI capabilities on legacy Intel Core systems  |\n",
            "|                                |  as a discrete GPU providing accelerated AI, and   |\n",
            "|                                |   media and graphics processing power. Intel Arc   |\n",
            "|                                |  GPUs also eliminate vendor lock-in with an open,  |\n",
            "|                                | standards-based software stack to offer choice and |\n",
            "|                                |   flexibility when building high-performance AI    |\n",
            "|                                |     applications and solutions.  How Altera’s      |\n",
            "|                                | Portfolio Will Accelerate Customer AI Innovations: |\n",
            "|                                |   Following the FPGA Vision Webcast in February,   |\n",
            "|                                |  Altera announced additional updates to its FPGA   |\n",
            "|                                |  portfolio, providing flexible solutions to help   |\n",
            "|                                | customers solve their challenges from the cloud to |\n",
            "|                                | network to the intelligent edge. “We announced the |\n",
            "|                                |  launch of the new Altera brand with the goal of   |\n",
            "|                                | bringing leading technologies and innovations more |\n",
            "|                                | quickly to the FPGA market. Today, we are excited  |\n",
            "|                                |  about the next phase in our 10-plus year journey  |\n",
            "|                                |   delivering flexible AI solutions,” said Sandra   |\n",
            "|                                | Rivera, Altera chief executive officer. “Altera is |\n",
            "|                                |   leading the new FPGAi era by tightly coupling    |\n",
            "|                                |    programmability with tensor capabilities and    |\n",
            "|                                |   infusing FPGA and AI tools for a best-in-class   |\n",
            "|                                |   developer experience. Agilex 5, the first FPGA   |\n",
            "|                                |   with AI-infused throughout the fabric, is now    |\n",
            "|                                |  broadly available.” Altera Leads the New Era of   |\n",
            "|                                |    FPGAi: Altera helps customers achieve their     |\n",
            "|                                | business goals with new AI capabilities to support |\n",
            "|                                |     high-performance and mid-range FPGA-based      |\n",
            "|                                |    solutions, developer usability and workload     |\n",
            "|                                | agility. FPGA AI Suite adds support for Agilex™ 5  |\n",
            "|                                |  SoC FPGAs. The AI tool flow allows developers to  |\n",
            "|                                | use existing and popular AI frameworks, along with |\n",
            "|                                |    the Intel® OpenVINO™ toolkit and the FPGA AI    |\n",
            "|                                |   Suite, to create AI intellectual property (IP)   |\n",
            "|                                | blocks and easily drop them into the FPGA design.  |\n",
            "|                                | More information is available at the FPGA AI Suite |\n",
            "|                                |  website.    Performance per Watt Leader Agilex 5  |\n",
            "|                                |   SoC FPGAs Broadly Available: Agilex 5 devices,   |\n",
            "|                                |     with best-in-class AI and up to 2x better      |\n",
            "|                                | performance per watt versus competing 7 nanometer  |\n",
            "|                                |  FPGAs7, are designed to deliver high performance  |\n",
            "|                                |  with lower power in a modern SoC subsystem with   |\n",
            "|                                |    small form factor package options, allowing     |\n",
            "|                                |  customers and developers to add AI capability to  |\n",
            "|                                |   their products without the need for dedicated    |\n",
            "|                                |     accelerators. Geared toward a broad set of     |\n",
            "|                                |    embedded applications, Agilex 5 devices and     |\n",
            "|                                |    development kits are broadly available with     |\n",
            "|                                |       Quartus® Prime software support. Broad       |\n",
            "|                                | availability also includes support by a large and  |\n",
            "|                                |    growing list of ecosystem partners providing    |\n",
            "|                                |  additional boards, system-on-modules (SOMs), IP   |\n",
            "|                                | and various value-added services. More information |\n",
            "|                                |    about Agilex 5 devices, including technical     |\n",
            "|                                |   details, is available at the Agilex 5 SoC FPGA   |\n",
            "|                                |  website. Unleash the Power of Agilex 5 E-Series   |\n",
            "|                                | Devices with Quartus Prime Pro Edition S/W Version |\n",
            "|                                | 24.1: The latest version of Altera’s cutting-edge  |\n",
            "|                                | software is available for download, offering free  |\n",
            "|                                |  access to the latest Agilex 5 E-Series SoC FPGAs  |\n",
            "|                                |    and selected complementary IP cores. Quartus    |\n",
            "|                                | offers a streamlined experience for an IP-centric  |\n",
            "|                                |   design flow, configurable example designs and    |\n",
            "|                                |  unprecedented capabilities including a powerful   |\n",
            "|                                | new Agilex 5 SoC subsystem (hard-processor system  |\n",
            "|                                | featuring dual-core Arm Cortex A76, dual-core Arm  |\n",
            "|                                |  Cortex A55 processors and various peripherals).   |\n",
            "|                                | This new SoC subsystem is also supported by third- |\n",
            "|                                |  party tools recently updated to support Agilex 5  |\n",
            "|                                |   devices. More information is available at the    |\n",
            "|                                |  Quartus Prime Pro website. Portfolio Breadth and  |\n",
            "|                                |  Industry-Leading Longevity: Altera continues to   |\n",
            "|                                |   deliver a broad portfolio, including industry-   |\n",
            "|                                | leading longevity with selected MAX® and Cyclone®  |\n",
            "|                                |  cost- and power-optimized product families’ life  |\n",
            "|                                |     cycles extended to 2040 and later, further     |\n",
            "|                                | improving supply chain resilience. Future Agilex™  |\n",
            "|                                |   3 devices, coming soon, will expand the Agilex   |\n",
            "|                                | portfolio to deliver even greater breadth.    Why  |\n",
            "|                                |    It Matters for Altera FPGAs: In an era where    |\n",
            "|                                | technological advancements are integral to staying |\n",
            "|                                | competitive, Intel’s new edge-optimized processors |\n",
            "|                                | and solutions deliver the capabilities enterprises |\n",
            "|                                | need to innovate, be efficient and improve time to |\n",
            "|                                |    market. Altera delivers flexibility and re-     |\n",
            "|                                |    programmability to accelerate innovators by     |\n",
            "|                                |    providing easy-to-design and easy-to-deploy     |\n",
            "|                                |      leadership programmable solutions. These      |\n",
            "|                                |  processors, FPGAs and associated solutions allow  |\n",
            "|                                |  enterprises to leverage the tremendous amount of  |\n",
            "|                                | data generated at the edge to deploy sophisticated |\n",
            "|                                | embedded AI devices across a variety of industries |\n",
            "|                                |     to streamline operations, improve customer     |\n",
            "|                                |    satisfaction and incorporate advanced visual    |\n",
            "|                                | workloads.  “The FPGA AI Suite from Altera allowed |\n",
            "|                                | the Tiami team to rapidly incorporate our IP into  |\n",
            "|                                |    an intricate digital signal processing (DSP)    |\n",
            "|                                |   pipeline,” said Amitav Mukherjee, CEO at Tiami   |\n",
            "|                                |   Networks. “This significantly reduced the time   |\n",
            "|                                |   required to integrate AI capabilities with 5G    |\n",
            "|                                | signal processing from an estimated six months to  |\n",
            "|                                |   just eight weeks. Our engineering team clearly   |\n",
            "|                                |  recognized the value proposition offered by the   |\n",
            "|                                |  FPGA in preprocessing wireless signals received   |\n",
            "|                                |     from the antenna and performing real-time      |\n",
            "|                                |  inference, resulting in a successful demo.” More  |\n",
            "|                                |   Context: Intel Core Ultra Processors for Edge    |\n",
            "|                                | (PDF) | Intel Processers for the Edge | Intel Arc  |\n",
            "|                                |   GPU for Edge |  Intel Launches Altera, Its New   |\n",
            "|                                |  Standalone FPGA Company  How Intel Expands AI to  |\n",
            "|                                |  Embedded Edge Devices: Building on its expansive  |\n",
            "|                                |      installed base of more than 90,000 edge       |\n",
            "|                                |    deployments, Intel delivers a wave of edge-     |\n",
            "|                                |  optimized processors and GPUs to power the next   |\n",
            "|                                |     generation of AI-enabled edge devices.         |\n",
            "|                                | Additionally, the Intel® Arc™ GPU for Edge boosts  |\n",
            "|                                |   performance and edge AI capabilities on legacy   |\n",
            "|                                |   Intel Core systems as a discrete GPU providing   |\n",
            "|                                | accelerated AI, and media and graphics processing  |\n",
            "|                                | power. Intel Arc GPUs also eliminate vendor lock-  |\n",
            "|                                | in with an open, standards-based software stack to |\n",
            "|                                |  offer choice and flexibility when building high-  |\n",
            "|                                |  performance AI applications and solutions.  How   |\n",
            "|                                |   Altera’s Portfolio Will Accelerate Customer AI   |\n",
            "|                                | Innovations: Following the FPGA Vision Webcast in  |\n",
            "|                                |  February, Altera announced additional updates to  |\n",
            "|                                |  its FPGA portfolio, providing flexible solutions  |\n",
            "|                                | to help customers solve their challenges from the  |\n",
            "|                                |   cloud to network to the intelligent edge. “We    |\n",
            "|                                | announced the launch of the new Altera brand with  |\n",
            "|                                |   the goal of bringing leading technologies and    |\n",
            "|                                |    innovations more quickly to the FPGA market.    |\n",
            "|                                | Today, we are excited about the next phase in our  |\n",
            "|                                |    10-plus year journey delivering flexible AI     |\n",
            "|                                |    solutions,” said Sandra Rivera, Altera chief    |\n",
            "|                                |   executive officer. “Altera is leading the new    |\n",
            "|                                | FPGAi era by tightly coupling programmability with |\n",
            "|                                | tensor capabilities and infusing FPGA and AI tools |\n",
            "|                                |  for a best-in-class developer experience. Agilex  |\n",
            "|                                |  5, the first FPGA with AI-infused throughout the  |\n",
            "|                                |  fabric, is now broadly available.” Altera Leads   |\n",
            "|                                |    the New Era of FPGAi: Altera helps customers    |\n",
            "|                                |      achieve their business goals with new AI      |\n",
            "|                                | capabilities to support high-performance and mid-  |\n",
            "|                                |  range FPGA-based solutions, developer usability   |\n",
            "|                                |  and workload agility. FPGA AI Suite adds support  |\n",
            "|                                |  for Agilex™ 5 SoC FPGAs. The AI tool flow allows  |\n",
            "|                                |     developers to use existing and popular AI      |\n",
            "|                                |    frameworks, along with the Intel® OpenVINO™     |\n",
            "|                                |    toolkit and the FPGA AI Suite, to create AI     |\n",
            "|                                | intellectual property (IP) blocks and easily drop  |\n",
            "|                                |   them into the FPGA design. More information is   |\n",
            "|                                | available at the FPGA AI Suite website.     Why It |\n",
            "|                                |     Matters for Altera FPGAs: In an era where      |\n",
            "|                                | technological advancements are integral to staying |\n",
            "|                                | competitive, Intel’s new edge-optimized processors |\n",
            "|                                | and solutions deliver the capabilities enterprises |\n",
            "|                                | need to innovate, be efficient and improve time to |\n",
            "|                                |    market. Altera delivers flexibility and re-     |\n",
            "|                                |    programmability to accelerate innovators by     |\n",
            "|                                |    providing easy-to-design and easy-to-deploy     |\n",
            "|                                |      leadership programmable solutions. These      |\n",
            "|                                |  processors, FPGAs and associated solutions allow  |\n",
            "|                                |  enterprises to leverage the tremendous amount of  |\n",
            "|                                | data generated at the edge to deploy sophisticated |\n",
            "|                                | embedded AI devices across a variety of industries |\n",
            "|                                |     to streamline operations, improve customer     |\n",
            "|                                |    satisfaction and incorporate advanced visual    |\n",
            "|                                | workloads.  “The FPGA AI Suite from Altera allowed |\n",
            "|                                | the Tiami team to rapidly incorporate our IP into  |\n",
            "|                                |    an intricate digital signal processing (DSP)    |\n",
            "|                                |   pipeline,” said Amitav Mukherjee, CEO at Tiami   |\n",
            "|                                |   Networks. “This significantly reduced the time   |\n",
            "|                                |   required to integrate AI capabilities with 5G    |\n",
            "|                                | signal processing from an estimated six months to  |\n",
            "|                                |   just eight weeks. Our engineering team clearly   |\n",
            "|                                |  recognized the value proposition offered by the   |\n",
            "|                                |  FPGA in preprocessing wireless signals received   |\n",
            "|                                |     from the antenna and performing real-time      |\n",
            "|                                |  inference, resulting in a successful demo.” More  |\n",
            "|                                |   Context: Intel Core Ultra Processors for Edge    |\n",
            "|                                | (PDF) | Intel Processers for the Edge | Intel Arc  |\n",
            "|                                |   GPU for Edge |  Intel Launches Altera, Its New   |\n",
            "|                                | Standalone FPGA Company The Small Print:  Altera,  |\n",
            "|                                |    the Altera logo, and other Altera marks are     |\n",
            "|                                | trademarks of Altera.   Other names and brands may |\n",
            "|                                |      be claimed as the property of others. 1       |\n",
            "|                                |   Performance varies by use, configuration, and    |\n",
            "|                                |            other factors. Learn more at            |\n",
            "|                                |   intel.com/processorclaims: Intel® Core™ Ultra    |\n",
            "|                                |   processors, Edge. Results may vary.   2 Intel®   |\n",
            "|                                |   Arc™ GPU is only available on select H-Series,   |\n",
            "|                                | Intel® Core™ Ultra processor-powered systems with  |\n",
            "|                                |  at least 16GB of system memory in a dual-channel  |\n",
            "|                                |  configuration. OEM enablement is required; check  |\n",
            "|                                |    with OEM for system configuration details.      |\n",
            "|                                |  3 Intel® AI Boost enablement limited at launch.   |\n",
            "|                                |  4 Performance varies by use, configuration, and   |\n",
            "|                                |            other factors. Learn more at            |\n",
            "|                                |         intel.com/processorclaims: Intel®          |\n",
            "|                                |     Core™ processors, Edge. Results may vary.      |\n",
            "|                                |  5 Support for Intel® Thread Director is expected  |\n",
            "|                                |   in Windows 11 IoT Enterprise LTSC and Linux  6   |\n",
            "|                                |   Performance varies by use, configuration, and    |\n",
            "|                                |            other factors. Learn more at            |\n",
            "|                                | intel.com/processorclaims: Intel Atom® Processors. |\n",
            "|                                | Results may vary.  7 FPGA performance per watt:  h |\n",
            "|                                | ttps://edc.intel.com/content/www/us/en/products/pe |\n",
            "|                                |   rformance/benchmarks/agilex-fpga/. Results may   |\n",
            "|                                |   vary.    The Small Print:  Altera, the Altera    |\n",
            "|                                |   logo, and other Altera marks are trademarks of   |\n",
            "|                                | Altera.   Other names and brands may be claimed as |\n",
            "|                                |  the property of others. 1 Performance varies by   |\n",
            "|                                | use, configuration, and other factors. Learn more  |\n",
            "|                                |  at intel.com/processorclaims: Intel® Core™ Ultra  |\n",
            "|                                |   processors, Edge. Results may vary.   2 Intel®   |\n",
            "|                                |   Arc™ GPU is only available on select H-Series,   |\n",
            "|                                | Intel® Core™ Ultra processor-powered systems with  |\n",
            "|                                |  at least 16GB of system memory in a dual-channel  |\n",
            "|                                |  configuration. OEM enablement is required; check  |\n",
            "|                                |    with OEM for system configuration details.      |\n",
            "|                                |  3 Intel® AI Boost enablement limited at launch.   |\n",
            "|                                |  4 Performance varies by use, configuration, and   |\n",
            "|                                |            other factors. Learn more at            |\n",
            "|                                |         intel.com/processorclaims: Intel®          |\n",
            "|                                |     Core™ processors, Edge. Results may vary.      |\n",
            "|                                |  5 Support for Intel® Thread Director is expected  |\n",
            "|                                |   in Windows 11 IoT Enterprise LTSC and Linux  6   |\n",
            "|                                |   Performance varies by use, configuration, and    |\n",
            "|                                |            other factors. Learn more at            |\n",
            "|                                | intel.com/processorclaims: Intel Atom® Processors. |\n",
            "|                                | Results may vary.  7 FPGA performance per watt:  h |\n",
            "|                                | ttps://edc.intel.com/content/www/us/en/products/pe |\n",
            "|                                |   rformance/benchmarks/agilex-fpga/. Results may   |\n",
            "|                                | vary.    Altera,  Internet of Things,  Artificial  |\n",
            "|                                | Intelligence  About Intel Intel (Nasdaq: INTC) is  |\n",
            "|                                |    an industry leader, creating world-changing     |\n",
            "|                                |    technology that enables global progress and     |\n",
            "|                                |    enriches lives. Inspired by Moore’s Law, we     |\n",
            "|                                |    continuously work to advance the design and     |\n",
            "|                                |  manufacturing of semiconductors to help address   |\n",
            "|                                |  our customers’ greatest challenges. By embedding  |\n",
            "|                                | intelligence in the cloud, network, edge and every |\n",
            "|                                | kind of computing device, we unleash the potential |\n",
            "|                                | of data to transform business and society for the  |\n",
            "|                                |  better. To learn more about Intel’s innovations,  |\n",
            "|                                |  go to newsroom.intel.com and intel.com. © Intel   |\n",
            "|                                | Corporation. Intel, the Intel logo and other Intel |\n",
            "|                                |  marks are trademarks of Intel Corporation or its  |\n",
            "|                                |    subsidiaries. Other names and brands may be     |\n",
            "|                                |      claimed as the property of others. Intel      |\n",
            "|                                |     technologies may require enabled hardware,     |\n",
            "|                                |  software or service activation. // No product or  |\n",
            "|                                | component can be absolutely secure. // Your costs  |\n",
            "|                                |   and results may vary. // Performance varies by   |\n",
            "|                                |  use, configuration and other factors. // See our  |\n",
            "|                                |  complete legal Notices and Disclaimers. // Intel  |\n",
            "|                                |    is committed to respecting human rights and     |\n",
            "|                                |    avoiding causing or contributing to adverse     |\n",
            "|                                | impacts on human rights. See Intel’s Global Human  |\n",
            "|                                |  Rights Principles. Intel’s products and software  |\n",
            "|                                | are intended only to be used in applications that  |\n",
            "|                                |  do not cause or contribute to adverse impacts on  |\n",
            "|                                |                   human rights.                    |\n",
            "|   Sandra Rivera on LinkedIn:   |                        Agree & Join LinkedIn       |\n",
            "|     #women4ew #womenintech     | By clicking Continue to join or sign in, you agree |\n",
            "| #wearealtera #ai | 13 comments |  to LinkedIn‚Äôs User Agreement, Privacy Policy,   |\n",
            "|                                | and Cookie Policy.      A great #women4ew event at |\n",
            "|                                |     embedded world Exhibition&Conference today     |\n",
            "|                                |   covering various topics from addressing gender   |\n",
            "|                                |  bias in AI algorithms to discussing the critical  |\n",
            "|                                |  role diversity plays in innovation. At Altera we  |\n",
            "|                                | create a culture that positively impacts the work  |\n",
            "|                                |  experience and development of women. So, it has   |\n",
            "|                                |  filled me with hope and optimism to see so many   |\n",
            "|                                |   women in this industry come together to share    |\n",
            "|                                |   their experience and pave the way for the next   |\n",
            "|                                | generation of #womenintech #WeAreAltera #AI  Loved |\n",
            "|                                |   the insights on gender bias & diversity in AI!   |\n",
            "|                                |  Plato said wisdom begins in wonder, reminding us  |\n",
            "|                                |  that diversity fuels innovation by widening our   |\n",
            "|                                | perspectives üåü #womenintech #innovation  I love |\n",
            "|                                | the topic - \"how diversity can impact innovation\"  |\n",
            "|                                | reminded me of why the military did not put all of |\n",
            "|                                | the same \"Human Dynamic\" people together on teams  |\n",
            "|                                |  ( higher injury rates) and Margaret Heffernan's   |\n",
            "|                                | super chickens TED talk! Martin Curley and I will  |\n",
            "|                                | release our second innovation book in Q4 \"Managing |\n",
            "|                                | Innovation in a Digital World\"- we will send you a |\n",
            "|                                |     copy!  Financial Cultural Operational and      |\n",
            "|                                |    Technical Consultant - Alpha Sense Financial    |\n",
            "|                                | Consulting Here's a remedy to the tribal feminism  |\n",
            "|                                |    agenda...  The solution is to unite around a    |\n",
            "|                                |    common set of principles and values, and the    |\n",
            "|                                |      Gordon Moore ethos and Grove Egalitarian      |\n",
            "|                                |   Meritocracy.    Glad to see Pat pushing this;    |\n",
            "|                                | Will you join him Sandra Rivera and create the One |\n",
            "|                                | Culture Bob Swan initiated.    There needs to be a |\n",
            "|                                |  lot of follow through.   What your espousing is   |\n",
            "|                                |  antithetical to good solid ethics and practices;  |\n",
            "|                                | don't you think?  https://www.linkedin.com/article |\n",
            "|                                |   /edit/7117624932322185216/   Thank you, Sandra   |\n",
            "|                                |      Rivera, for being an incredible part of       |\n",
            "|                                |  #women4ew!¬†üí™  We are absolutely honoured to   |\n",
            "|                                |      have such amazing women like you in the       |\n",
            "|                                |   #embeddedworld! Assembly Test Manufacturing GM   |\n",
            "|                                |  Communications & Chief of Staff Support | Senior  |\n",
            "|                                |  Technical Leader | IDM 2.0 & Foundry Programs |   |\n",
            "|                                |    Lean Six Sigma Blackbelt | Multicultural ERG    |\n",
            "|                                |  Alliance Chair at Intel Corporation This is way   |\n",
            "|                                |   too important thank you for being a leader in    |\n",
            "|                                |  this. Bias of any kind in AI algorithms at this   |\n",
            "|                                |     critical juncture of machine learning is a     |\n",
            "|                                |   continuation of status quo, which is not good    |\n",
            "|                                |  enough. Change can only happen with real actions  |\n",
            "|                                |  beyond intentions. Thanks for making it real and  |\n",
            "|                                |  hearing, supporting and hopefully responding to   |\n",
            "|                                |   these issues. Digital Marketing | Social Media   |\n",
            "|                                |      Management | Content Creation It's truly      |\n",
            "|                                |    empowering to see initiatives like #women4ew    |\n",
            "|                                |    fostering discussions on crucial topics like    |\n",
            "|                                | gender bias in AI and the importance of diversity  |\n",
            "|                                |  in innovation.   Great to see you pushing this.   |\n",
            "|                                | It's really needed and hitting a chord. I know of  |\n",
            "|                                |  one tech startup that had 10 men originally with  |\n",
            "|                                |  no women. Now it's up to 22 with 12 women and 10  |\n",
            "|                                |    men. But web talks are still all men. I help    |\n",
            "|                                | ambitious leaders build strong Executive Presence  |\n",
            "|                                |  so that they get rapid career growth and coveted  |\n",
            "|                                |     CXO roles I Executive & Leadership Coach I     |\n",
            "|                                |    Learning and Development | Training | Talent    |\n",
            "|                                |   Management That's fantastic to hear about your   |\n",
            "|                                |  experience! It's encouraging to see women coming  |\n",
            "|                                |  together to support each other and advocate for   |\n",
            "|                                |  positive change. Financial Cultural Operational   |\n",
            "|                                |  and Technical Consultant - Alpha Sense Financial  |\n",
            "|                                | Consulting A picture of true unity and diversity.  |\n",
            "|                                |     A place where diverse talents thinking and     |\n",
            "|                                |    experience makes the best and highest use of    |\n",
            "|                                |  scarce Human Resources...      The Gordon Moore   |\n",
            "|                                | ethos of Intels first 3 decades was a place where  |\n",
            "|                                |   everyone rallied around a common purpose and a   |\n",
            "|                                |     shared sense of identity. Solving digital      |\n",
            "|                                |  challenges for U.S companies @ RKTech | Dreamer   |\n",
            "|                                | who does @ Rikkeisoft | Forbes Tech Council Member |\n",
            "|                                |    Kudos to Altera for fostering a culture that    |\n",
            "|                                | supports and develops women in the tech industry!  |\n",
            "|                                |         To view or add a comment, sign in          |\n",
            "|                                |    Financial Cultural Operational and Technical    |\n",
            "|                                |   Consultant - Alpha Sense Financial Consulting    |\n",
            "|                                |  Here's a remedy to the tribal feminism agenda...  |\n",
            "|                                |  The solution is to unite around a common set of   |\n",
            "|                                | principles and values, and the Gordon Moore ethos  |\n",
            "|                                | and Grove Egalitarian Meritocracy.    Glad to see  |\n",
            "|                                | Pat pushing this;  Will you join him Sandra Rivera |\n",
            "|                                |   and create the One Culture Bob Swan initiated.   |\n",
            "|                                | There needs to be a lot of follow through.   What  |\n",
            "|                                |    your espousing is antithetical to good solid    |\n",
            "|                                |       ethics and practices; don't you think?       |\n",
            "|                                |   https://lnkd.in/gg6wt2fU  Here's our pitch for   |\n",
            "|                                | Intel to live out the true spirit of the Open Door |\n",
            "|                                |  culture, and regain its position as the cultural  |\n",
            "|                                |        standard bearer for Silicon Valley.         |\n",
            "|                                |  https://lnkd.in/gbckTSTV A great #women4ew event  |\n",
            "|                                |   at embedded world Exhibition&Conference today    |\n",
            "|                                |   covering various topics from addressing gender   |\n",
            "|                                |  bias in AI algorithms to discussing the critical  |\n",
            "|                                |  role diversity plays in innovation. At Altera we  |\n",
            "|                                | create a culture that positively impacts the work  |\n",
            "|                                |  experience and development of women. So, it has   |\n",
            "|                                |  filled me with hope and optimism to see so many   |\n",
            "|                                |   women in this industry come together to share    |\n",
            "|                                |   their experience and pave the way for the next   |\n",
            "|                                |    generation of #womenintech #WeAreAltera #AI     |\n",
            "|                                |         To view or add a comment, sign in          |\n",
            "|                                |  1,230 followers              Empowering Women in  |\n",
            "|                                | AI: A Journey of Inclusivity & Innovation üöÄ  At |\n",
            "|                                |       Resonant Consulting, we believe in the       |\n",
            "|                                |  transformative power of artificial intelligence   |\n",
            "|                                |    (AI) and its potential to enrich lives when     |\n",
            "|                                |   inclusivity is at the forefront.   Our latest    |\n",
            "|                                |   carousel celebrates the journey towards gender   |\n",
            "|                                | inclusivity in AI, spotlighting the essential role |\n",
            "|                                | of male allies and the untapped potential of women |\n",
            "|                                |  in shaping the future of technology. üåü  We're  |\n",
            "|                                |      calling on everyone, especially our male      |\n",
            "|                                |  counterparts, to join us in this movement. Your   |\n",
            "|                                |   support is crucial in creating an environment    |\n",
            "|                                |    where women can excel and contribute to AI's    |\n",
            "|                                |  limitless possibilities. Together, let's ensure   |\n",
            "|                                |    the AI journey is inclusive, empowering, and    |\n",
            "|                                |   beneficial for all. Dive into our carousel to    |\n",
            "|                                | learn more and be part of the change.   #WomenInAI |\n",
            "|                                |   #InclusiveTech #ResonantConsulting #WomenInAI    |\n",
            "|                                |  #InclusiveAI #AIForAll #GenderInclusivityInTech   |\n",
            "|                                |  #EmpowerHerAI #AIInnovationForAll #DiversityInAI  |\n",
            "|                                |         #FutureIsFemaleAI #MaleAlliesForAI         |\n",
            "|                                |  #EmpoweringWomenInTech #TechForGood #AIEquality   |\n",
            "|                                |         To view or add a comment, sign in          |\n",
            "|                                |  100,559 followers              Generative AI is   |\n",
            "|                                | rapidly transforming the world as we know it, with |\n",
            "|                                |  C-suite executives anticipating that nearly half  |\n",
            "|                                |   of workers on average will require reskilling    |\n",
            "|                                | within the next three years.  A recent BCG report  |\n",
            "|                                | underscores that senior women in tech are leading  |\n",
            "|                                |     the way in #GenAI adoption, utilizing the      |\n",
            "|                                |  #technology at rates 14 percentage points higher  |\n",
            "|                                |  than their male counterparts. However, women in   |\n",
            "|                                |  non-technical roles and junior women across all   |\n",
            "|                                | functions are not keeping pace.  What drives these |\n",
            "|                                |  gender disparities in GenAI adoption and how can  |\n",
            "|                                |          leaders narrow the gap? Find out          |\n",
            "|                                |  here:¬†https://on.bcg.com/4b98ld0 #GenerativeAI   |\n",
            "|                                | #WomenInTech #ArtificialIntelligence           To  |\n",
            "|                                |           view or add a comment, sign in           |\n",
            "|                                | Digital Content Manager | Strategist | Gen AI | Ex |\n",
            "|                                |  Adani Digital Labs, Ogilvy, Wunderman Thompson,   |\n",
            "|                                |        FCB | Social Stars Gold, Digies Gold        |\n",
            "|                                |  This research says senior managers are adopting   |\n",
            "|                                | Gen AI fast. But why don't I see this happening in |\n",
            "|                                |  advertising and marketing? I hear people talking  |\n",
            "|                                |   about using AI and individuals flaunting their   |\n",
            "|                                |   knwoledge about it. But no effort to make AI a   |\n",
            "|                                |  part of daily jobs. Will this change? Hopefully,  |\n",
            "|                                |  it will trickle down from the senior managers to  |\n",
            "|                                | their teams soon enough.                  100,559  |\n",
            "|                                |  followers              Generative AI is rapidly   |\n",
            "|                                | transforming the world as we know it, with C-suite |\n",
            "|                                |    executives anticipating that nearly half of     |\n",
            "|                                | workers on average will require reskilling within  |\n",
            "|                                |     the next three years.  A recent BCG report     |\n",
            "|                                | underscores that senior women in tech are leading  |\n",
            "|                                |     the way in #GenAI adoption, utilizing the      |\n",
            "|                                |  #technology at rates 14 percentage points higher  |\n",
            "|                                |  than their male counterparts. However, women in   |\n",
            "|                                |  non-technical roles and junior women across all   |\n",
            "|                                | functions are not keeping pace.  What drives these |\n",
            "|                                |  gender disparities in GenAI adoption and how can  |\n",
            "|                                |          leaders narrow the gap? Find out          |\n",
            "|                                |  here:¬†https://on.bcg.com/4b98ld0 #GenerativeAI   |\n",
            "|                                | #WomenInTech #ArtificialIntelligence           To  |\n",
            "|                                |           view or add a comment, sign in           |\n",
            "|                                |  Global Leader - People & Organization Practice,   |\n",
            "|                                |   Senior Partner and Managing Director at Boston   |\n",
            "|                                |     Consulting Group (BCG)              As we      |\n",
            "|                                |  commemorate International Women‚Äôs Day, it's a   |\n",
            "|                                |     moment of reflection on our journey and a      |\n",
            "|                                | celebration of progress in the realm of technology |\n",
            "|                                | and leadership. I'm proud to share a glimpse into  |\n",
            "|                                |  @BCG‚Äôs latest report on GenAI‚Äôs integration   |\n",
            "|                                |   within the tech sector highlighting promising    |\n",
            "|                                | trends in gender diversity.     This report isn't  |\n",
            "|                                | just numbers; it's a narrative of change. It shows |\n",
            "|                                |    that women in senior tech roles are not just    |\n",
            "|                                |   pioneering the adoption of GenAI, but they are   |\n",
            "|                                | setting the pace, outperforming male counterparts  |\n",
            "|                                |     in GenAI adoption by 14 percentage points.     |\n",
            "|                                | Despite these gains, we acknowledge the persisting |\n",
            "|                                |  obstacles women continue to face. Bridging this   |\n",
            "|                                |   adoption gap is not just a tech issue; it's a    |\n",
            "|                                | business priority that demands a concerted effort  |\n",
            "|                                | across all levels of an organization.    Thank you |\n",
            "|                                | to my colleagues who drove this research: @Neveen  |\n",
            "|                                |   Awad, @Maria Barisano, @Adriana Dahik, @Julie    |\n",
            "|                                |   Bedard, @Uche Monu, and @Gunjan Mundhra. Their   |\n",
            "|                                | dedication echoes our shared mission‚Äîto build a  |\n",
            "|                                | culture where every woman's potential is realized, |\n",
            "|                                |    and their contributions are valued.    Let's    |\n",
            "|                                |   commit to the advancement of women and build a   |\n",
            "|                                |          more inclusive future together.           |\n",
            "|                                | #InternationalWomensday #GenerativeAI #WomeninTech |\n",
            "|                                |         To view or add a comment, sign in          |\n",
            "|                                |   3,074 followers              the vital role of   |\n",
            "|                                |  women in Artificial Intelligence (AI)! üåü Why   |\n",
            "|                                |  Female Representation in AI Matters: 1. Diverse   |\n",
            "|                                |     Perspectives 2. Ethical Considerations 3.      |\n",
            "|                                |   Inclusive Design 4. Inspiration and Mentorship   |\n",
            "|                                | Don't miss this chance to connect with AI experts  |\n",
            "|                                |      and innovators. #WomenInAI #AIInnovation      |\n",
            "|                                |  #womenempowerment #gwf23                   3,074  |\n",
            "|                                | followers              üì£ Exciting News! GLOBAL  |\n",
            "|                                |     WOMEN FORUM (GWF) Welcomes New Supporter:      |\n",
            "|                                |   International Group of Artificial Intelligence   |\n",
            "|                                |     highlighting the crucial role of women in      |\n",
            "|                                |  #ArtificialIntelligence.  Join us on Nov 15th in  |\n",
            "|                                | Berlin as we empower female #AI innovators, break  |\n",
            "|                                | gender barriers, and shape ethical AI. Let's drive |\n",
            "|                                |  the AI industry toward inclusivity and progress!  |\n",
            "|                                | Be part of the happening: https://lnkd.in/eAe4Y_KG |\n",
            "|                                |    Dr. Jassim Haji #WomenInAI #DiversityInTech     |\n",
            "|                                | #womeninstem #womenintechnology #womenempowerment  |\n",
            "|                                | #gwf23           To view or add a comment, sign in |\n",
            "|                                |     75 followers              AI for Women is      |\n",
            "|                                |    launching a brand new website - We are now a    |\n",
            "|                                |   professional networking platform for women AI    |\n",
            "|                                |  enthusiasts! The objective of this website is to  |\n",
            "|                                | promote networking among like-minded women who can |\n",
            "|                                | inspire, mentor, and help one another.   As a part |\n",
            "|                                | of the pre-launch campaign, I have decided to do a |\n",
            "|                                |  deep dive into how we can achieve equality in AI  |\n",
            "|                                | for women. I will be sharing my findings over the  |\n",
            "|                                |  next 3 days in the form of blog posts.   Today's  |\n",
            "|                                |        article talks about 'Gender Bias and        |\n",
            "|                                |        Stereotyping'. You can find it here:        |\n",
            "|                                |  https://lnkd.in/g3me3upH  Do you agree with the   |\n",
            "|                                |  article? Have you experienced / overcome similar  |\n",
            "|                                | challenges? Feel free to share your thoughts! üñã |\n",
            "|                                |  #AI #GenerativeAI #WomenEmpowerment #AIforWomen   |\n",
            "|                                | #WomeninAI #WomeninTech #WomeninSTEM #DataScience  |\n",
            "|                                |         To view or add a comment, sign in          |\n",
            "|                                |    Jubilant Pharmova | Former BCG | Former Egon    |\n",
            "|                                | Zehnder              This #InternationalWomensDay  |\n",
            "|                                |    is all about inspiring inclusion, and #GenAI    |\n",
            "|                                |  adoption holds tremendous opportunity.    A new   |\n",
            "|                                |       global BCG study featuring 6,500 tech        |\n",
            "|                                |  professionals reveals senior women in technical   |\n",
            "|                                | functions are leading the way in #GenAI adoption;  |\n",
            "|                                |   they are, 14 percentage points more likely to    |\n",
            "|                                |       embrace the technology than their male       |\n",
            "|                                | counterparts. But despite this progress, women in  |\n",
            "|                                | non-technical senior functions and junior women in |\n",
            "|                                |   all functions are lagging behind.    As GenAI    |\n",
            "|                                |  continues to transform the workplace and beyond,  |\n",
            "|                                |   it‚Äôs crucial that we band together to bridge   |\n",
            "|                                |  this divide and foster an inclusive environment.  |\n",
            "|                                |  Stay tuned for BCG‚Äôs new report, diving deeper  |\n",
            "|                                |  into the state of GenAI adoption and how we can   |\n",
            "|                                |   make a difference, launching soon.    #IWD2024   |\n",
            "|                                | #generativeAI #womenintech          To view or add |\n",
            "|                                |    a comment, sign in                   Global     |\n",
            "|                                |      Compensation Director at BCG | Strategic      |\n",
            "|                                |  Compensation Solutions Expert              This   |\n",
            "|                                |   #InternationalWomensDay is all about inspiring   |\n",
            "|                                |  inclusion, and #GenAI adoption holds tremendous   |\n",
            "|                                |  opportunity.    A new global BCG study featuring  |\n",
            "|                                |  6,500 tech professionals reveals senior women in  |\n",
            "|                                | technical functions are leading the way in #GenAI  |\n",
            "|                                |   adoption; they are, 14 percentage points more    |\n",
            "|                                |  likely to embrace the technology than their male  |\n",
            "|                                | counterparts. But despite this progress, women in  |\n",
            "|                                | non-technical senior functions and junior women in |\n",
            "|                                |   all functions are lagging behind.    As GenAI    |\n",
            "|                                |  continues to transform the workplace and beyond,  |\n",
            "|                                |   it‚Äôs crucial that we band together to bridge   |\n",
            "|                                |  this divide and foster an inclusive environment.  |\n",
            "|                                |  Stay tuned for BCG‚Äôs new report, diving deeper  |\n",
            "|                                |  into the state of GenAI adoption and how we can   |\n",
            "|                                |   make a difference, launching soon.    #IWD2024   |\n",
            "|                                | #generativeAI #womenintech          To view or add |\n",
            "|                                |    a comment, sign in                   Partner    |\n",
            "|                                |     As we mark International Women‚Äôs Day and     |\n",
            "|                                |   celebrate the remarkable achievements of women   |\n",
            "|                                |  worldwide, recent incidents in the tech industry  |\n",
            "|                                |  highlight the urgent need to address inadvertent  |\n",
            "|                                |    discrimination, particularly in the realm of    |\n",
            "|                                |  artificial intelligence (AI).  Let‚Äôs recommit   |\n",
            "|                                | ourselves to fostering inclusivity and equality in |\n",
            "|                                |       all aspects of technology and beyond.        |\n",
            "|                                |      #InternationalWomensDay #GenderEquality       |\n",
            "|                                | #TechInclusion #EthicalAI          To view or add  |\n",
            "|                                | a comment, sign in               49,355 followers  |\n",
            "|                                |  Create your free account or sign in to continue   |\n",
            "|                                |   your search                                 or   |\n",
            "|                                | By clicking Continue to join or sign in, you agree |\n",
            "|                                |  to LinkedIn‚Äôs User Agreement, Privacy Policy,   |\n",
            "|                                |  and Cookie Policy.                       New to   |\n",
            "|                                |     LinkedIn? Join now                     or      |\n",
            "|                                | By clicking Continue to join or sign in, you agree |\n",
            "|                                |  to LinkedIn‚Äôs User Agreement, Privacy Policy,   |\n",
            "|                                |   and Cookie Policy.                     New to    |\n",
            "|                                |                 LinkedIn? Join now                 |\n",
            "+--------------------------------+----------------------------------------------------+\n",
            "[{'title': 'Intel and Altera Announce Edge and FPGA Offerings for AI at Embedded...', 'text': \"You can easily search the entire Intel.com site in several ways.\\nYou can also try the quick links below to see results for most popular searches.\\nThe browser version you are using is not recommended for this site.Please consider upgrading to the latest version of your browser by clicking one of the following links.\\nNew edge-optimized processors and FPGAs bring AI everywhere across edge computing markets including retail, industrial and healthcare.\\n\\nApril 8, 2024\\nContact Intel PR\\n\\nFollow Intel Newsroom on social:\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBy\\n\\nWhat’s New:\\xa0Today at Embedded World, Intel and Altera, an Intel Company, announced new edge-optimized processors, FPGAs and programmable market-ready solutions extending powerful AI capabilities into edge computing. These products will power AI-enabled edge devices applicable to industries across retail, healthcare, industrial, automotive, defense and aerospace.\\n\\nWhat’s New:\\xa0Today at Embedded World, Intel and Altera, an Intel Company, announced new edge-optimized processors, FPGAs and programmable market-ready solutions extending powerful AI capabilities into edge computing. These products will power AI-enabled edge devices applicable to industries across retail, healthcare, industrial, automotive, defense and aerospace.\\n“This next generation of Intel edge-optimized processors and discrete GPUs unleashes powerful AI capabilities to help businesses more seamlessly incorporate AI alongside compute, media and graphics workloads. From manufacturing to healthcare, Intel’s extensive edge AI experience and breadth and depth of edge-ready silicon and software help our customers deliver AI where they need it most for better business outcomes.” \\nWhy It Matters for Edge and AI: Why It Matters for Edge and AI: Intel’s new series of edge-optimized Intel® Core™\\u202fUltra, Intel® Core™ and Intel Atom® processors\\u202fand discrete Intel® Arc™ graphics processing units (GPUs) will advance innovation for artificial intelligence, visual computing and media processing – in support of faster and smarter decisions with on-premise edge computing. Agilex™ 5 FPGAs for mid-range applications with best-in-class performance per watt target a\\u202fbroad set of applications, including video, industrial, robotics, medical and others. Agilex\\u202f5 FPGAs with AI infused into the fabric offer a\\u202fhigh level of\\u202fintegration, low latency and improved computing capabilities\\u202ffor intelligent edge applications.\\nExpanding on Intel’s commitment to bringing AI everywhere, today's announcements utilize built-in AI acceleration in the new series of processors to power the next generation of edge devices.\\n\\nWhy It Matters for Edge and AI: Why It Matters for Edge and AI: Intel’s new series of edge-optimized Intel® Core™\\u202fUltra, Intel® Core™ and Intel Atom® processors\\u202fand discrete Intel® Arc™ graphics processing units (GPUs) will advance innovation for artificial intelligence, visual computing and media processing – in support of faster and smarter decisions with on-premise edge computing. Agilex™ 5 FPGAs for mid-range applications with best-in-class performance per watt target a\\u202fbroad set of applications, including video, industrial, robotics, medical and others. Agilex\\u202f5 FPGAs with AI infused into the fabric offer a\\u202fhigh level of\\u202fintegration, low latency and improved computing capabilities\\u202ffor intelligent edge applications.\\nExpanding on Intel’s commitment to bringing AI everywhere, today's announcements utilize built-in AI acceleration in the new series of processors to power the next generation of edge devices.\\nAn image shows the FPGAi Altera company logo. Altera helps customers achieve their business goals with new AI capabilities to support high-performance and mid-range FPGA-based solutions, developer usability and workload agility. (Credit: Altera, an Intel Company)\\nAn image shows an Intel Atom processor badge. Intel Atom processors x7000C Series delivers ramped-up processor base frequency in up to eight Efficient-cores. Intel Atom processors x7000RE Series features built-in deep learning inference capabilities. (Credit: Intel Corporation)\\nAn image shows an Intel Core Ultra processor badge. Intel Core Ultra processors combine the Intel Arc GPU and a neural processing unit (NPU) with LGA socket flexibility into a simplified system-on-chip (SoC). The new SoC is designed to enable generative AI (GenAI) and demanding graphics workloads at the edge. (Credit: Intel Corporation)\\nAn image shows the Intel Arc GPU for Edge badge. The Intel® Arc™ GPU for Edge boosts performance and edge AI capabilities on legacy Intel Core systems as a discrete GPU, providing accelerated AI, media and graphics processing power. (Credit: Intel Corporation)\\nAn image shows an Intel Core processor badge. Intel Core processors combine the GPU power of 13th Gen Intel Core mobile processors with LGA socket flexibility to prioritize system scalability and speed to deployment. (Credit: Intel Corporation)\\nAn image shows the Agilex 5 field programmable gate array. Agilex 5 FPGAs for mid-range applications with best-in-class performance per watt target a\\u202fbroad set of applications, including video, industrial, robotics, medical and others. (Credit: Altera, an Intel Company)\\nDownload all images (ZIP, 2 MB)\\n\\nDownload all images (ZIP, 2 MB)\\nHow Intel Expands AI to Embedded Edge Devices: Building on its expansive installed base of more than 90,000 edge deployments, Intel delivers a wave of edge-optimized processors and GPUs to power the next generation of AI-enabled edge devices.\\n\\xa0\\n\\nIntel Core\\u202fUltra processors for edge: Offering up to 5.02x better image classification inference performance compared to 14th Gen Intel® Core™ desktop processors,1 Intel Core Ultra processors combine the Intel Arc GPU2 and a neural processing unit (NPU)3 with LGA socket flexibility into a simplified system-on-chip (SoC). The new SoC is designed to enable generative AI (GenAI) and demanding graphics workloads at the edge for retail, education, smart cities and industrial customers, including GenAI-enabled kiosk and smart point-of-sale systems in brick-and-mortar retailers, interactive whiteboards for enhanced in-classroom experiences and AI vision-enhanced industrial devices for manufacturing and roadside units.\\xa0\\nIntel Core processors for edge: Intel Core processors combine the GPU power of 13th Gen Intel® Core® mobile processors with LGA socket flexibility to prioritize system scalability and speed to deployment. This series of processors optimized for the edge offers up to 2.57x greater graphics performance compared to 13th Gen Intel® Core™ desktop processors4 by leveraging up to 3 times more graphics execution units alongside performance hybrid architecture with Intel® Thread Director5 and an LGA socket-based design offering customers more edge AI and graphics performance without sacrificing hardware setup flexibility.\\nIntel Atom® processors x7000C Series: Intel Atom processors x7000C Series delivers ramped-up processor base frequency in up to eight Efficient-cores to drive exceptional packet processing throughput for enterprise networking and telecommunications devices. This enables telecommunications businesses to use built-in deep learning inference capabilities to support the detection of zero-day threats, boost packet and control plane processing for OpenSSL/IPSec using native instruction sets, and leverage Intel security features to harden networks.\\nIntel Atom® processors x7000RE Series: Primarily for industrial and manufacturing end users, Intel Atom processors x7000RE Series features built-in deep learning inference capabilities and up to 32 graphics execution units in a ruggedized, power-efficient 6W-12W BGA package offering up to 9.83x image classification performance compared with Intel Atom processors x6000RE Series6. The new processor supports fanless designs to enable Industry 4.0 automation for key use cases in AI-automated tending, warehouse AMR, in-line visual inspection for quality control and ruggedized industrial PC scenarios.\\xa0\\n\\n\\xa0\\nAdditionally, the Intel® Arc™ GPU for Edge boosts performance and edge AI capabilities on legacy Intel Core systems as a discrete GPU providing accelerated AI, and media and graphics processing power. Intel Arc GPUs also eliminate vendor lock-in with an open, standards-based software stack to offer choice and flexibility when building high-performance AI applications and solutions.\\xa0\\nHow Altera’s Portfolio Will Accelerate Customer AI Innovations: Following the FPGA Vision Webcast in February, Altera announced additional updates to its FPGA portfolio, providing flexible solutions to help customers solve their challenges from the cloud to network to the intelligent edge.\\n“We announced the launch of the new Altera brand with the goal of bringing leading technologies and innovations more quickly to the FPGA market. Today, we are excited about the next phase in our 10-plus year journey delivering flexible AI solutions,” said Sandra Rivera, Altera chief executive officer. “Altera is leading the new FPGAi era by tightly coupling programmability with tensor capabilities and infusing FPGA and AI tools for a best-in-class developer experience. Agilex 5, the first FPGA with AI-infused throughout the fabric, is now broadly available.”\\nAltera Leads the New Era of FPGAi: Altera helps customers achieve their business goals with new AI capabilities to support high-performance and mid-range FPGA-based solutions, developer usability and workload agility. FPGA AI Suite adds support for Agilex™ 5 SoC FPGAs. The AI tool flow allows developers to use existing and popular AI frameworks, along with the Intel® OpenVINO™ toolkit and the FPGA AI Suite, to create AI intellectual property (IP) blocks and easily drop them into the FPGA design. More information is available at the FPGA AI Suite website.\\n\\xa0\\n\\nPerformance per Watt Leader Agilex 5 SoC FPGAs Broadly Available: Agilex 5 devices, with best-in-class AI and up to 2x better performance per watt versus competing 7 nanometer FPGAs7, are designed to deliver high performance with lower power in a modern SoC subsystem with small form factor package options, allowing customers and developers to add AI capability to their products without the need for dedicated accelerators. Geared toward a broad set of embedded applications, Agilex 5 devices and development kits are broadly available with Quartus® Prime software support. Broad availability also includes support by a large and growing list of ecosystem partners providing additional boards, system-on-modules (SOMs), IP and various value-added services. More information about Agilex 5 devices, including technical details, is available at the Agilex 5 SoC FPGA website.\\nUnleash the Power of Agilex 5 E-Series Devices with Quartus Prime Pro Edition S/W Version 24.1: The latest version of Altera’s cutting-edge software is available for download, offering free access to the latest Agilex 5 E-Series SoC FPGAs and selected complementary IP cores. Quartus offers a streamlined experience for an IP-centric design flow, configurable example designs and unprecedented capabilities including a powerful new Agilex 5 SoC subsystem (hard-processor system featuring dual-core Arm Cortex A76, dual-core Arm Cortex A55 processors and various peripherals). This new SoC subsystem is also supported by third-party tools recently updated to support Agilex 5 devices. More information is available at the Quartus Prime Pro website.\\nPortfolio Breadth and Industry-Leading Longevity: Altera continues to deliver a broad portfolio, including industry-leading longevity with selected MAX® and Cyclone® cost- and power-optimized product families’ life cycles extended to 2040 and later, further improving supply chain resilience. Future Agilex™ 3 devices, coming soon, will expand the Agilex portfolio to deliver even greater breadth.\\n\\n\\xa0\\nWhy It Matters for Altera FPGAs: In an era where technological advancements are integral to staying competitive, Intel’s new edge-optimized processors and solutions deliver the capabilities enterprises need to innovate, be efficient and improve time to market. Altera delivers flexibility and re-programmability to accelerate innovators by providing easy-to-design and easy-to-deploy leadership programmable solutions.\\nThese processors, FPGAs and associated solutions allow enterprises to leverage the tremendous amount of data generated at the edge to deploy sophisticated embedded AI devices across a variety of industries to streamline operations, improve customer satisfaction and incorporate advanced visual workloads.\\xa0\\n“The FPGA AI Suite from Altera allowed the Tiami team to rapidly incorporate our IP into an intricate digital signal processing (DSP) pipeline,” said Amitav Mukherjee, CEO at Tiami Networks. “This significantly reduced the time required to integrate AI capabilities with 5G signal processing from an estimated six months to just eight weeks. Our engineering team clearly recognized the value proposition offered by the FPGA in preprocessing wireless signals received from the antenna and performing real-time inference, resulting in a successful demo.”\\nMore Context: Intel Core Ultra Processors for Edge (PDF) | Intel Processers for the Edge | Intel Arc GPU for Edge |\\xa0 Intel Launches Altera, Its New Standalone FPGA Company\\n\\nHow Intel Expands AI to Embedded Edge Devices: Building on its expansive installed base of more than 90,000 edge deployments, Intel delivers a wave of edge-optimized processors and GPUs to power the next generation of AI-enabled edge devices.\\n\\xa0\\n\\xa0\\nAdditionally, the Intel® Arc™ GPU for Edge boosts performance and edge AI capabilities on legacy Intel Core systems as a discrete GPU providing accelerated AI, and media and graphics processing power. Intel Arc GPUs also eliminate vendor lock-in with an open, standards-based software stack to offer choice and flexibility when building high-performance AI applications and solutions.\\xa0\\nHow Altera’s Portfolio Will Accelerate Customer AI Innovations: Following the FPGA Vision Webcast in February, Altera announced additional updates to its FPGA portfolio, providing flexible solutions to help customers solve their challenges from the cloud to network to the intelligent edge.\\n“We announced the launch of the new Altera brand with the goal of bringing leading technologies and innovations more quickly to the FPGA market. Today, we are excited about the next phase in our 10-plus year journey delivering flexible AI solutions,” said Sandra Rivera, Altera chief executive officer. “Altera is leading the new FPGAi era by tightly coupling programmability with tensor capabilities and infusing FPGA and AI tools for a best-in-class developer experience. Agilex 5, the first FPGA with AI-infused throughout the fabric, is now broadly available.”\\nAltera Leads the New Era of FPGAi: Altera helps customers achieve their business goals with new AI capabilities to support high-performance and mid-range FPGA-based solutions, developer usability and workload agility. FPGA AI Suite adds support for Agilex™ 5 SoC FPGAs. The AI tool flow allows developers to use existing and popular AI frameworks, along with the Intel® OpenVINO™ toolkit and the FPGA AI Suite, to create AI intellectual property (IP) blocks and easily drop them into the FPGA design. More information is available at the FPGA AI Suite website.\\n\\xa0\\n\\xa0\\nWhy It Matters for Altera FPGAs: In an era where technological advancements are integral to staying competitive, Intel’s new edge-optimized processors and solutions deliver the capabilities enterprises need to innovate, be efficient and improve time to market. Altera delivers flexibility and re-programmability to accelerate innovators by providing easy-to-design and easy-to-deploy leadership programmable solutions.\\nThese processors, FPGAs and associated solutions allow enterprises to leverage the tremendous amount of data generated at the edge to deploy sophisticated embedded AI devices across a variety of industries to streamline operations, improve customer satisfaction and incorporate advanced visual workloads.\\xa0\\n“The FPGA AI Suite from Altera allowed the Tiami team to rapidly incorporate our IP into an intricate digital signal processing (DSP) pipeline,” said Amitav Mukherjee, CEO at Tiami Networks. “This significantly reduced the time required to integrate AI capabilities with 5G signal processing from an estimated six months to just eight weeks. Our engineering team clearly recognized the value proposition offered by the FPGA in preprocessing wireless signals received from the antenna and performing real-time inference, resulting in a successful demo.”\\nMore Context: Intel Core Ultra Processors for Edge (PDF) | Intel Processers for the Edge | Intel Arc GPU for Edge |\\xa0 Intel Launches Altera, Its New Standalone FPGA Company\\nThe Small Print:\\xa0\\nAltera, the Altera logo, and other Altera marks are trademarks of Altera.\\xa0\\r\\nOther names and brands may be claimed as the property of others.\\n1 Performance varies by use, configuration, and other factors. Learn more at intel.com/processorclaims: Intel® Core™ Ultra processors, Edge. Results may vary.\\xa0\\xa0\\n2\\xa0Intel® Arc™ GPU\\xa0is only available on select H-Series, Intel® Core™ Ultra processor-powered\\xa0systems with at least 16GB of system memory in a dual-channel configuration.\\xa0OEM enablement\\xa0is\\xa0required; check with OEM for system configuration details.\\xa0\\n3\\xa0Intel® AI Boost enablement limited at launch.\\xa0\\n4\\xa0Performance varies by use, configuration, and other factors. Learn more at intel.com/processorclaims: Intel® Core™\\xa0processors, Edge.\\xa0Results may vary.\\xa0\\n5\\xa0Support for Intel® Thread Director is expected in Windows 11 IoT Enterprise LTSC and Linux\\xa0\\n6 Performance varies by use, configuration, and other factors. Learn more at intel.com/processorclaims:\\xa0Intel Atom® Processors. Results may vary.\\xa0\\n7\\xa0FPGA performance per watt:\\xa0\\xa0https://edc.intel.com/content/www/us/en/products/performance/benchmarks/agilex-fpga/. Results may vary.\\xa0\\xa0\\n\\nThe Small Print:\\xa0\\nAltera, the Altera logo, and other Altera marks are trademarks of Altera.\\xa0\\r\\nOther names and brands may be claimed as the property of others.\\n1 Performance varies by use, configuration, and other factors. Learn more at intel.com/processorclaims: Intel® Core™ Ultra processors, Edge. Results may vary.\\xa0\\xa0\\n2\\xa0Intel® Arc™ GPU\\xa0is only available on select H-Series, Intel® Core™ Ultra processor-powered\\xa0systems with at least 16GB of system memory in a dual-channel configuration.\\xa0OEM enablement\\xa0is\\xa0required; check with OEM for system configuration details.\\xa0\\n3\\xa0Intel® AI Boost enablement limited at launch.\\xa0\\n4\\xa0Performance varies by use, configuration, and other factors. Learn more at intel.com/processorclaims: Intel® Core™\\xa0processors, Edge.\\xa0Results may vary.\\xa0\\n5\\xa0Support for Intel® Thread Director is expected in Windows 11 IoT Enterprise LTSC and Linux\\xa0\\n6 Performance varies by use, configuration, and other factors. Learn more at intel.com/processorclaims:\\xa0Intel Atom® Processors. Results may vary.\\xa0\\n7\\xa0FPGA performance per watt:\\xa0\\xa0https://edc.intel.com/content/www/us/en/products/performance/benchmarks/agilex-fpga/. Results may vary.\\xa0\\xa0\\n\\nAltera, \\nInternet of Things, \\nArtificial Intelligence\\n\\nAbout Intel\\nIntel (Nasdaq: INTC) is an industry leader, creating world-changing technology that enables global progress and enriches lives. Inspired by Moore’s Law, we continuously work to advance the design and manufacturing of semiconductors to help address our customers’ greatest challenges. By embedding intelligence in the cloud, network, edge and every kind of computing device, we unleash the potential of data to transform business and society for the better. To learn more about Intel’s innovations, go to newsroom.intel.com and intel.com.\\n© Intel Corporation. Intel, the Intel logo and other Intel marks are trademarks of Intel Corporation or its subsidiaries. Other names and brands may be claimed as the property of others.\\nIntel technologies may require enabled hardware, software or service activation. // No product or component can be absolutely secure. // Your costs and results may vary. // Performance varies by use, configuration and other factors. // See our complete legal Notices and Disclaimers. //\\xa0Intel is committed to respecting human rights and avoiding causing or contributing to adverse impacts on human rights. See Intel’s Global Human Rights Principles. Intel’s products and software are intended only to be used in applications that do not cause or contribute to adverse impacts on human rights.\"}, {'title': 'Sandra Rivera on LinkedIn: #women4ew #womenintech #wearealtera #ai | 13 comments', 'text': '\\n                Agree & Join LinkedIn\\n              \\n\\n      By clicking Continue to join or sign in, you agree to LinkedIn‚Äôs User Agreement, Privacy Policy, and Cookie Policy.\\n    \\nA great #women4ew event at embedded world Exhibition&Conference today covering various topics from addressing gender bias in AI algorithms to discussing the critical role diversity plays in innovation.\\nAt Altera we create a culture that positively impacts the work experience and development of women. So, it has filled me with hope and optimism to see so many women in this industry come together to share their experience and pave the way for the next generation of #womenintech #WeAreAltera #AI\\n\\nLoved the insights on gender bias & diversity in AI! Plato said wisdom begins in wonder, reminding us that diversity fuels innovation by widening our perspectives \\uf8ffüåü #womenintech #innovation\\n\\nI love the topic - \"how diversity can impact innovation\"  reminded me of why the military did not put all of the same \"Human Dynamic\" people together on teams ( higher injury rates) and Margaret Heffernan\\'s super chickens TED talk! Martin Curley and I will release our second innovation book in Q4 \"Managing Innovation in a Digital World\"- we will send you a copy! \\nFinancial Cultural Operational and Technical Consultant - Alpha Sense Financial Consulting\\nHere\\'s a remedy to the tribal feminism agenda...\\n\\nThe solution is to unite around a common set of principles and values, and the Gordon Moore ethos and Grove Egalitarian Meritocracy.    Glad to see Pat pushing this;  Will you join him Sandra Rivera and create the One Culture Bob Swan initiated.    There needs to be a lot of follow through. \\n\\nWhat your espousing is antithetical to good solid ethics and practices; don\\'t you think?\\n\\nhttps://www.linkedin.com/article/edit/7117624932322185216/\\n\\n\\nThank you, Sandra Rivera, for being an incredible part of #women4ew!¬†\\uf8ffüí™ \\nWe are absolutely honoured to have such amazing women like you in the #embeddedworld!\\nAssembly Test Manufacturing GM Communications & Chief of Staff Support | Senior Technical Leader | IDM 2.0 & Foundry Programs | Lean Six Sigma Blackbelt | Multicultural ERG Alliance Chair at Intel Corporation\\nThis is way too important thank you for being a leader in this. Bias of any kind in AI algorithms at this critical juncture of machine learning is a continuation of status quo, which is not good enough. Change can only happen with real actions beyond intentions. Thanks for making it real and hearing, supporting and hopefully responding to these issues.\\nDigital Marketing | Social Media Management | Content Creation\\nIt\\'s truly empowering to see initiatives like #women4ew fostering discussions on crucial topics like gender bias in AI and the importance of diversity in innovation. \\n\\nGreat to see you pushing this. It\\'s really needed and hitting a chord. I know of one tech startup that had 10 men originally with no women. Now it\\'s up to 22 with 12 women and 10 men. But web talks are still all men.\\nI help ambitious leaders build strong Executive Presence so that they get rapid career growth and coveted CXO roles I Executive & Leadership Coach I Learning and Development | Training | Talent Management\\nThat\\'s fantastic to hear about your experience! It\\'s encouraging to see women coming together to support each other and advocate for positive change.\\nFinancial Cultural Operational and Technical Consultant - Alpha Sense Financial Consulting\\nA picture of true unity and diversity.   A place where diverse talents thinking and experience makes the best and highest use of scarce Human Resources...    \\n\\nThe Gordon Moore ethos of Intels first 3 decades was a place where everyone rallied around a common purpose and a shared sense of identity.\\nSolving digital challenges for U.S companies @ RKTech | Dreamer who does @ Rikkeisoft | Forbes Tech Council Member\\nKudos to Altera for fostering a culture that supports and develops women in the tech industry! \\n\\n        To view or add a comment, sign in\\n\\n\\n                Financial Cultural Operational and Technical Consultant - Alpha Sense Financial Consulting\\n            \\nHere\\'s a remedy to the tribal feminism agenda...\\n\\nThe solution is to unite around a common set of principles and values, and the Gordon Moore ethos and Grove Egalitarian Meritocracy.    Glad to see Pat pushing this;  Will you join him Sandra Rivera and create the One Culture Bob Swan initiated.    There needs to be a lot of follow through. \\n\\nWhat your espousing is antithetical to good solid ethics and practices; don\\'t you think?\\n\\nhttps://lnkd.in/gg6wt2fU\\n\\nHere\\'s our pitch for Intel to live out the true spirit of the Open Door culture, and regain its position as the cultural standard bearer for Silicon Valley.\\n\\nhttps://lnkd.in/gbckTSTV\\nA great #women4ew event at embedded world Exhibition&Conference today covering various topics from addressing gender bias in AI algorithms to discussing the critical role diversity plays in innovation.\\nAt Altera we create a culture that positively impacts the work experience and development of women. So, it has filled me with hope and optimism to see so many women in this industry come together to share their experience and pave the way for the next generation of #womenintech #WeAreAltera #AI\\n\\n        To view or add a comment, sign in\\n\\n\\n                1,230 followers\\n            \\nEmpowering Women in AI: A Journey of Inclusivity & Innovation \\uf8ffüöÄ\\n\\nAt Resonant Consulting, we believe in the transformative power of artificial intelligence (AI) and its potential to enrich lives when inclusivity is at the forefront. \\n\\nOur latest carousel celebrates the journey towards gender inclusivity in AI, spotlighting the essential role of male allies and the untapped potential of women in shaping the future of technology. \\uf8ffüåü\\n\\nWe\\'re calling on everyone, especially our male counterparts, to join us in this movement. Your support is crucial in creating an environment where women can excel and contribute to AI\\'s limitless possibilities. Together, let\\'s ensure the AI journey is inclusive, empowering, and beneficial for all. Dive into our carousel to learn more and be part of the change. \\n\\n#WomenInAI #InclusiveTech #ResonantConsulting #WomenInAI\\n#InclusiveAI #AIForAll #GenderInclusivityInTech #EmpowerHerAI #AIInnovationForAll #DiversityInAI #FutureIsFemaleAI #MaleAlliesForAI #EmpoweringWomenInTech #TechForGood #AIEquality\\n\\n\\n        To view or add a comment, sign in\\n\\n\\n                100,559 followers\\n            \\nGenerative AI is rapidly transforming the world as we know it, with C-suite executives anticipating that nearly half of workers on average will require reskilling within the next three years.\\n\\nA recent BCG report underscores that senior women in tech are leading the way in #GenAI adoption, utilizing the #technology at rates 14 percentage points higher than their male counterparts. However, women in non-technical roles and junior women across all functions are not keeping pace.\\n\\nWhat drives these gender disparities in GenAI adoption and how can leaders narrow the gap? Find out here:¬†https://on.bcg.com/4b98ld0\\n#GenerativeAI #WomenInTech #ArtificialIntelligence\\n\\n\\n        To view or add a comment, sign in\\n\\n\\n                Digital Content Manager | Strategist | Gen AI | Ex Adani Digital Labs, Ogilvy, Wunderman Thompson, FCB | Social Stars Gold, Digies Gold\\n            \\nThis research says senior managers are adopting Gen AI fast. But why don\\'t I see this happening in advertising and marketing? I hear people talking about using AI and individuals flaunting their knwoledge about it. But no effort to make AI a part of daily jobs. Will this change? Hopefully, it will trickle down from the senior managers to their teams soon enough.\\n\\n                100,559 followers\\n            \\nGenerative AI is rapidly transforming the world as we know it, with C-suite executives anticipating that nearly half of workers on average will require reskilling within the next three years.\\n\\nA recent BCG report underscores that senior women in tech are leading the way in #GenAI adoption, utilizing the #technology at rates 14 percentage points higher than their male counterparts. However, women in non-technical roles and junior women across all functions are not keeping pace.\\n\\nWhat drives these gender disparities in GenAI adoption and how can leaders narrow the gap? Find out here:¬†https://on.bcg.com/4b98ld0\\n#GenerativeAI #WomenInTech #ArtificialIntelligence\\n\\n\\n        To view or add a comment, sign in\\n\\n\\n                Global Leader - People & Organization Practice, Senior Partner and Managing Director at Boston Consulting Group (BCG)\\n            \\nAs we commemorate International Women‚Äôs Day, it\\'s a moment of reflection on our journey and a celebration of progress in the realm of technology and leadership. I\\'m proud to share a glimpse into @BCG‚Äôs latest report on GenAI‚Äôs integration within the tech sector highlighting promising trends in gender diversity.  \\n \\nThis report isn\\'t just numbers; it\\'s a narrative of change. It shows that women in senior tech roles are not just pioneering the adoption of GenAI, but they are setting the pace, outperforming male counterparts in GenAI adoption by 14 percentage points.\\n \\nDespite these gains, we acknowledge the persisting obstacles women continue to face. Bridging this adoption gap is not just a tech issue; it\\'s a business priority that demands a concerted effort across all levels of an organization. \\n \\nThank you to my colleagues who drove this research: @Neveen Awad, @Maria Barisano, @Adriana Dahik, @Julie Bedard, @Uche Monu, and @Gunjan Mundhra. Their dedication echoes our shared mission‚Äîto build a culture where every woman\\'s potential is realized, and their contributions are valued. \\n \\nLet\\'s commit to the advancement of women and build a more inclusive future together. \\n  \\n#InternationalWomensday #GenerativeAI #WomeninTech \\n\\n        To view or add a comment, sign in\\n\\n\\n                3,074 followers\\n            \\nthe vital role of women in Artificial Intelligence (AI)!\\n\\uf8ffüåü Why Female Representation in AI Matters:\\n1. Diverse Perspectives\\n2. Ethical Considerations\\n3. Inclusive Design\\n4. Inspiration and Mentorship\\nDon\\'t miss this chance to connect with AI experts and innovators.\\n#WomenInAI #AIInnovation #womenempowerment #gwf23 \\n\\n                3,074 followers\\n            \\n\\uf8ffüì£ Exciting News! GLOBAL WOMEN FORUM (GWF) Welcomes New Supporter: International Group of Artificial Intelligence highlighting the crucial role of women in #ArtificialIntelligence. \\nJoin us on Nov 15th in Berlin as we empower female #AI innovators, break gender barriers, and shape ethical AI. Let\\'s drive the AI industry toward inclusivity and progress! \\n\\nBe part of the happening: https://lnkd.in/eAe4Y_KG\\nDr. Jassim Haji #WomenInAI #DiversityInTech #womeninstem #womenintechnology #womenempowerment #gwf23\\n\\n\\n        To view or add a comment, sign in\\n\\n\\n                75 followers\\n            \\nAI for Women is launching a brand new website - We are now a professional networking platform for women AI enthusiasts! The objective of this website is to promote networking among like-minded women who can inspire, mentor, and help one another. \\n\\nAs a part of the pre-launch campaign, I have decided to do a deep dive into how we can achieve equality in AI for women. I will be sharing my findings over the next 3 days in the form of blog posts. \\n\\nToday\\'s article talks about \\'Gender Bias and Stereotyping\\'. You can find it here: https://lnkd.in/g3me3upH\\n\\nDo you agree with the article? Have you experienced / overcome similar challenges? Feel free to share your thoughts! \\uf8ffüñã \\n\\n#AI #GenerativeAI #WomenEmpowerment #AIforWomen #WomeninAI #WomeninTech #WomeninSTEM #DataScience\\n\\n        To view or add a comment, sign in\\n\\n\\n                Jubilant Pharmova | Former BCG | Former Egon Zehnder\\n            \\nThis #InternationalWomensDay is all about inspiring inclusion, and #GenAI adoption holds tremendous opportunity.  \\n\\nA new global BCG study featuring 6,500 tech professionals reveals senior women in technical functions are leading the way in #GenAI adoption; they are, 14 percentage points more likely to embrace the technology than their male counterparts. But despite this progress, women in non-technical senior functions and junior women in all functions are lagging behind.  \\n\\nAs GenAI continues to transform the workplace and beyond, it‚Äôs crucial that we band together to bridge this divide and foster an inclusive environment. Stay tuned for BCG‚Äôs new report, diving deeper into the state of GenAI adoption and how we can make a difference, launching soon.  \\n\\n#IWD2024 #generativeAI #womenintech\\n\\n        To view or add a comment, sign in\\n\\n\\n                Global Compensation Director at BCG | Strategic Compensation Solutions Expert\\n            \\nThis #InternationalWomensDay is all about inspiring inclusion, and #GenAI adoption holds tremendous opportunity.  \\n\\nA new global BCG study featuring 6,500 tech professionals reveals senior women in technical functions are leading the way in #GenAI adoption; they are, 14 percentage points more likely to embrace the technology than their male counterparts. But despite this progress, women in non-technical senior functions and junior women in all functions are lagging behind.  \\n\\nAs GenAI continues to transform the workplace and beyond, it‚Äôs crucial that we band together to bridge this divide and foster an inclusive environment. Stay tuned for BCG‚Äôs new report, diving deeper into the state of GenAI adoption and how we can make a difference, launching soon.  \\n\\n#IWD2024 #generativeAI #womenintech\\n\\n        To view or add a comment, sign in\\n\\n\\n                Partner \\n            \\nAs we mark International Women‚Äôs Day and celebrate the remarkable achievements of women worldwide, recent incidents in the tech industry highlight the urgent need to address inadvertent discrimination, particularly in the realm of artificial intelligence (AI).\\n\\nLet‚Äôs recommit ourselves to fostering inclusivity and equality in all aspects of technology and beyond.\\n\\n#InternationalWomensDay #GenderEquality #TechInclusion #EthicalAI\\n\\n        To view or add a comment, sign in\\n\\n\\n            49,355 followers\\n          \\n\\n                Create your free account or sign in to continue your search\\n              \\n\\n\\n\\n              or\\n            \\n\\n      By clicking Continue to join or sign in, you agree to LinkedIn‚Äôs User Agreement, Privacy Policy, and Cookie Policy.\\n    \\n\\n                New to LinkedIn? Join now\\n\\n\\n                  or\\n                \\n\\n      By clicking Continue to join or sign in, you agree to LinkedIn‚Äôs User Agreement, Privacy Policy, and Cookie Policy.\\n    \\n\\n              New to LinkedIn? Join now\\n\\n'}]\n",
            "File '/content/drive/My Drive/KG/results.txt' created successfully.\n",
            "['results.txt']\n",
            "Sync function has been called\n",
            "200\n",
            "INFO:     174.249.149.114:0 - \"GET /generate_knowledge_graph?kg_query=Altera%20infuses%20AI HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-18 (construct_knowledge_graph):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-28-c139f9fc0d1f>\", line 33, in construct_knowledge_graph\n",
            "AttributeError: 'KnowledgeGraphIndex' object has no attribute 'get_triplets'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Knowledge graph constructed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [233]\n"
          ]
        }
      ],
      "source": [
        "# Set up a local web server to make it accessible over the internet, the APIs will be called by the React.js application\n",
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('URL: ', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama_index networkx matplotlib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkfJ5VogPeDx",
        "outputId": "0b1500e9-78fe-4353-915d-cd9108446293"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama_index\n",
            "  Downloading llama_index-0.10.65-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama_index)\n",
            "  Downloading llama_index_agent_openai-0.2.9-py3-none-any.whl.metadata (729 bytes)\n",
            "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama_index)\n",
            "  Downloading llama_index_cli-0.1.13-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.65 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.10.65)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.1.11)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.2.0 (from llama_index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.2.7-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama_index)\n",
            "  Downloading llama_index_legacy-0.9.48.post1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.27 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.1.29)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama_index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.1.9-py3-none-any.whl.metadata (728 bytes)\n",
            "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama_index)\n",
            "  Downloading llama_index_program_openai-0.1.7-py3-none-any.whl.metadata (760 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama_index)\n",
            "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\n",
            "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.1.33)\n",
            "Collecting llama-index-readers-llama-parse>=0.1.2 (from llama_index)\n",
            "  Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-agent-openai<0.3.0,>=0.1.4->llama_index) (1.40.6)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama_index) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.65->llama_index) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama_index) (3.10.2)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama_index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama_index) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama_index) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama_index) (2024.6.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama_index) (0.27.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama_index) (1.6.0)\n",
            "Requirement already satisfied: nltk>=3.8.2 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama_index) (3.8.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama_index) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama_index) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama_index) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama_index) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama_index) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama_index) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama_index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama_index) (1.16.0)\n",
            "Collecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama_index)\n",
            "  Downloading llama_cloud-0.0.13-py3-none-any.whl.metadata (751 bytes)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama_index) (4.12.3)\n",
            "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama_index) (4.3.1)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama_index) (0.0.26)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama_index)\n",
            "  Downloading llama_parse-0.4.9-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama_index) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama_index) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama_index) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama_index) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama_index) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama_index) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama_index) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama_index) (2.5)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llama-cloud>=0.0.11->llama-index-indices-managed-llama-cloud>=0.2.0->llama_index) (2.8.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.65->llama_index) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.65->llama_index) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.65->llama_index) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.65->llama_index) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.65->llama_index) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.65->llama_index) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.65->llama_index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.65->llama_index) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.65->llama_index) (2024.5.15)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama_index) (1.7.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama_index) (0.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.65->llama_index) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.65->llama_index) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.65->llama_index) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.65->llama_index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.65->llama_index) (3.21.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.65->llama_index) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.65->llama_index) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.65->llama_index) (1.2.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llama-cloud>=0.0.11->llama-index-indices-managed-llama-cloud>=0.2.0->llama_index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llama-cloud>=0.0.11->llama-index-indices-managed-llama-cloud>=0.2.0->llama_index) (2.20.1)\n",
            "Downloading llama_index-0.10.65-py3-none-any.whl (6.8 kB)\n",
            "Downloading llama_index_agent_openai-0.2.9-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_cli-0.1.13-py3-none-any.whl (27 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.2.7-py3-none-any.whl (9.5 kB)\n",
            "Downloading llama_index_legacy-0.9.48.post1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_multi_modal_llms_openai-0.1.9-py3-none-any.whl (5.9 kB)\n",
            "Downloading llama_index_program_openai-0.1.7-py3-none-any.whl (5.3 kB)\n",
            "Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
            "Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl (2.5 kB)\n",
            "Downloading llama_cloud-0.0.13-py3-none-any.whl (169 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.4/169.4 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.4.9-py3-none-any.whl (9.4 kB)\n",
            "Installing collected packages: llama-cloud, llama-index-legacy, llama-parse, llama-index-indices-managed-llama-cloud, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama_index\n",
            "Successfully installed llama-cloud-0.0.13 llama-index-agent-openai-0.2.9 llama-index-cli-0.1.13 llama-index-indices-managed-llama-cloud-0.2.7 llama-index-legacy-0.9.48.post1 llama-index-multi-modal-llms-openai-0.1.9 llama-index-program-openai-0.1.7 llama-index-question-gen-openai-0.1.3 llama-index-readers-llama-parse-0.1.6 llama-parse-0.4.9 llama_index-0.10.65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## create graph\n",
        "from pyvis.network import Network\n",
        "\n",
        "g = new_index.get_networkx_graph()\n",
        "net = Network(notebook=True, cdn_resources=\"in_line\", directed=True)\n",
        "net.from_nx(g)\n",
        "net.show(\"kg_graph.html\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "collapsed": true,
        "id": "wRX_N72YPlV1",
        "outputId": "8a8f00ba-c815-4899-81f1-013409a53a4c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kg_graph.html\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7dcc82ceb7f0>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"600px\"\n",
              "            src=\"kg_graph.html\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyvis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRZb5Ev1QbNv",
        "outputId": "c6299b6c-17bf-4d41-d1fc-d00b349490f1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyvis\n",
            "  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from pyvis) (7.34.0)\n",
            "Requirement already satisfied: jinja2>=2.9.6 in /usr/local/lib/python3.10/dist-packages (from pyvis) (3.1.4)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pyvis) (3.2.2)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.10/dist-packages (from pyvis) (3.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (71.0.4)\n",
            "Collecting jedi>=0.16 (from ipython>=5.3.0->pyvis)\n",
            "  Using cached jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.9.6->pyvis) (2.1.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis) (0.2.13)\n",
            "Downloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "Installing collected packages: jedi, pyvis\n",
            "Successfully installed jedi-0.19.1 pyvis-0.3.2\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "WMSAh6Rs8ly-"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvpUcoWbjC9b",
        "outputId": "f189c500-b90d-4b94-fe19-155c0bec1b09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test\n"
          ]
        }
      ],
      "source": [
        "print(\"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMSAh6Rs8ly-"
      },
      "source": [
        "# **Run prior to starting the server and chatbot**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Cuf_GVLt5368",
        "outputId": "db721300-b669-4e27-9acc-a2d60ce8b9ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-llms-openai\n",
            "  Downloading llama_index_llms_openai-0.1.29-py3-none-any.whl.metadata (650 bytes)\n",
            "Collecting llama-index-core<0.11.0,>=0.10.57 (from llama-index-llms-openai)\n",
            "  Downloading llama_index_core-0.10.65-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting openai<2.0.0,>=1.40.0 (from llama-index-llms-openai)\n",
            "  Downloading openai-1.40.6-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (3.10.1)\n",
            "Collecting dataclasses-json (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (2024.6.1)\n",
            "Collecting httpx (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (3.3)\n",
            "Collecting nltk>=3.8.2 (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai)\n",
            "  Downloading nltk-3.8.2-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (2.1.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.2.0 (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (4.12.2)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (1.16.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.7.0)\n",
            "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.40.0->llama-index-llms-openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (4.0.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (2024.5.15)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai<2.0.0,>=1.40.0->llama-index-llms-openai) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (2024.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (24.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.57->llama-index-llms-openai) (1.16.0)\n",
            "Downloading llama_index_llms_openai-0.1.29-py3-none-any.whl (11 kB)\n",
            "Downloading llama_index_core-0.10.65-py3-none-any.whl (15.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.40.6-py3-none-any.whl (361 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m361.3/361.3 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nltk-3.8.2-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dirtyjson, tenacity, nltk, mypy-extensions, marshmallow, jiter, h11, deprecated, typing-inspect, tiktoken, httpcore, httpx, dataclasses-json, openai, llama-index-core, llama-index-llms-openai\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.8.1\n",
            "    Uninstalling nltk-3.8.1:\n",
            "      Successfully uninstalled nltk-3.8.1\n",
            "Successfully installed dataclasses-json-0.6.7 deprecated-1.2.14 dirtyjson-1.0.8 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jiter-0.5.0 llama-index-core-0.10.65 llama-index-llms-openai-0.1.29 marshmallow-3.21.3 mypy-extensions-1.0.0 nltk-3.8.2 openai-1.40.6 tenacity-8.5.0 tiktoken-0.7.0 typing-inspect-0.9.0\n",
            "Collecting llama-index-readers-file\n",
            "  Downloading llama_index_readers_file-0.1.33-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file) (4.12.3)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.37.post1 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file) (0.10.65)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file)\n",
            "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file) (2.5)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (3.10.1)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2024.6.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (0.27.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (3.3)\n",
            "Requirement already satisfied: nltk>=3.8.2 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (3.8.2)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.26.4)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.40.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2.1.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (4.0.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2024.5.15)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.7.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (0.5.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (3.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (3.21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.2.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (24.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (2.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.37.post1->llama-index-readers-file) (1.16.0)\n",
            "Downloading llama_index_readers_file-0.1.33-py3-none-any.whl (38 kB)\n",
            "Downloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Installing collected packages: striprtf, pypdf, llama-index-readers-file\n",
            "Successfully installed llama-index-readers-file-0.1.33 pypdf-4.3.1 striprtf-0.0.26\n",
            "Collecting llama-index-embeddings-openai\n",
            "  Downloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl.metadata (655 bytes)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-openai) (0.10.65)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.10.1)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2024.6.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.27.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.3)\n",
            "Requirement already satisfied: nltk>=3.8.2 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.8.2)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.26.4)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.40.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.1.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (4.0.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.2->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2024.5.15)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.7.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.5.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.2.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (24.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.16.0)\n",
            "Downloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl (6.3 kB)\n",
            "Installing collected packages: llama-index-embeddings-openai\n",
            "Successfully installed llama-index-embeddings-openai-0.1.11\n"
          ]
        }
      ],
      "source": [
        "#Installations for constructing knowledge graph\n",
        "!pip install llama-index-llms-openai\n",
        "!pip install llama-index-readers-file\n",
        "!pip install llama-index-embeddings-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "W3hBnhIUAlVE",
        "outputId": "3a0bdbc5-e690-43b7-c8ad-6b4451584022"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastapi\n",
            "  Downloading fastapi-0.112.0-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.20.1)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.38.0,>=0.37.2->fastapi) (3.7.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi) (1.2.2)\n",
            "Downloading fastapi-0.112.0-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.0-py3-none-any.whl (22 kB)\n",
            "Downloading uvicorn-0.30.6-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvicorn, pyngrok, starlette, fastapi\n",
            "Successfully installed fastapi-0.112.0 pyngrok-7.2.0 starlette-0.37.2 uvicorn-0.30.6\n",
            "add-authtoken - save authtoken to configuration file\n",
            "\n",
            "USAGE:\n",
            "  ngrok config add-authtoken TOKEN [flags]\n",
            "\n",
            "AUTHOR:\n",
            "  ngrok - <support@ngrok.com>\n",
            "\n",
            "COMMANDS: \n",
            "  config          update or migrate ngrok's configuration file\n",
            "  http            start an HTTP tunnel\n",
            "  tcp             start a TCP tunnel\n",
            "  tunnel          start a tunnel for use with a tunnel-group backend\n",
            "\n",
            "EXAMPLES: \n",
            "  ngrok http 80                                                 # secure public URL for port 80 web server\n",
            "  ngrok http --domain baz.ngrok.dev 8080                        # port 8080 available at baz.ngrok.dev\n",
            "  ngrok tcp 22                                                  # tunnel arbitrary TCP traffic to port 22\n",
            "  ngrok http 80 --oauth=google --oauth-allow-email=foo@foo.com  # secure your app with oauth\n",
            "\n",
            "Paid Features: \n",
            "  ngrok http 80 --domain mydomain.com                           # run ngrok with your own custom domain\n",
            "  ngrok http 80 --allow-cidr 2600:8c00::a03c:91ee:fe69:9695/32  # run ngrok with IP policy restrictions\n",
            "  Upgrade your account at https://dashboard.ngrok.com/billing/subscription to access paid features\n",
            "\n",
            "Upgrade your account at https://dashboard.ngrok.com/billing/subscription to access paid features\n",
            "\n",
            "Flags:\n",
            "  -h, --help      help for ngrok\n",
            "\n",
            "Use \"ngrok [command] --help\" for more information about a command.\n",
            "\n",
            "ERROR:  accepts 1 arg(s), received 0\n"
          ]
        }
      ],
      "source": [
        "#installations for Fast API\n",
        "!pip install fastapi nest-asyncio pyngrok uvicorn\n",
        "!ngrok config add-authtoken $NGROK_AUTHTOKEN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DKcxiaT24gsj"
      },
      "outputs": [],
      "source": [
        "# Needed for information extraction\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import networkx as nx\n",
        "import spacy\n",
        "from prettytable import PrettyTable\n",
        "import textwrap\n",
        "from google.colab import userdata\n",
        "\n",
        "# For Google custom search engine\n",
        "api_key = userdata.get('api_key')\n",
        "cse_id = userdata.get('cse_id')\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYjsMore5BgP",
        "outputId": "01bf5d6c-9662-41ec-f9eb-0c8c18a4a972"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# To store the extracted info in GDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NN-WZav06LZz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('openai_api-key')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "M8Gn1l4r6UcY"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import sys\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "b_vRwVgJ6Wh8"
      },
      "outputs": [],
      "source": [
        "# For constructing knowledge graph and displaying results\n",
        "from llama_index.core import SimpleDirectoryReader, KnowledgeGraphIndex\n",
        "from llama_index.core.graph_stores import SimpleGraphStore\n",
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.core import Settings\n",
        "from IPython.display import Markdown, display\n",
        "from llama_index.core import StorageContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ep39Fn5g8_5q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Define the path to the specific folder in Google Drive\n",
        "folder_path = '/content/drive/My Drive/KG'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not os.path.exists(folder_path):\n",
        "    os.makedirs(folder_path)\n",
        "\n",
        "# Define the path for the file\n",
        "file_path = os.path.join(folder_path, 'results.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eywQpwVF9OBW"
      },
      "outputs": [],
      "source": [
        "# Default value\n",
        "curr_query = 'use cases of transformers in machine learning'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PHCnNFjpzVSX"
      },
      "outputs": [],
      "source": [
        "os.environ['NGROK_AUTHTOKEN'] = userdata.get('ngrok_auth_token')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRvPMMvI80VN"
      },
      "source": [
        "# **Chatbot calls these functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "collapsed": true,
        "id": "laxfanKR3Es3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "outputId": "a7fb74fb-76ee-42d4-c694-9bf9b475e305"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'def google_search(query, api_key, cse_id, num_results=5):\\n    search_url = f\"https://www.googleapis.com/customsearch/v1?q={query}&key={api_key}&cx={cse_id}&num={num_results}\"\\n    response = requests.get(search_url)\\n    results = response.json().get(\\'items\\', [])\\n    return [item[\\'link\\'] for item in results]\\n\\ndef extract_relevant_info(url):\\n    try:\\n        response = requests.get(url)\\n        response.raise_for_status()\\n        soup = BeautifulSoup(response.content, \\'html.parser\\')\\n        title = soup.find(\\'title\\').get_text()\\n        paragraphs = soup.find_all(\\'p\\')\\n        text = \"\\n\".join([p.get_text() for p in paragraphs])\\n        return {\"title\": title, \"text\": text}\\n    except requests.exceptions.RequestException as e:\\n        return {\"error\": str(e)}\\n\\n# Function to wrap text for table display\\ndef wrap_text(text, width):\\n    return \"\\n\".join(textwrap.wrap(text, width=width))\\n\\n# Function to format and print the output using PrettyTable\\ndef print_formatted_output(results):\\n    table = PrettyTable()\\n    table.field_names = [\"Title\", \"URL\", \"Text\"]\\n\\n    for result in results:\\n        wrapped_title = wrap_text(result[\\'title\\'], width=30)\\n        wrapped_url = wrap_text(result[\\'url\\'], width=30)\\n        wrapped_text = wrap_text(result[\\'text\\'], width=50)\\n        table.add_row([wrapped_title, wrapped_url, wrapped_text])\\n\\n    print(table)\\n\\n\\n\\ndef user_input_kg(query):\\n  if len(query)>0:\\n    curr_query = query\\n  else:\\n    curr_query = \\'use cases of transformers in machine learning\\'\\n  query = curr_query\\n  urls = google_search(query, api_key, cse_id)\\n  all_entities = set()\\n  all_relationships = []\\n  results = []\\n\\n  for url in urls:\\n      info = extract_relevant_info(url)\\n      if \"error\" not in info:\\n          info[\\'url\\'] = url\\n          results.append(info)\\n  print_formatted_output(results)\\n  return results\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# Extract information using the Google API key and Custom search engine id\n",
        "\"\"\"def google_search(query, api_key, cse_id, num_results=5):\n",
        "    search_url = f\"https://www.googleapis.com/customsearch/v1?q={query}&key={api_key}&cx={cse_id}&num={num_results}\"\n",
        "    response = requests.get(search_url)\n",
        "    results = response.json().get('items', [])\n",
        "    return [item['link'] for item in results]\n",
        "\n",
        "def extract_relevant_info(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        title = soup.find('title').get_text()\n",
        "        paragraphs = soup.find_all('p')\n",
        "        text = \"\\n\".join([p.get_text() for p in paragraphs])\n",
        "        return {\"title\": title, \"text\": text}\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "# Function to wrap text for table display\n",
        "def wrap_text(text, width):\n",
        "    return \"\\n\".join(textwrap.wrap(text, width=width))\n",
        "\n",
        "# Function to format and print the output using PrettyTable\n",
        "def print_formatted_output(results):\n",
        "    table = PrettyTable()\n",
        "    table.field_names = [\"Title\", \"URL\", \"Text\"]\n",
        "\n",
        "    for result in results:\n",
        "        wrapped_title = wrap_text(result['title'], width=30)\n",
        "        wrapped_url = wrap_text(result['url'], width=30)\n",
        "        wrapped_text = wrap_text(result['text'], width=50)\n",
        "        table.add_row([wrapped_title, wrapped_url, wrapped_text])\n",
        "\n",
        "    print(table)\n",
        "\n",
        "\n",
        "\n",
        "def user_input_kg(query):\n",
        "  if len(query)>0:\n",
        "    curr_query = query\n",
        "  else:\n",
        "    curr_query = 'use cases of transformers in machine learning'\n",
        "  query = curr_query\n",
        "  urls = google_search(query, api_key, cse_id)\n",
        "  all_entities = set()\n",
        "  all_relationships = []\n",
        "  results = []\n",
        "\n",
        "  for url in urls:\n",
        "      info = extract_relevant_info(url)\n",
        "      if \"error\" not in info:\n",
        "          info['url'] = url\n",
        "          results.append(info)\n",
        "  print_formatted_output(results)\n",
        "  return results\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For handling missing text\n",
        "# Extract information using the Google API key and Custom search engine id\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import spacy\n",
        "import textwrap\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "# Load the spaCy language model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "def google_search(query, api_key, cse_id, num_results=5):\n",
        "    search_url = f\"https://www.googleapis.com/customsearch/v1?q={query}&key={api_key}&cx={cse_id}&num={num_results}\"\n",
        "    response = requests.get(search_url)\n",
        "    results = response.json().get('items', [])\n",
        "    print(\"Google search completed\")\n",
        "    return [item['link'] for item in results]\n",
        "\n",
        "def extract_relevant_info(url):\n",
        "    try:\n",
        "        # Set a timeout for the request\n",
        "        response = requests.get(url, timeout=10)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        title_tag = soup.find('title')\n",
        "        if not title_tag:\n",
        "            print(f\"Skipping {url}: No title tag found.\")\n",
        "            return {\"error\": \"No title tag found\"}\n",
        "\n",
        "        title = title_tag.get_text()\n",
        "        paragraphs = soup.find_all('p')\n",
        "        text = \"\\n\".join([p.get_text() for p in paragraphs])\n",
        "\n",
        "        return {\"title\": title, \"text\": text}\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Skipping {url}: {str(e)}\")\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "# Function to wrap text for table display\n",
        "def wrap_text(text, width):\n",
        "    return \"\\n\".join(textwrap.wrap(text, width=width))\n",
        "\n",
        "# Function to format and print the output using PrettyTable\n",
        "def print_formatted_output(results):\n",
        "    table = PrettyTable()\n",
        "    table.field_names = [\"Title\", \"Text\"]\n",
        "\n",
        "    for result in results:\n",
        "        wrapped_title = wrap_text(result['title'], width=30)\n",
        "        wrapped_text = wrap_text(result['text'], width=50)\n",
        "        table.add_row([wrapped_title, wrapped_text])\n",
        "\n",
        "    print(table)\n",
        "\n",
        "# Function to save the extracted text and title to a file\n",
        "def save_to_file(results, filename=\"output.txt\"):\n",
        "    with open(filename, \"w\") as file:\n",
        "        for result in results:\n",
        "            file.write(result['title'] + \"\\n\\n\")\n",
        "            file.write(result['text'] + \"\\n\")\n",
        "            file.write(\"\\n\" + \"=\"*50 + \"\\n\\n\")  # Separator between entries\n",
        "\n",
        "def user_input_kg(query):\n",
        "    if len(query) > 0:\n",
        "        curr_query = query\n",
        "    else:\n",
        "        curr_query = 'use cases of transformers in machine learning'\n",
        "    query = curr_query\n",
        "    urls = google_search(query, api_key, cse_id)\n",
        "    all_entities = set()\n",
        "    all_relationships = []\n",
        "    results = []\n",
        "\n",
        "    for url in urls:\n",
        "        print(\"Currently processing\", url)\n",
        "        info = extract_relevant_info(url)\n",
        "        if \"error\" not in info:\n",
        "            results.append(info)\n",
        "\n",
        "    print_formatted_output(results)\n",
        "    return results\n",
        "\n",
        "\n",
        "user_input_kg(\"Altera infuses AI\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEF3AvnwOSMY",
        "outputId": "c8e3f9d8-7b8d-41cc-b43a-cd65e2ebb645"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google search completed\n",
            "Currently processing https://www.allaboutcircuits.com/news/altera-infuses-ai-into-new-mid-range-fpgas/\n",
            "Skipping https://www.allaboutcircuits.com/news/altera-infuses-ai-into-new-mid-range-fpgas/: 403 Client Error: Forbidden for url: https://www.allaboutcircuits.com/news/altera-infuses-ai-into-new-mid-range-fpgas/\n",
            "Currently processing https://www.intel.com/content/www/us/en/newsroom/news/intel-altera-bring-ai-to-embedded-world.html\n",
            "Currently processing https://www.eetimes.com/embedded-world-2024-sandra-rivera-talks-about-altera-and-ai/\n",
            "Skipping https://www.eetimes.com/embedded-world-2024-sandra-rivera-talks-about-altera-and-ai/: HTTPSConnectionPool(host='www.eetimes.com', port=443): Read timed out. (read timeout=10)\n",
            "Currently processing https://www.linkedin.com/posts/sandra-rivera-6a24291_women4ew-womenintech-wearealtera-activity-7183884756843999232-ZNMo\n",
            "Currently processing https://ni.linkedin.com/posts/sandra-rivera-6a24291_intelvision-iamintel-activity-7067988817651118080-tIH1\n",
            "+--------------------------------+----------------------------------------------------+\n",
            "|             Title              |                        Text                        |\n",
            "+--------------------------------+----------------------------------------------------+\n",
            "| Intel and Altera Announce Edge | You can easily search the entire Intel.com site in |\n",
            "|  and FPGA Offerings for AI at  |   several ways. You can also try the quick links   |\n",
            "|          Embedded...           |  below to see results for most popular searches.   |\n",
            "|                                |      The browser version you are using is not      |\n",
            "|                                |     recommended for this site.Please consider      |\n",
            "|                                | upgrading to the latest version of your browser by |\n",
            "|                                |   clicking one of the following links. New edge-   |\n",
            "|                                | optimized processors and FPGAs bring AI everywhere |\n",
            "|                                |  across edge computing markets including retail,   |\n",
            "|                                | industrial and healthcare.  April 8, 2024 Contact  |\n",
            "|                                |     Intel PR  Follow Intel Newsroom on social:     |\n",
            "|                                | By  What’s New: Today at Embedded World, Intel and |\n",
            "|                                |   Altera, an Intel Company, announced new edge-    |\n",
            "|                                |    optimized processors, FPGAs and programmable    |\n",
            "|                                |    market-ready solutions extending powerful AI    |\n",
            "|                                |  capabilities into edge computing. These products  |\n",
            "|                                |  will power AI-enabled edge devices applicable to  |\n",
            "|                                | industries across retail, healthcare, industrial,  |\n",
            "|                                |     automotive, defense and aerospace.  What’s     |\n",
            "|                                | New: Today at Embedded World, Intel and Altera, an |\n",
            "|                                |    Intel Company, announced new edge-optimized     |\n",
            "|                                |  processors, FPGAs and programmable market-ready   |\n",
            "|                                | solutions extending powerful AI capabilities into  |\n",
            "|                                |   edge computing. These products will power AI-    |\n",
            "|                                |   enabled edge devices applicable to industries    |\n",
            "|                                | across retail, healthcare, industrial, automotive, |\n",
            "|                                |  defense and aerospace. “This next generation of   |\n",
            "|                                | Intel edge-optimized processors and discrete GPUs  |\n",
            "|                                |     unleashes powerful AI capabilities to help     |\n",
            "|                                |     businesses more seamlessly incorporate AI      |\n",
            "|                                |  alongside compute, media and graphics workloads.  |\n",
            "|                                |     From manufacturing to healthcare, Intel’s      |\n",
            "|                                | extensive edge AI experience and breadth and depth |\n",
            "|                                |    of edge-ready silicon and software help our     |\n",
            "|                                |  customers deliver AI where they need it most for  |\n",
            "|                                |   better business outcomes.”  Why It Matters for   |\n",
            "|                                |    Edge and AI: Why It Matters for Edge and AI:    |\n",
            "|                                |    Intel’s new series of edge-optimized Intel®     |\n",
            "|                                |     Core™ Ultra, Intel® Core™ and Intel Atom®      |\n",
            "|                                |    processors and discrete Intel® Arc™ graphics    |\n",
            "|                                |  processing units (GPUs) will advance innovation   |\n",
            "|                                | for artificial intelligence, visual computing and  |\n",
            "|                                |    media processing – in support of faster and     |\n",
            "|                                | smarter decisions with on-premise edge computing.  |\n",
            "|                                |  Agilex™ 5 FPGAs for mid-range applications with   |\n",
            "|                                | best-in-class performance per watt target a broad  |\n",
            "|                                | set of applications, including video, industrial,  |\n",
            "|                                | robotics, medical and others. Agilex 5 FPGAs with  |\n",
            "|                                |   AI infused into the fabric offer a high level    |\n",
            "|                                | of integration, low latency and improved computing |\n",
            "|                                |  capabilities for intelligent edge applications.   |\n",
            "|                                |   Expanding on Intel’s commitment to bringing AI   |\n",
            "|                                | everywhere, today's announcements utilize built-in |\n",
            "|                                | AI acceleration in the new series of processors to |\n",
            "|                                | power the next generation of edge devices.  Why It |\n",
            "|                                |  Matters for Edge and AI: Why It Matters for Edge  |\n",
            "|                                |    and AI: Intel’s new series of edge-optimized    |\n",
            "|                                |  Intel® Core™ Ultra, Intel® Core™ and Intel Atom®  |\n",
            "|                                |    processors and discrete Intel® Arc™ graphics    |\n",
            "|                                |  processing units (GPUs) will advance innovation   |\n",
            "|                                | for artificial intelligence, visual computing and  |\n",
            "|                                |    media processing – in support of faster and     |\n",
            "|                                | smarter decisions with on-premise edge computing.  |\n",
            "|                                |  Agilex™ 5 FPGAs for mid-range applications with   |\n",
            "|                                | best-in-class performance per watt target a broad  |\n",
            "|                                | set of applications, including video, industrial,  |\n",
            "|                                | robotics, medical and others. Agilex 5 FPGAs with  |\n",
            "|                                |   AI infused into the fabric offer a high level    |\n",
            "|                                | of integration, low latency and improved computing |\n",
            "|                                |  capabilities for intelligent edge applications.   |\n",
            "|                                |   Expanding on Intel’s commitment to bringing AI   |\n",
            "|                                | everywhere, today's announcements utilize built-in |\n",
            "|                                | AI acceleration in the new series of processors to |\n",
            "|                                |   power the next generation of edge devices. An    |\n",
            "|                                | image shows the FPGAi Altera company logo. Altera  |\n",
            "|                                | helps customers achieve their business goals with  |\n",
            "|                                |  new AI capabilities to support high-performance   |\n",
            "|                                |   and mid-range FPGA-based solutions, developer    |\n",
            "|                                |  usability and workload agility. (Credit: Altera,  |\n",
            "|                                |   an Intel Company) An image shows an Intel Atom   |\n",
            "|                                |   processor badge. Intel Atom processors x7000C    |\n",
            "|                                | Series delivers ramped-up processor base frequency |\n",
            "|                                |     in up to eight Efficient-cores. Intel Atom     |\n",
            "|                                |  processors x7000RE Series features built-in deep  |\n",
            "|                                |  learning inference capabilities. (Credit: Intel   |\n",
            "|                                |  Corporation) An image shows an Intel Core Ultra   |\n",
            "|                                |    processor badge. Intel Core Ultra processors    |\n",
            "|                                | combine the Intel Arc GPU and a neural processing  |\n",
            "|                                |   unit (NPU) with LGA socket flexibility into a    |\n",
            "|                                |  simplified system-on-chip (SoC). The new SoC is   |\n",
            "|                                |    designed to enable generative AI (GenAI) and    |\n",
            "|                                | demanding graphics workloads at the edge. (Credit: |\n",
            "|                                |  Intel Corporation) An image shows the Intel Arc   |\n",
            "|                                |  GPU for Edge badge. The Intel® Arc™ GPU for Edge  |\n",
            "|                                |   boosts performance and edge AI capabilities on   |\n",
            "|                                |    legacy Intel Core systems as a discrete GPU,    |\n",
            "|                                |    providing accelerated AI, media and graphics    |\n",
            "|                                |  processing power. (Credit: Intel Corporation) An  |\n",
            "|                                |  image shows an Intel Core processor badge. Intel  |\n",
            "|                                | Core processors combine the GPU power of 13th Gen  |\n",
            "|                                |    Intel Core mobile processors with LGA socket    |\n",
            "|                                |  flexibility to prioritize system scalability and  |\n",
            "|                                |  speed to deployment. (Credit: Intel Corporation)  |\n",
            "|                                |   An image shows the Agilex 5 field programmable   |\n",
            "|                                |      gate array. Agilex 5 FPGAs for mid-range      |\n",
            "|                                |  applications with best-in-class performance per   |\n",
            "|                                | watt target a broad set of applications, including |\n",
            "|                                |  video, industrial, robotics, medical and others.  |\n",
            "|                                |  (Credit: Altera, an Intel Company) Download all   |\n",
            "|                                |  images (ZIP, 2 MB)  Download all images (ZIP, 2   |\n",
            "|                                | MB) How Intel Expands AI to Embedded Edge Devices: |\n",
            "|                                |  Building on its expansive installed base of more  |\n",
            "|                                |   than 90,000 edge deployments, Intel delivers a   |\n",
            "|                                |   wave of edge-optimized processors and GPUs to    |\n",
            "|                                |    power the next generation of AI-enabled edge    |\n",
            "|                                | devices.    Intel Core Ultra processors for edge:  |\n",
            "|                                |  Offering up to 5.02x better image classification  |\n",
            "|                                | inference performance compared to 14th Gen Intel®  |\n",
            "|                                |    Core™ desktop processors,1 Intel Core Ultra     |\n",
            "|                                | processors combine the Intel Arc GPU2 and a neural |\n",
            "|                                | processing unit (NPU)3 with LGA socket flexibility |\n",
            "|                                |  into a simplified system-on-chip (SoC). The new   |\n",
            "|                                |  SoC is designed to enable generative AI (GenAI)   |\n",
            "|                                |  and demanding graphics workloads at the edge for  |\n",
            "|                                |   retail, education, smart cities and industrial   |\n",
            "|                                | customers, including GenAI-enabled kiosk and smart |\n",
            "|                                |     point-of-sale systems in brick-and-mortar      |\n",
            "|                                |  retailers, interactive whiteboards for enhanced   |\n",
            "|                                |  in-classroom experiences and AI vision-enhanced   |\n",
            "|                                | industrial devices for manufacturing and roadside  |\n",
            "|                                | units.  Intel Core processors for edge: Intel Core |\n",
            "|                                |    processors combine the GPU power of 13th Gen    |\n",
            "|                                |   Intel® Core® mobile processors with LGA socket   |\n",
            "|                                |  flexibility to prioritize system scalability and  |\n",
            "|                                |   speed to deployment. This series of processors   |\n",
            "|                                | optimized for the edge offers up to 2.57x greater  |\n",
            "|                                |  graphics performance compared to 13th Gen Intel®  |\n",
            "|                                |  Core™ desktop processors4 by leveraging up to 3   |\n",
            "|                                |   times more graphics execution units alongside    |\n",
            "|                                | performance hybrid architecture with Intel® Thread |\n",
            "|                                | Director5 and an LGA socket-based design offering  |\n",
            "|                                |  customers more edge AI and graphics performance   |\n",
            "|                                |  without sacrificing hardware setup flexibility.   |\n",
            "|                                |  Intel Atom® processors x7000C Series: Intel Atom  |\n",
            "|                                |    processors x7000C Series delivers ramped-up     |\n",
            "|                                | processor base frequency in up to eight Efficient- |\n",
            "|                                |    cores to drive exceptional packet processing    |\n",
            "|                                |      throughput for enterprise networking and      |\n",
            "|                                |      telecommunications devices. This enables      |\n",
            "|                                | telecommunications businesses to use built-in deep |\n",
            "|                                |   learning inference capabilities to support the   |\n",
            "|                                |  detection of zero-day threats, boost packet and   |\n",
            "|                                |  control plane processing for OpenSSL/IPSec using  |\n",
            "|                                |    native instruction sets, and leverage Intel     |\n",
            "|                                | security features to harden networks. Intel Atom®  |\n",
            "|                                |      processors x7000RE Series: Primarily for      |\n",
            "|                                | industrial and manufacturing end users, Intel Atom |\n",
            "|                                |  processors x7000RE Series features built-in deep  |\n",
            "|                                |    learning inference capabilities and up to 32    |\n",
            "|                                |  graphics execution units in a ruggedized, power-  |\n",
            "|                                | efficient 6W-12W BGA package offering up to 9.83x  |\n",
            "|                                |   image classification performance compared with   |\n",
            "|                                |   Intel Atom processors x6000RE Series6. The new   |\n",
            "|                                |    processor supports fanless designs to enable    |\n",
            "|                                |  Industry 4.0 automation for key use cases in AI-  |\n",
            "|                                |  automated tending, warehouse AMR, in-line visual  |\n",
            "|                                |   inspection for quality control and ruggedized    |\n",
            "|                                |   industrial PC scenarios.     Additionally, the   |\n",
            "|                                |  Intel® Arc™ GPU for Edge boosts performance and   |\n",
            "|                                | edge AI capabilities on legacy Intel Core systems  |\n",
            "|                                |  as a discrete GPU providing accelerated AI, and   |\n",
            "|                                |   media and graphics processing power. Intel Arc   |\n",
            "|                                |  GPUs also eliminate vendor lock-in with an open,  |\n",
            "|                                | standards-based software stack to offer choice and |\n",
            "|                                |   flexibility when building high-performance AI    |\n",
            "|                                |     applications and solutions.  How Altera’s      |\n",
            "|                                | Portfolio Will Accelerate Customer AI Innovations: |\n",
            "|                                |   Following the FPGA Vision Webcast in February,   |\n",
            "|                                |  Altera announced additional updates to its FPGA   |\n",
            "|                                |  portfolio, providing flexible solutions to help   |\n",
            "|                                | customers solve their challenges from the cloud to |\n",
            "|                                | network to the intelligent edge. “We announced the |\n",
            "|                                |  launch of the new Altera brand with the goal of   |\n",
            "|                                | bringing leading technologies and innovations more |\n",
            "|                                | quickly to the FPGA market. Today, we are excited  |\n",
            "|                                |  about the next phase in our 10-plus year journey  |\n",
            "|                                |   delivering flexible AI solutions,” said Sandra   |\n",
            "|                                | Rivera, Altera chief executive officer. “Altera is |\n",
            "|                                |   leading the new FPGAi era by tightly coupling    |\n",
            "|                                |    programmability with tensor capabilities and    |\n",
            "|                                |   infusing FPGA and AI tools for a best-in-class   |\n",
            "|                                |   developer experience. Agilex 5, the first FPGA   |\n",
            "|                                |   with AI-infused throughout the fabric, is now    |\n",
            "|                                |  broadly available.” Altera Leads the New Era of   |\n",
            "|                                |    FPGAi: Altera helps customers achieve their     |\n",
            "|                                | business goals with new AI capabilities to support |\n",
            "|                                |     high-performance and mid-range FPGA-based      |\n",
            "|                                |    solutions, developer usability and workload     |\n",
            "|                                | agility. FPGA AI Suite adds support for Agilex™ 5  |\n",
            "|                                |  SoC FPGAs. The AI tool flow allows developers to  |\n",
            "|                                | use existing and popular AI frameworks, along with |\n",
            "|                                |    the Intel® OpenVINO™ toolkit and the FPGA AI    |\n",
            "|                                |   Suite, to create AI intellectual property (IP)   |\n",
            "|                                | blocks and easily drop them into the FPGA design.  |\n",
            "|                                | More information is available at the FPGA AI Suite |\n",
            "|                                |  website.    Performance per Watt Leader Agilex 5  |\n",
            "|                                |   SoC FPGAs Broadly Available: Agilex 5 devices,   |\n",
            "|                                |     with best-in-class AI and up to 2x better      |\n",
            "|                                | performance per watt versus competing 7 nanometer  |\n",
            "|                                |  FPGAs7, are designed to deliver high performance  |\n",
            "|                                |  with lower power in a modern SoC subsystem with   |\n",
            "|                                |    small form factor package options, allowing     |\n",
            "|                                |  customers and developers to add AI capability to  |\n",
            "|                                |   their products without the need for dedicated    |\n",
            "|                                |     accelerators. Geared toward a broad set of     |\n",
            "|                                |    embedded applications, Agilex 5 devices and     |\n",
            "|                                |    development kits are broadly available with     |\n",
            "|                                |       Quartus® Prime software support. Broad       |\n",
            "|                                | availability also includes support by a large and  |\n",
            "|                                |    growing list of ecosystem partners providing    |\n",
            "|                                |  additional boards, system-on-modules (SOMs), IP   |\n",
            "|                                | and various value-added services. More information |\n",
            "|                                |    about Agilex 5 devices, including technical     |\n",
            "|                                |   details, is available at the Agilex 5 SoC FPGA   |\n",
            "|                                |  website. Unleash the Power of Agilex 5 E-Series   |\n",
            "|                                | Devices with Quartus Prime Pro Edition S/W Version |\n",
            "|                                | 24.1: The latest version of Altera’s cutting-edge  |\n",
            "|                                | software is available for download, offering free  |\n",
            "|                                |  access to the latest Agilex 5 E-Series SoC FPGAs  |\n",
            "|                                |    and selected complementary IP cores. Quartus    |\n",
            "|                                | offers a streamlined experience for an IP-centric  |\n",
            "|                                |   design flow, configurable example designs and    |\n",
            "|                                |  unprecedented capabilities including a powerful   |\n",
            "|                                | new Agilex 5 SoC subsystem (hard-processor system  |\n",
            "|                                | featuring dual-core Arm Cortex A76, dual-core Arm  |\n",
            "|                                |  Cortex A55 processors and various peripherals).   |\n",
            "|                                | This new SoC subsystem is also supported by third- |\n",
            "|                                |  party tools recently updated to support Agilex 5  |\n",
            "|                                |   devices. More information is available at the    |\n",
            "|                                |  Quartus Prime Pro website. Portfolio Breadth and  |\n",
            "|                                |  Industry-Leading Longevity: Altera continues to   |\n",
            "|                                |   deliver a broad portfolio, including industry-   |\n",
            "|                                | leading longevity with selected MAX® and Cyclone®  |\n",
            "|                                |  cost- and power-optimized product families’ life  |\n",
            "|                                |     cycles extended to 2040 and later, further     |\n",
            "|                                | improving supply chain resilience. Future Agilex™  |\n",
            "|                                |   3 devices, coming soon, will expand the Agilex   |\n",
            "|                                | portfolio to deliver even greater breadth.    Why  |\n",
            "|                                |    It Matters for Altera FPGAs: In an era where    |\n",
            "|                                | technological advancements are integral to staying |\n",
            "|                                | competitive, Intel’s new edge-optimized processors |\n",
            "|                                | and solutions deliver the capabilities enterprises |\n",
            "|                                | need to innovate, be efficient and improve time to |\n",
            "|                                |    market. Altera delivers flexibility and re-     |\n",
            "|                                |    programmability to accelerate innovators by     |\n",
            "|                                |    providing easy-to-design and easy-to-deploy     |\n",
            "|                                |      leadership programmable solutions. These      |\n",
            "|                                |  processors, FPGAs and associated solutions allow  |\n",
            "|                                |  enterprises to leverage the tremendous amount of  |\n",
            "|                                | data generated at the edge to deploy sophisticated |\n",
            "|                                | embedded AI devices across a variety of industries |\n",
            "|                                |     to streamline operations, improve customer     |\n",
            "|                                |    satisfaction and incorporate advanced visual    |\n",
            "|                                | workloads.  “The FPGA AI Suite from Altera allowed |\n",
            "|                                | the Tiami team to rapidly incorporate our IP into  |\n",
            "|                                |    an intricate digital signal processing (DSP)    |\n",
            "|                                |   pipeline,” said Amitav Mukherjee, CEO at Tiami   |\n",
            "|                                |   Networks. “This significantly reduced the time   |\n",
            "|                                |   required to integrate AI capabilities with 5G    |\n",
            "|                                | signal processing from an estimated six months to  |\n",
            "|                                |   just eight weeks. Our engineering team clearly   |\n",
            "|                                |  recognized the value proposition offered by the   |\n",
            "|                                |  FPGA in preprocessing wireless signals received   |\n",
            "|                                |     from the antenna and performing real-time      |\n",
            "|                                |  inference, resulting in a successful demo.” More  |\n",
            "|                                |   Context: Intel Core Ultra Processors for Edge    |\n",
            "|                                | (PDF) | Intel Processers for the Edge | Intel Arc  |\n",
            "|                                |   GPU for Edge |  Intel Launches Altera, Its New   |\n",
            "|                                |  Standalone FPGA Company  How Intel Expands AI to  |\n",
            "|                                |  Embedded Edge Devices: Building on its expansive  |\n",
            "|                                |      installed base of more than 90,000 edge       |\n",
            "|                                |    deployments, Intel delivers a wave of edge-     |\n",
            "|                                |  optimized processors and GPUs to power the next   |\n",
            "|                                |     generation of AI-enabled edge devices.         |\n",
            "|                                | Additionally, the Intel® Arc™ GPU for Edge boosts  |\n",
            "|                                |   performance and edge AI capabilities on legacy   |\n",
            "|                                |   Intel Core systems as a discrete GPU providing   |\n",
            "|                                | accelerated AI, and media and graphics processing  |\n",
            "|                                | power. Intel Arc GPUs also eliminate vendor lock-  |\n",
            "|                                | in with an open, standards-based software stack to |\n",
            "|                                |  offer choice and flexibility when building high-  |\n",
            "|                                |  performance AI applications and solutions.  How   |\n",
            "|                                |   Altera’s Portfolio Will Accelerate Customer AI   |\n",
            "|                                | Innovations: Following the FPGA Vision Webcast in  |\n",
            "|                                |  February, Altera announced additional updates to  |\n",
            "|                                |  its FPGA portfolio, providing flexible solutions  |\n",
            "|                                | to help customers solve their challenges from the  |\n",
            "|                                |   cloud to network to the intelligent edge. “We    |\n",
            "|                                | announced the launch of the new Altera brand with  |\n",
            "|                                |   the goal of bringing leading technologies and    |\n",
            "|                                |    innovations more quickly to the FPGA market.    |\n",
            "|                                | Today, we are excited about the next phase in our  |\n",
            "|                                |    10-plus year journey delivering flexible AI     |\n",
            "|                                |    solutions,” said Sandra Rivera, Altera chief    |\n",
            "|                                |   executive officer. “Altera is leading the new    |\n",
            "|                                | FPGAi era by tightly coupling programmability with |\n",
            "|                                | tensor capabilities and infusing FPGA and AI tools |\n",
            "|                                |  for a best-in-class developer experience. Agilex  |\n",
            "|                                |  5, the first FPGA with AI-infused throughout the  |\n",
            "|                                |  fabric, is now broadly available.” Altera Leads   |\n",
            "|                                |    the New Era of FPGAi: Altera helps customers    |\n",
            "|                                |      achieve their business goals with new AI      |\n",
            "|                                | capabilities to support high-performance and mid-  |\n",
            "|                                |  range FPGA-based solutions, developer usability   |\n",
            "|                                |  and workload agility. FPGA AI Suite adds support  |\n",
            "|                                |  for Agilex™ 5 SoC FPGAs. The AI tool flow allows  |\n",
            "|                                |     developers to use existing and popular AI      |\n",
            "|                                |    frameworks, along with the Intel® OpenVINO™     |\n",
            "|                                |    toolkit and the FPGA AI Suite, to create AI     |\n",
            "|                                | intellectual property (IP) blocks and easily drop  |\n",
            "|                                |   them into the FPGA design. More information is   |\n",
            "|                                | available at the FPGA AI Suite website.     Why It |\n",
            "|                                |     Matters for Altera FPGAs: In an era where      |\n",
            "|                                | technological advancements are integral to staying |\n",
            "|                                | competitive, Intel’s new edge-optimized processors |\n",
            "|                                | and solutions deliver the capabilities enterprises |\n",
            "|                                | need to innovate, be efficient and improve time to |\n",
            "|                                |    market. Altera delivers flexibility and re-     |\n",
            "|                                |    programmability to accelerate innovators by     |\n",
            "|                                |    providing easy-to-design and easy-to-deploy     |\n",
            "|                                |      leadership programmable solutions. These      |\n",
            "|                                |  processors, FPGAs and associated solutions allow  |\n",
            "|                                |  enterprises to leverage the tremendous amount of  |\n",
            "|                                | data generated at the edge to deploy sophisticated |\n",
            "|                                | embedded AI devices across a variety of industries |\n",
            "|                                |     to streamline operations, improve customer     |\n",
            "|                                |    satisfaction and incorporate advanced visual    |\n",
            "|                                | workloads.  “The FPGA AI Suite from Altera allowed |\n",
            "|                                | the Tiami team to rapidly incorporate our IP into  |\n",
            "|                                |    an intricate digital signal processing (DSP)    |\n",
            "|                                |   pipeline,” said Amitav Mukherjee, CEO at Tiami   |\n",
            "|                                |   Networks. “This significantly reduced the time   |\n",
            "|                                |   required to integrate AI capabilities with 5G    |\n",
            "|                                | signal processing from an estimated six months to  |\n",
            "|                                |   just eight weeks. Our engineering team clearly   |\n",
            "|                                |  recognized the value proposition offered by the   |\n",
            "|                                |  FPGA in preprocessing wireless signals received   |\n",
            "|                                |     from the antenna and performing real-time      |\n",
            "|                                |  inference, resulting in a successful demo.” More  |\n",
            "|                                |   Context: Intel Core Ultra Processors for Edge    |\n",
            "|                                | (PDF) | Intel Processers for the Edge | Intel Arc  |\n",
            "|                                |   GPU for Edge |  Intel Launches Altera, Its New   |\n",
            "|                                | Standalone FPGA Company The Small Print:  Altera,  |\n",
            "|                                |    the Altera logo, and other Altera marks are     |\n",
            "|                                | trademarks of Altera.   Other names and brands may |\n",
            "|                                |      be claimed as the property of others. 1       |\n",
            "|                                |   Performance varies by use, configuration, and    |\n",
            "|                                |            other factors. Learn more at            |\n",
            "|                                |   intel.com/processorclaims: Intel® Core™ Ultra    |\n",
            "|                                |   processors, Edge. Results may vary.   2 Intel®   |\n",
            "|                                |   Arc™ GPU is only available on select H-Series,   |\n",
            "|                                | Intel® Core™ Ultra processor-powered systems with  |\n",
            "|                                |  at least 16GB of system memory in a dual-channel  |\n",
            "|                                |  configuration. OEM enablement is required; check  |\n",
            "|                                |    with OEM for system configuration details.      |\n",
            "|                                |  3 Intel® AI Boost enablement limited at launch.   |\n",
            "|                                |  4 Performance varies by use, configuration, and   |\n",
            "|                                |            other factors. Learn more at            |\n",
            "|                                |         intel.com/processorclaims: Intel®          |\n",
            "|                                |     Core™ processors, Edge. Results may vary.      |\n",
            "|                                |  5 Support for Intel® Thread Director is expected  |\n",
            "|                                |   in Windows 11 IoT Enterprise LTSC and Linux  6   |\n",
            "|                                |   Performance varies by use, configuration, and    |\n",
            "|                                |            other factors. Learn more at            |\n",
            "|                                | intel.com/processorclaims: Intel Atom® Processors. |\n",
            "|                                | Results may vary.  7 FPGA performance per watt:  h |\n",
            "|                                | ttps://edc.intel.com/content/www/us/en/products/pe |\n",
            "|                                |   rformance/benchmarks/agilex-fpga/. Results may   |\n",
            "|                                |   vary.    The Small Print:  Altera, the Altera    |\n",
            "|                                |   logo, and other Altera marks are trademarks of   |\n",
            "|                                | Altera.   Other names and brands may be claimed as |\n",
            "|                                |  the property of others. 1 Performance varies by   |\n",
            "|                                | use, configuration, and other factors. Learn more  |\n",
            "|                                |  at intel.com/processorclaims: Intel® Core™ Ultra  |\n",
            "|                                |   processors, Edge. Results may vary.   2 Intel®   |\n",
            "|                                |   Arc™ GPU is only available on select H-Series,   |\n",
            "|                                | Intel® Core™ Ultra processor-powered systems with  |\n",
            "|                                |  at least 16GB of system memory in a dual-channel  |\n",
            "|                                |  configuration. OEM enablement is required; check  |\n",
            "|                                |    with OEM for system configuration details.      |\n",
            "|                                |  3 Intel® AI Boost enablement limited at launch.   |\n",
            "|                                |  4 Performance varies by use, configuration, and   |\n",
            "|                                |            other factors. Learn more at            |\n",
            "|                                |         intel.com/processorclaims: Intel®          |\n",
            "|                                |     Core™ processors, Edge. Results may vary.      |\n",
            "|                                |  5 Support for Intel® Thread Director is expected  |\n",
            "|                                |   in Windows 11 IoT Enterprise LTSC and Linux  6   |\n",
            "|                                |   Performance varies by use, configuration, and    |\n",
            "|                                |            other factors. Learn more at            |\n",
            "|                                | intel.com/processorclaims: Intel Atom® Processors. |\n",
            "|                                | Results may vary.  7 FPGA performance per watt:  h |\n",
            "|                                | ttps://edc.intel.com/content/www/us/en/products/pe |\n",
            "|                                |   rformance/benchmarks/agilex-fpga/. Results may   |\n",
            "|                                | vary.    Altera,  Internet of Things,  Artificial  |\n",
            "|                                | Intelligence  About Intel Intel (Nasdaq: INTC) is  |\n",
            "|                                |    an industry leader, creating world-changing     |\n",
            "|                                |    technology that enables global progress and     |\n",
            "|                                |    enriches lives. Inspired by Moore’s Law, we     |\n",
            "|                                |    continuously work to advance the design and     |\n",
            "|                                |  manufacturing of semiconductors to help address   |\n",
            "|                                |  our customers’ greatest challenges. By embedding  |\n",
            "|                                | intelligence in the cloud, network, edge and every |\n",
            "|                                | kind of computing device, we unleash the potential |\n",
            "|                                | of data to transform business and society for the  |\n",
            "|                                |  better. To learn more about Intel’s innovations,  |\n",
            "|                                |  go to newsroom.intel.com and intel.com. © Intel   |\n",
            "|                                | Corporation. Intel, the Intel logo and other Intel |\n",
            "|                                |  marks are trademarks of Intel Corporation or its  |\n",
            "|                                |    subsidiaries. Other names and brands may be     |\n",
            "|                                |      claimed as the property of others. Intel      |\n",
            "|                                |     technologies may require enabled hardware,     |\n",
            "|                                |  software or service activation. // No product or  |\n",
            "|                                | component can be absolutely secure. // Your costs  |\n",
            "|                                |   and results may vary. // Performance varies by   |\n",
            "|                                |  use, configuration and other factors. // See our  |\n",
            "|                                |  complete legal Notices and Disclaimers. // Intel  |\n",
            "|                                |    is committed to respecting human rights and     |\n",
            "|                                |    avoiding causing or contributing to adverse     |\n",
            "|                                | impacts on human rights. See Intel’s Global Human  |\n",
            "|                                |  Rights Principles. Intel’s products and software  |\n",
            "|                                | are intended only to be used in applications that  |\n",
            "|                                |  do not cause or contribute to adverse impacts on  |\n",
            "|                                |                   human rights.                    |\n",
            "|   Sandra Rivera on LinkedIn:   |                        Agree & Join LinkedIn       |\n",
            "|     #women4ew #womenintech     | By clicking Continue to join or sign in, you agree |\n",
            "| #wearealtera #ai | 13 comments |  to LinkedIn‚Äôs User Agreement, Privacy Policy,   |\n",
            "|                                | and Cookie Policy.      A great #women4ew event at |\n",
            "|                                |     embedded world Exhibition&Conference today     |\n",
            "|                                |   covering various topics from addressing gender   |\n",
            "|                                |  bias in AI algorithms to discussing the critical  |\n",
            "|                                |  role diversity plays in innovation. At Altera we  |\n",
            "|                                | create a culture that positively impacts the work  |\n",
            "|                                |  experience and development of women. So, it has   |\n",
            "|                                |  filled me with hope and optimism to see so many   |\n",
            "|                                |   women in this industry come together to share    |\n",
            "|                                |   their experience and pave the way for the next   |\n",
            "|                                | generation of #womenintech #WeAreAltera #AI  Loved |\n",
            "|                                |   the insights on gender bias & diversity in AI!   |\n",
            "|                                |  Plato said wisdom begins in wonder, reminding us  |\n",
            "|                                |  that diversity fuels innovation by widening our   |\n",
            "|                                | perspectives üåü #womenintech #innovation  I love |\n",
            "|                                | the topic - \"how diversity can impact innovation\"  |\n",
            "|                                | reminded me of why the military did not put all of |\n",
            "|                                | the same \"Human Dynamic\" people together on teams  |\n",
            "|                                |  ( higher injury rates) and Margaret Heffernan's   |\n",
            "|                                | super chickens TED talk! Martin Curley and I will  |\n",
            "|                                | release our second innovation book in Q4 \"Managing |\n",
            "|                                | Innovation in a Digital World\"- we will send you a |\n",
            "|                                |     copy!  Financial Cultural Operational and      |\n",
            "|                                |    Technical Consultant - Alpha Sense Financial    |\n",
            "|                                | Consulting Here's a remedy to the tribal feminism  |\n",
            "|                                |    agenda...  The solution is to unite around a    |\n",
            "|                                |    common set of principles and values, and the    |\n",
            "|                                |      Gordon Moore ethos and Grove Egalitarian      |\n",
            "|                                |   Meritocracy.    Glad to see Pat pushing this;    |\n",
            "|                                | Will you join him Sandra Rivera and create the One |\n",
            "|                                | Culture Bob Swan initiated.    There needs to be a |\n",
            "|                                |  lot of follow through.   What your espousing is   |\n",
            "|                                |  antithetical to good solid ethics and practices;  |\n",
            "|                                | don't you think?  https://www.linkedin.com/article |\n",
            "|                                |   /edit/7117624932322185216/   Thank you, Sandra   |\n",
            "|                                |      Rivera, for being an incredible part of       |\n",
            "|                                |  #women4ew!¬†üí™  We are absolutely honoured to   |\n",
            "|                                |      have such amazing women like you in the       |\n",
            "|                                |   #embeddedworld! Assembly Test Manufacturing GM   |\n",
            "|                                |  Communications & Chief of Staff Support | Senior  |\n",
            "|                                |  Technical Leader | IDM 2.0 & Foundry Programs |   |\n",
            "|                                |    Lean Six Sigma Blackbelt | Multicultural ERG    |\n",
            "|                                |  Alliance Chair at Intel Corporation This is way   |\n",
            "|                                |   too important thank you for being a leader in    |\n",
            "|                                |  this. Bias of any kind in AI algorithms at this   |\n",
            "|                                |     critical juncture of machine learning is a     |\n",
            "|                                |   continuation of status quo, which is not good    |\n",
            "|                                |  enough. Change can only happen with real actions  |\n",
            "|                                |  beyond intentions. Thanks for making it real and  |\n",
            "|                                |  hearing, supporting and hopefully responding to   |\n",
            "|                                |   these issues. Digital Marketing | Social Media   |\n",
            "|                                |      Management | Content Creation It's truly      |\n",
            "|                                |    empowering to see initiatives like #women4ew    |\n",
            "|                                |    fostering discussions on crucial topics like    |\n",
            "|                                | gender bias in AI and the importance of diversity  |\n",
            "|                                |  in innovation.   Great to see you pushing this.   |\n",
            "|                                | It's really needed and hitting a chord. I know of  |\n",
            "|                                |  one tech startup that had 10 men originally with  |\n",
            "|                                |  no women. Now it's up to 22 with 12 women and 10  |\n",
            "|                                |    men. But web talks are still all men. I help    |\n",
            "|                                | ambitious leaders build strong Executive Presence  |\n",
            "|                                |  so that they get rapid career growth and coveted  |\n",
            "|                                |     CXO roles I Executive & Leadership Coach I     |\n",
            "|                                |    Learning and Development | Training | Talent    |\n",
            "|                                |   Management That's fantastic to hear about your   |\n",
            "|                                |  experience! It's encouraging to see women coming  |\n",
            "|                                |  together to support each other and advocate for   |\n",
            "|                                |  positive change. Financial Cultural Operational   |\n",
            "|                                |  and Technical Consultant - Alpha Sense Financial  |\n",
            "|                                | Consulting A picture of true unity and diversity.  |\n",
            "|                                |     A place where diverse talents thinking and     |\n",
            "|                                |    experience makes the best and highest use of    |\n",
            "|                                |  scarce Human Resources...      The Gordon Moore   |\n",
            "|                                | ethos of Intels first 3 decades was a place where  |\n",
            "|                                |   everyone rallied around a common purpose and a   |\n",
            "|                                |     shared sense of identity. Solving digital      |\n",
            "|                                |  challenges for U.S companies @ RKTech | Dreamer   |\n",
            "|                                | who does @ Rikkeisoft | Forbes Tech Council Member |\n",
            "|                                |    Kudos to Altera for fostering a culture that    |\n",
            "|                                | supports and develops women in the tech industry!  |\n",
            "|                                |         To view or add a comment, sign in          |\n",
            "|                                |    Financial Cultural Operational and Technical    |\n",
            "|                                |   Consultant - Alpha Sense Financial Consulting    |\n",
            "|                                |  Here's a remedy to the tribal feminism agenda...  |\n",
            "|                                |  The solution is to unite around a common set of   |\n",
            "|                                | principles and values, and the Gordon Moore ethos  |\n",
            "|                                | and Grove Egalitarian Meritocracy.    Glad to see  |\n",
            "|                                | Pat pushing this;  Will you join him Sandra Rivera |\n",
            "|                                |   and create the One Culture Bob Swan initiated.   |\n",
            "|                                | There needs to be a lot of follow through.   What  |\n",
            "|                                |    your espousing is antithetical to good solid    |\n",
            "|                                |       ethics and practices; don't you think?       |\n",
            "|                                |   https://lnkd.in/gg6wt2fU  Here's our pitch for   |\n",
            "|                                | Intel to live out the true spirit of the Open Door |\n",
            "|                                |  culture, and regain its position as the cultural  |\n",
            "|                                |        standard bearer for Silicon Valley.         |\n",
            "|                                |  https://lnkd.in/gbckTSTV A great #women4ew event  |\n",
            "|                                |   at embedded world Exhibition&Conference today    |\n",
            "|                                |   covering various topics from addressing gender   |\n",
            "|                                |  bias in AI algorithms to discussing the critical  |\n",
            "|                                |  role diversity plays in innovation. At Altera we  |\n",
            "|                                | create a culture that positively impacts the work  |\n",
            "|                                |  experience and development of women. So, it has   |\n",
            "|                                |  filled me with hope and optimism to see so many   |\n",
            "|                                |   women in this industry come together to share    |\n",
            "|                                |   their experience and pave the way for the next   |\n",
            "|                                |    generation of #womenintech #WeAreAltera #AI     |\n",
            "|                                |         To view or add a comment, sign in          |\n",
            "|                                |  1,230 followers              Empowering Women in  |\n",
            "|                                | AI: A Journey of Inclusivity & Innovation üöÄ  At |\n",
            "|                                |       Resonant Consulting, we believe in the       |\n",
            "|                                |  transformative power of artificial intelligence   |\n",
            "|                                |    (AI) and its potential to enrich lives when     |\n",
            "|                                |   inclusivity is at the forefront.   Our latest    |\n",
            "|                                |   carousel celebrates the journey towards gender   |\n",
            "|                                | inclusivity in AI, spotlighting the essential role |\n",
            "|                                | of male allies and the untapped potential of women |\n",
            "|                                |  in shaping the future of technology. üåü  We're  |\n",
            "|                                |      calling on everyone, especially our male      |\n",
            "|                                |  counterparts, to join us in this movement. Your   |\n",
            "|                                |   support is crucial in creating an environment    |\n",
            "|                                |    where women can excel and contribute to AI's    |\n",
            "|                                |  limitless possibilities. Together, let's ensure   |\n",
            "|                                |    the AI journey is inclusive, empowering, and    |\n",
            "|                                |   beneficial for all. Dive into our carousel to    |\n",
            "|                                | learn more and be part of the change.   #WomenInAI |\n",
            "|                                |   #InclusiveTech #ResonantConsulting #WomenInAI    |\n",
            "|                                |  #InclusiveAI #AIForAll #GenderInclusivityInTech   |\n",
            "|                                |  #EmpowerHerAI #AIInnovationForAll #DiversityInAI  |\n",
            "|                                |         #FutureIsFemaleAI #MaleAlliesForAI         |\n",
            "|                                |  #EmpoweringWomenInTech #TechForGood #AIEquality   |\n",
            "|                                |         To view or add a comment, sign in          |\n",
            "|                                |  100,536 followers              Generative AI is   |\n",
            "|                                | rapidly transforming the world as we know it, with |\n",
            "|                                |  C-suite executives anticipating that nearly half  |\n",
            "|                                |   of workers on average will require reskilling    |\n",
            "|                                | within the next three years.  A recent BCG report  |\n",
            "|                                | underscores that senior women in tech are leading  |\n",
            "|                                |     the way in #GenAI adoption, utilizing the      |\n",
            "|                                |  #technology at rates 14 percentage points higher  |\n",
            "|                                |  than their male counterparts. However, women in   |\n",
            "|                                |  non-technical roles and junior women across all   |\n",
            "|                                | functions are not keeping pace.  What drives these |\n",
            "|                                |  gender disparities in GenAI adoption and how can  |\n",
            "|                                |          leaders narrow the gap? Find out          |\n",
            "|                                |  here:¬†https://on.bcg.com/4b98ld0 #GenerativeAI   |\n",
            "|                                | #WomenInTech #ArtificialIntelligence           To  |\n",
            "|                                |           view or add a comment, sign in           |\n",
            "|                                | Digital Content Manager | Strategist | Gen AI | Ex |\n",
            "|                                |  Adani Digital Labs, Ogilvy, Wunderman Thompson,   |\n",
            "|                                |        FCB | Social Stars Gold, Digies Gold        |\n",
            "|                                |  This research says senior managers are adopting   |\n",
            "|                                | Gen AI fast. But why don't I see this happening in |\n",
            "|                                |  advertising and marketing? I hear people talking  |\n",
            "|                                |   about using AI and individuals flaunting their   |\n",
            "|                                |   knwoledge about it. But no effort to make AI a   |\n",
            "|                                |  part of daily jobs. Will this change? Hopefully,  |\n",
            "|                                |  it will trickle down from the senior managers to  |\n",
            "|                                | their teams soon enough.                  100,536  |\n",
            "|                                |  followers              Generative AI is rapidly   |\n",
            "|                                | transforming the world as we know it, with C-suite |\n",
            "|                                |    executives anticipating that nearly half of     |\n",
            "|                                | workers on average will require reskilling within  |\n",
            "|                                |     the next three years.  A recent BCG report     |\n",
            "|                                | underscores that senior women in tech are leading  |\n",
            "|                                |     the way in #GenAI adoption, utilizing the      |\n",
            "|                                |  #technology at rates 14 percentage points higher  |\n",
            "|                                |  than their male counterparts. However, women in   |\n",
            "|                                |  non-technical roles and junior women across all   |\n",
            "|                                | functions are not keeping pace.  What drives these |\n",
            "|                                |  gender disparities in GenAI adoption and how can  |\n",
            "|                                |          leaders narrow the gap? Find out          |\n",
            "|                                |  here:¬†https://on.bcg.com/4b98ld0 #GenerativeAI   |\n",
            "|                                | #WomenInTech #ArtificialIntelligence           To  |\n",
            "|                                |           view or add a comment, sign in           |\n",
            "|                                |   3,072 followers              the vital role of   |\n",
            "|                                |  women in Artificial Intelligence (AI)! üåü Why   |\n",
            "|                                |  Female Representation in AI Matters: 1. Diverse   |\n",
            "|                                |     Perspectives 2. Ethical Considerations 3.      |\n",
            "|                                |   Inclusive Design 4. Inspiration and Mentorship   |\n",
            "|                                | Don't miss this chance to connect with AI experts  |\n",
            "|                                |      and innovators. #WomenInAI #AIInnovation      |\n",
            "|                                |  #womenempowerment #gwf23                   3,072  |\n",
            "|                                | followers              üì£ Exciting News! GLOBAL  |\n",
            "|                                |     WOMEN FORUM (GWF) Welcomes New Supporter:      |\n",
            "|                                |   International Group of Artificial Intelligence   |\n",
            "|                                |     highlighting the crucial role of women in      |\n",
            "|                                |  #ArtificialIntelligence.  Join us on Nov 15th in  |\n",
            "|                                | Berlin as we empower female #AI innovators, break  |\n",
            "|                                | gender barriers, and shape ethical AI. Let's drive |\n",
            "|                                |  the AI industry toward inclusivity and progress!  |\n",
            "|                                | Be part of the happening: https://lnkd.in/eAe4Y_KG |\n",
            "|                                |    Dr. Jassim Haji #WomenInAI #DiversityInTech     |\n",
            "|                                | #womeninstem #womenintechnology #womenempowerment  |\n",
            "|                                | #gwf23           To view or add a comment, sign in |\n",
            "|                                |   CMO at amdocs              In my corner of the   |\n",
            "|                                |  universe, yes, we really Gen! üí™ Leveling the   |\n",
            "|                                |  playing field is essential for winning the game,  |\n",
            "|                                |  especially for women, and especially in the tech  |\n",
            "|                                |    and generative AI fields. With GenAI at the     |\n",
            "|                                |    crossroads of the future, it offers immense     |\n",
            "|                                |    potential for women to use the benefits and     |\n",
            "|                                |    capabilities of this technology to close the    |\n",
            "|                                | gender gap. I want to encourage all women to seize |\n",
            "|                                |   this opportunity. The flip side, of course, is   |\n",
            "|                                | that inaction will actually increase the gap.  So, |\n",
            "|                                | it's my call to action for women everywhere: dive  |\n",
            "|                                |  into the AI wave, shape it, own it. Let's use AI  |\n",
            "|                                |   not just to imagine a world of equality but to   |\n",
            "|                                |  create it. #promptyourfuture          To view or  |\n",
            "|                                |  add a comment, sign in                   Global   |\n",
            "|                                |  Leader - People & Organization Practice, Senior   |\n",
            "|                                | Partner and Managing Director at Boston Consulting |\n",
            "|                                |     Group (BCG)              As we commemorate     |\n",
            "|                                |   International Women‚Äôs Day, it's a moment of    |\n",
            "|                                |   reflection on our journey and a celebration of   |\n",
            "|                                |      progress in the realm of technology and       |\n",
            "|                                |   leadership. I'm proud to share a glimpse into    |\n",
            "|                                |  @BCG‚Äôs latest report on GenAI‚Äôs integration   |\n",
            "|                                |   within the tech sector highlighting promising    |\n",
            "|                                | trends in gender diversity.     This report isn't  |\n",
            "|                                | just numbers; it's a narrative of change. It shows |\n",
            "|                                |    that women in senior tech roles are not just    |\n",
            "|                                |   pioneering the adoption of GenAI, but they are   |\n",
            "|                                | setting the pace, outperforming male counterparts  |\n",
            "|                                |     in GenAI adoption by 14 percentage points.     |\n",
            "|                                | Despite these gains, we acknowledge the persisting |\n",
            "|                                |  obstacles women continue to face. Bridging this   |\n",
            "|                                |   adoption gap is not just a tech issue; it's a    |\n",
            "|                                | business priority that demands a concerted effort  |\n",
            "|                                | across all levels of an organization.    Thank you |\n",
            "|                                | to my colleagues who drove this research: @Neveen  |\n",
            "|                                |   Awad, @Maria Barisano, @Adriana Dahik, @Julie    |\n",
            "|                                |   Bedard, @Uche Monu, and @Gunjan Mundhra. Their   |\n",
            "|                                | dedication echoes our shared mission‚Äîto build a  |\n",
            "|                                | culture where every woman's potential is realized, |\n",
            "|                                |    and their contributions are valued.    Let's    |\n",
            "|                                |   commit to the advancement of women and build a   |\n",
            "|                                |          more inclusive future together.           |\n",
            "|                                | #InternationalWomensday #GenerativeAI #WomeninTech |\n",
            "|                                |         To view or add a comment, sign in          |\n",
            "|                                |  5 followers              üìå \"Overcoming AI‚Äôs  |\n",
            "|                                | Stark Gender Imbalance: Time For A Fresh Approach\" |\n",
            "|                                | üåê  üë©üíº Championing Women in AI: Building a |\n",
            "|                                |  Balanced Future in Technology üë®üíª  üí° In   |\n",
            "|                                |   this insightful article, we explore the gender   |\n",
            "|                                | imbalance in the field of Artificial Intelligence  |\n",
            "|                                | (AI) and shed light on the urgent need for a fresh |\n",
            "|                                |    approach in addressing this issue.  üë©üî¨    |\n",
            "|                                |  Despite the increasing popularity and impact of   |\n",
            "|                                | AI, women continue to be underrepresented in this  |\n",
            "|                                | field. This disparity not only hampers inclusivity |\n",
            "|                                |  but also limits the diversity of perspectives in  |\n",
            "|                                | developing AI solutions.  üöÄ It's time to change |\n",
            "|                                | the narrative and actively empower women to pursue |\n",
            "|                                |   AI careers. By providing mentorship programs,    |\n",
            "|                                | promoting diversity and inclusivity, and creating  |\n",
            "|                                | a supportive environment, we can bridge the gender |\n",
            "|                                | gap and build a brighter, more balanced future in  |\n",
            "|                                | technology.   üåü Let's work together to overcome |\n",
            "|                                |  AI's stark gender imbalance and unlock the full   |\n",
            "|                                |  potential of women in shaping the future of AI!   |\n",
            "|                                |  üí™üèºüí°  #AI #GenderDiversity #WomenInTech   |\n",
            "|                                |             #Inclusivity #Empowerment              |\n",
            "|                                |  Link:https://buff.ly/3HmUwdE          To view or  |\n",
            "|                                |   add a comment, sign in                   2,227   |\n",
            "|                                | followers              üí° Dive into the weekend  |\n",
            "|                                | with our must-read, as we take a look at a recent  |\n",
            "|                                | article by The Guardian, https://t.ly/kKO8A.   The |\n",
            "|                                |    AI landscape is evolving rapidly, presenting    |\n",
            "|                                | incredible opportunities and challenges. üå± One  |\n",
            "|                                |  challenge we must actively address is the gender  |\n",
            "|                                |  gap. The article addresses the lack of women in   |\n",
            "|                                |  the field, while key figures like Sam Altman at   |\n",
            "|                                |   OpenAI dominate the conversation.   Share your   |\n",
            "|                                | thoughts in the comments about possible solutions  |\n",
            "|                                |    to close the gender gap and generate greater    |\n",
            "|                                |           opportunities for women!  #AI            |\n",
            "|                                |      #ArtificialIntelligence #DiversityInTech      |\n",
            "|                                |       #WomenInAI #Innovation #TechCommunity        |\n",
            "|                                | #FutureOfWork #GenderEquality          To view or  |\n",
            "|                                |    add a comment, sign in                   75     |\n",
            "|                                | followers              AI for Women is launching a |\n",
            "|                                |   brand new website - We are now a professional    |\n",
            "|                                | networking platform for women AI enthusiasts! The  |\n",
            "|                                | objective of this website is to promote networking |\n",
            "|                                |  among like-minded women who can inspire, mentor,  |\n",
            "|                                |   and help one another.   As a part of the pre-    |\n",
            "|                                | launch campaign, I have decided to do a deep dive  |\n",
            "|                                | into how we can achieve equality in AI for women.  |\n",
            "|                                | I will be sharing my findings over the next 3 days |\n",
            "|                                | in the form of blog posts.   Today's article talks |\n",
            "|                                | about 'Gender Bias and Stereotyping'. You can find |\n",
            "|                                |  it here: https://lnkd.in/g3me3upH  Do you agree   |\n",
            "|                                | with the article? Have you experienced / overcome  |\n",
            "|                                |    similar challenges? Feel free to share your     |\n",
            "|                                |         thoughts! üñã   #AI #GenerativeAI         |\n",
            "|                                |      #WomenEmpowerment #AIforWomen #WomeninAI      |\n",
            "|                                | #WomeninTech #WomeninSTEM #DataScience          To |\n",
            "|                                |           view or add a comment, sign in           |\n",
            "|                                |                  49,341 followers                  |\n",
            "|                                |  Create your free account or sign in to continue   |\n",
            "|                                |   your search                                 or   |\n",
            "|                                | By clicking Continue to join or sign in, you agree |\n",
            "|                                |  to LinkedIn‚Äôs User Agreement, Privacy Policy,   |\n",
            "|                                |  and Cookie Policy.                       New to   |\n",
            "|                                |     LinkedIn? Join now                     or      |\n",
            "|                                | By clicking Continue to join or sign in, you agree |\n",
            "|                                |  to LinkedIn‚Äôs User Agreement, Privacy Policy,   |\n",
            "|                                |   and Cookie Policy.                     New to    |\n",
            "|                                |                 LinkedIn? Join now                 |\n",
            "|   Sandra Rivera en LinkedIn:   |                     Aceptar y unirse a LinkedIn    |\n",
            "|     #intelvision #iamintel     |    Al hacer clic en ¬´Continuar¬ª para unirte o    |\n",
            "|                                |  iniciar sesi√≥n, aceptas las Condiciones de uso,  |\n",
            "|                                |    la Pol√≠tica de privacidad y la Pol√≠tica de    |\n",
            "|                                |    cookies de LinkedIn.      Another successful    |\n",
            "|                                | #intelvision event this week in Taiwan. Thanks to  |\n",
            "|                                | all the partners and customers who attended. After |\n",
            "|                                |  talking with many of you, I‚Äôm highly inspired   |\n",
            "|                                |  about our future collaboration.  Intel‚Äôs data   |\n",
            "|                                |  center solutions are on the forefront of driving  |\n",
            "|                                |   some of the industry‚Äôs biggest technological   |\n",
            "|                                |     breakthroughs, including AI, security and      |\n",
            "|                                | sustainability.  Through our partnerships, we will |\n",
            "|                                |     unleash business innovations within cloud,     |\n",
            "|                                |   enterprise and hybrid environments. #iamintel    |\n",
            "|                                |  Currently an unaffiliated independent researcher  |\n",
            "|                                |  with precision focus-centered research activity.  |\n",
            "|                                | Looking for a mutually agreed-upon faculty role in |\n",
            "|                                | Electrical Engineering in a private university in  |\n",
            "|                                |  Dhaka, Bangladesh. Taiwan is integral for USA's   |\n",
            "|                                |    semiconductor companies' success.  Thank you    |\n",
            "|                                |      author for this wonderful post with the       |\n",
            "|                                | participants in the events beaming with smile, so  |\n",
            "|                                |    adoring.  Commercialize technology dreams /     |\n",
            "|                                |    visions / innovations into revenue Cool for     |\n",
            "|                                |    Taiwan. Someday it will be nice to see such     |\n",
            "|                                | investment in America‚Äôs own population. Helping  |\n",
            "|                                |    Your High Value Products Arrive Safely | Sr.    |\n",
            "|                                |   Account Executive | Outdoor Enthusiast | Avid    |\n",
            "|                                |  Coursera Student ü§ì Sandra Rivera Great to see  |\n",
            "|                                | Intel Corporation producing so many smiling faces  |\n",
            "|                                |   in trying times!  The semi-conductor and Data    |\n",
            "|                                |      Center industry is booming! #taiwan #usa      |\n",
            "|                                |  #datacenters  Senior Manager, Sales and Business  |\n",
            "|                                |    Development Intel is clearly A FOLLOWER now,    |\n",
            "|                                |  following AMD and Nvidia. No exception   Inicia   |\n",
            "|                                | sesi√≥n para ver o a√±adir un comentario.      Our |\n",
            "|                                |  goal is to be the world‚Äôs #1 FPGA provider by   |\n",
            "|                                |   delivering leading-edge programmable solutions   |\n",
            "|                                |      that scale - from the cloud to embedded       |\n",
            "|                                |      applications - based on our customers‚Äô      |\n",
            "|                                | requirements. It‚Äôs an ambitious goal that I have |\n",
            "|                                |  full confidence we‚Äôll achieve by listening to   |\n",
            "|                                | customers, continuing to deliver value, and always |\n",
            "|                                |   be learning. https://lnkd.in/gKuqA8iy  Inicia    |\n",
            "|                                | sesi√≥n para ver o a√±adir un comentario.      Ice |\n",
            "|                                |  cream and volleyball. What a great afternoon at   |\n",
            "|                                |     Altera's San Jose campus. I continue to be     |\n",
            "|                                |  inspired by the Altera technologists driving the  |\n",
            "|                                | industry‚Äôs next generation of #FPGA innovations. |\n",
            "|                                |  Congratulations to our winning volleyball team.   |\n",
            "|                                |   Pat Gelsinger's serve proved to be too much.¬†   |\n",
            "|                                |  Inicia sesi√≥n para ver o a√±adir un comentario.  |\n",
            "|                                | Today is a day when we recognize and celebrate the |\n",
            "|                                | strength and resilience of Black Americans. As we  |\n",
            "|                                | reflect on the meaning of #Juneteenth, I encourage |\n",
            "|                                | you to commit yourself to building a more just and |\n",
            "|                                |  equitable society for everyone.  Inicia sesi√≥n   |\n",
            "|                                |  para ver o a√±adir un comentario.      Grateful   |\n",
            "|                                |  for the opportunity to recharge and connect with  |\n",
            "|                                |    brilliant minds. Thank you #Altera San Jose     |\n",
            "|                                | employees. #wearealtera  Inicia sesi√≥n para ver o |\n",
            "|                                | a√±adir un comentario.      I‚Äôm thrilled to join |\n",
            "|                                |   Thomas Sohmers, Thomas Catalino, and Dr. Rania   |\n",
            "|                                |   Hussein for this LinkedIn Live event, where we   |\n",
            "|                                |  will discuss the rapidly evolving AI market, and  |\n",
            "|                                | how the programmability of FPGAs are accelerating  |\n",
            "|                                |  innovation. I hope you can join us on June 11 at  |\n",
            "|                                |   9:00 a.m. Pacific.¬† https://lnkd.in/gCZZQKBJ    |\n",
            "|                                | 63.838 seguidores              üìÖJoin us on June |\n",
            "|                                |   11th for our LinkedIn Live event, \"Unleashing    |\n",
            "|                                | Limitless AI Possibilities with FPGAs‚Äú hosted by |\n",
            "|                                |  Bernard Marr, and hear industry leaders discuss   |\n",
            "|                                |    the future of AI.  ¬† Meet Our Panelists:  -    |\n",
            "|                                |  Sandra Rivera, CEO of Altera  - Thomas Catalino,  |\n",
            "|                                | VP, Critical Link  - Dr. Rania Hussein, Associate  |\n",
            "|                                |  Teaching Professor, University Of Washington  -   |\n",
            "|                                |  Thomas Sohmers, CEO, Positron.ai ¬† What we‚Äôll  |\n",
            "|                                |    be discussing: - Real-world success stories:    |\n",
            "|                                | Innovative AI solutions in action - FPGAi: What is |\n",
            "|                                |  it? And how will it revolutionize how innovators  |\n",
            "|                                | design AI applications? - Future Trends: Insights  |\n",
            "|                                |  into Altera‚Äôs technology roadmap and ecosystem  |\n",
            "|                                | collaborations.  Inicia sesi√≥n para ver o a√±adir |\n",
            "|                                |    un comentario.      As part of our effort to    |\n",
            "|                                |  accelerate innovation, we are expanding our high  |\n",
            "|                                |   performance team with the addition of two high   |\n",
            "|                                | performing leaders. Congratulations to Premal Buch |\n",
            "|                                |      on his expanded role as Altera's Head of      |\n",
            "|                                |   Engineering and Jeni Barovian Panhorst on her    |\n",
            "|                                |     appointment as Head of Market Development.     |\n",
            "|                                |        #WeAreAltera #AcceleratingInnovators        |\n",
            "|                                | 63.838 seguidores              We are delighted to |\n",
            "|                                |     announce that we have two new additions to     |\n",
            "|                                |     Altera‚Äôs leadership team - Jeni Barovian     |\n",
            "|                                | Panhorst as Head of Market Development and Premal  |\n",
            "|                                | Buch as Head of Engineering. A warm welcome to the |\n",
            "|                                |    team!  #WeAreAltera #AcceleratingInnovators     |\n",
            "|                                | #AlteraTeam  Inicia sesi√≥n para ver o a√±adir un  |\n",
            "|                                |  comentario.      An exciting industry first and   |\n",
            "|                                | milestone for Intel Corporation that will benefit  |\n",
            "|                                |      Altera and our customers by accelerating      |\n",
            "|                                |     innovation for cutting edge solutions with     |\n",
            "|                                |    emerging technologies like #AI. ¬†   Inicia     |\n",
            "|                                | sesi√≥n para ver o a√±adir un comentario.      At  |\n",
            "|                                | Altera, we are driven by innovation and commitment |\n",
            "|                                |   to our customers. Team Malaysia embodies these   |\n",
            "|                                |   principles with passion. #WeareAltera  Inicia    |\n",
            "|                                | sesi√≥n para ver o a√±adir un comentario.      At  |\n",
            "|                                |  Altera, we focus on providing our customers the   |\n",
            "|                                |   right hardware and software solutions to solve   |\n",
            "|                                |   some of their most complex problems. ¬†Our AI-   |\n",
            "|                                |      infused Agilex 5 FPGA is opening up new       |\n",
            "|                                |     possibilities for innovators - and it‚Äôs      |\n",
            "|                                |  available now, along with software tools to help  |\n",
            "|                                |         get your designs to market faster.         |\n",
            "|                                | ¬†#AcceleratingInnovators #FPGAi   Inicia sesi√≥n  |\n",
            "|                                |         para ver o a√±adir un comentario.          |\n",
            "|                                | 49.341 seguidores                             Crea |\n",
            "|                                | tu cuenta gratuita o inicia sesi√≥n para continuar |\n",
            "|                                |   tu b√∫squeda                                 o   |\n",
            "|                                |    Al hacer clic en ¬´Continuar¬ª para unirte o    |\n",
            "|                                |  iniciar sesi√≥n, aceptas las Condiciones de uso,  |\n",
            "|                                |    la Pol√≠tica de privacidad y la Pol√≠tica de    |\n",
            "|                                |                cookies de LinkedIn.                |\n",
            "|                                |  ¬øEst√°s empezando a usar LinkedIn? √önete ahora  |\n",
            "|                                |     o                         Al hacer clic en     |\n",
            "|                                |    ¬´Continuar¬ª para unirte o iniciar sesi√≥n,    |\n",
            "|                                |  aceptas las Condiciones de uso, la Pol√≠tica de   |\n",
            "|                                | privacidad y la Pol√≠tica de cookies de LinkedIn.  |\n",
            "|                                |  ¬øEst√°s empezando a usar LinkedIn? √önete ahora  |\n",
            "+--------------------------------+----------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'title': 'Intel and Altera Announce Edge and FPGA Offerings for AI at Embedded...',\n",
              "  'text': \"You can easily search the entire Intel.com site in several ways.\\nYou can also try the quick links below to see results for most popular searches.\\nThe browser version you are using is not recommended for this site.Please consider upgrading to the latest version of your browser by clicking one of the following links.\\nNew edge-optimized processors and FPGAs bring AI everywhere across edge computing markets including retail, industrial and healthcare.\\n\\nApril 8, 2024\\nContact Intel PR\\n\\nFollow Intel Newsroom on social:\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBy\\n\\nWhat’s New:\\xa0Today at Embedded World, Intel and Altera, an Intel Company, announced new edge-optimized processors, FPGAs and programmable market-ready solutions extending powerful AI capabilities into edge computing. These products will power AI-enabled edge devices applicable to industries across retail, healthcare, industrial, automotive, defense and aerospace.\\n\\nWhat’s New:\\xa0Today at Embedded World, Intel and Altera, an Intel Company, announced new edge-optimized processors, FPGAs and programmable market-ready solutions extending powerful AI capabilities into edge computing. These products will power AI-enabled edge devices applicable to industries across retail, healthcare, industrial, automotive, defense and aerospace.\\n“This next generation of Intel edge-optimized processors and discrete GPUs unleashes powerful AI capabilities to help businesses more seamlessly incorporate AI alongside compute, media and graphics workloads. From manufacturing to healthcare, Intel’s extensive edge AI experience and breadth and depth of edge-ready silicon and software help our customers deliver AI where they need it most for better business outcomes.” \\nWhy It Matters for Edge and AI: Why It Matters for Edge and AI: Intel’s new series of edge-optimized Intel® Core™\\u202fUltra, Intel® Core™ and Intel Atom® processors\\u202fand discrete Intel® Arc™ graphics processing units (GPUs) will advance innovation for artificial intelligence, visual computing and media processing – in support of faster and smarter decisions with on-premise edge computing. Agilex™ 5 FPGAs for mid-range applications with best-in-class performance per watt target a\\u202fbroad set of applications, including video, industrial, robotics, medical and others. Agilex\\u202f5 FPGAs with AI infused into the fabric offer a\\u202fhigh level of\\u202fintegration, low latency and improved computing capabilities\\u202ffor intelligent edge applications.\\nExpanding on Intel’s commitment to bringing AI everywhere, today's announcements utilize built-in AI acceleration in the new series of processors to power the next generation of edge devices.\\n\\nWhy It Matters for Edge and AI: Why It Matters for Edge and AI: Intel’s new series of edge-optimized Intel® Core™\\u202fUltra, Intel® Core™ and Intel Atom® processors\\u202fand discrete Intel® Arc™ graphics processing units (GPUs) will advance innovation for artificial intelligence, visual computing and media processing – in support of faster and smarter decisions with on-premise edge computing. Agilex™ 5 FPGAs for mid-range applications with best-in-class performance per watt target a\\u202fbroad set of applications, including video, industrial, robotics, medical and others. Agilex\\u202f5 FPGAs with AI infused into the fabric offer a\\u202fhigh level of\\u202fintegration, low latency and improved computing capabilities\\u202ffor intelligent edge applications.\\nExpanding on Intel’s commitment to bringing AI everywhere, today's announcements utilize built-in AI acceleration in the new series of processors to power the next generation of edge devices.\\nAn image shows the FPGAi Altera company logo. Altera helps customers achieve their business goals with new AI capabilities to support high-performance and mid-range FPGA-based solutions, developer usability and workload agility. (Credit: Altera, an Intel Company)\\nAn image shows an Intel Atom processor badge. Intel Atom processors x7000C Series delivers ramped-up processor base frequency in up to eight Efficient-cores. Intel Atom processors x7000RE Series features built-in deep learning inference capabilities. (Credit: Intel Corporation)\\nAn image shows an Intel Core Ultra processor badge. Intel Core Ultra processors combine the Intel Arc GPU and a neural processing unit (NPU) with LGA socket flexibility into a simplified system-on-chip (SoC). The new SoC is designed to enable generative AI (GenAI) and demanding graphics workloads at the edge. (Credit: Intel Corporation)\\nAn image shows the Intel Arc GPU for Edge badge. The Intel® Arc™ GPU for Edge boosts performance and edge AI capabilities on legacy Intel Core systems as a discrete GPU, providing accelerated AI, media and graphics processing power. (Credit: Intel Corporation)\\nAn image shows an Intel Core processor badge. Intel Core processors combine the GPU power of 13th Gen Intel Core mobile processors with LGA socket flexibility to prioritize system scalability and speed to deployment. (Credit: Intel Corporation)\\nAn image shows the Agilex 5 field programmable gate array. Agilex 5 FPGAs for mid-range applications with best-in-class performance per watt target a\\u202fbroad set of applications, including video, industrial, robotics, medical and others. (Credit: Altera, an Intel Company)\\nDownload all images (ZIP, 2 MB)\\n\\nDownload all images (ZIP, 2 MB)\\nHow Intel Expands AI to Embedded Edge Devices: Building on its expansive installed base of more than 90,000 edge deployments, Intel delivers a wave of edge-optimized processors and GPUs to power the next generation of AI-enabled edge devices.\\n\\xa0\\n\\nIntel Core\\u202fUltra processors for edge: Offering up to 5.02x better image classification inference performance compared to 14th Gen Intel® Core™ desktop processors,1 Intel Core Ultra processors combine the Intel Arc GPU2 and a neural processing unit (NPU)3 with LGA socket flexibility into a simplified system-on-chip (SoC). The new SoC is designed to enable generative AI (GenAI) and demanding graphics workloads at the edge for retail, education, smart cities and industrial customers, including GenAI-enabled kiosk and smart point-of-sale systems in brick-and-mortar retailers, interactive whiteboards for enhanced in-classroom experiences and AI vision-enhanced industrial devices for manufacturing and roadside units.\\xa0\\nIntel Core processors for edge: Intel Core processors combine the GPU power of 13th Gen Intel® Core® mobile processors with LGA socket flexibility to prioritize system scalability and speed to deployment. This series of processors optimized for the edge offers up to 2.57x greater graphics performance compared to 13th Gen Intel® Core™ desktop processors4 by leveraging up to 3 times more graphics execution units alongside performance hybrid architecture with Intel® Thread Director5 and an LGA socket-based design offering customers more edge AI and graphics performance without sacrificing hardware setup flexibility.\\nIntel Atom® processors x7000C Series: Intel Atom processors x7000C Series delivers ramped-up processor base frequency in up to eight Efficient-cores to drive exceptional packet processing throughput for enterprise networking and telecommunications devices. This enables telecommunications businesses to use built-in deep learning inference capabilities to support the detection of zero-day threats, boost packet and control plane processing for OpenSSL/IPSec using native instruction sets, and leverage Intel security features to harden networks.\\nIntel Atom® processors x7000RE Series: Primarily for industrial and manufacturing end users, Intel Atom processors x7000RE Series features built-in deep learning inference capabilities and up to 32 graphics execution units in a ruggedized, power-efficient 6W-12W BGA package offering up to 9.83x image classification performance compared with Intel Atom processors x6000RE Series6. The new processor supports fanless designs to enable Industry 4.0 automation for key use cases in AI-automated tending, warehouse AMR, in-line visual inspection for quality control and ruggedized industrial PC scenarios.\\xa0\\n\\n\\xa0\\nAdditionally, the Intel® Arc™ GPU for Edge boosts performance and edge AI capabilities on legacy Intel Core systems as a discrete GPU providing accelerated AI, and media and graphics processing power. Intel Arc GPUs also eliminate vendor lock-in with an open, standards-based software stack to offer choice and flexibility when building high-performance AI applications and solutions.\\xa0\\nHow Altera’s Portfolio Will Accelerate Customer AI Innovations: Following the FPGA Vision Webcast in February, Altera announced additional updates to its FPGA portfolio, providing flexible solutions to help customers solve their challenges from the cloud to network to the intelligent edge.\\n“We announced the launch of the new Altera brand with the goal of bringing leading technologies and innovations more quickly to the FPGA market. Today, we are excited about the next phase in our 10-plus year journey delivering flexible AI solutions,” said Sandra Rivera, Altera chief executive officer. “Altera is leading the new FPGAi era by tightly coupling programmability with tensor capabilities and infusing FPGA and AI tools for a best-in-class developer experience. Agilex 5, the first FPGA with AI-infused throughout the fabric, is now broadly available.”\\nAltera Leads the New Era of FPGAi: Altera helps customers achieve their business goals with new AI capabilities to support high-performance and mid-range FPGA-based solutions, developer usability and workload agility. FPGA AI Suite adds support for Agilex™ 5 SoC FPGAs. The AI tool flow allows developers to use existing and popular AI frameworks, along with the Intel® OpenVINO™ toolkit and the FPGA AI Suite, to create AI intellectual property (IP) blocks and easily drop them into the FPGA design. More information is available at the FPGA AI Suite website.\\n\\xa0\\n\\nPerformance per Watt Leader Agilex 5 SoC FPGAs Broadly Available: Agilex 5 devices, with best-in-class AI and up to 2x better performance per watt versus competing 7 nanometer FPGAs7, are designed to deliver high performance with lower power in a modern SoC subsystem with small form factor package options, allowing customers and developers to add AI capability to their products without the need for dedicated accelerators. Geared toward a broad set of embedded applications, Agilex 5 devices and development kits are broadly available with Quartus® Prime software support. Broad availability also includes support by a large and growing list of ecosystem partners providing additional boards, system-on-modules (SOMs), IP and various value-added services. More information about Agilex 5 devices, including technical details, is available at the Agilex 5 SoC FPGA website.\\nUnleash the Power of Agilex 5 E-Series Devices with Quartus Prime Pro Edition S/W Version 24.1: The latest version of Altera’s cutting-edge software is available for download, offering free access to the latest Agilex 5 E-Series SoC FPGAs and selected complementary IP cores. Quartus offers a streamlined experience for an IP-centric design flow, configurable example designs and unprecedented capabilities including a powerful new Agilex 5 SoC subsystem (hard-processor system featuring dual-core Arm Cortex A76, dual-core Arm Cortex A55 processors and various peripherals). This new SoC subsystem is also supported by third-party tools recently updated to support Agilex 5 devices. More information is available at the Quartus Prime Pro website.\\nPortfolio Breadth and Industry-Leading Longevity: Altera continues to deliver a broad portfolio, including industry-leading longevity with selected MAX® and Cyclone® cost- and power-optimized product families’ life cycles extended to 2040 and later, further improving supply chain resilience. Future Agilex™ 3 devices, coming soon, will expand the Agilex portfolio to deliver even greater breadth.\\n\\n\\xa0\\nWhy It Matters for Altera FPGAs: In an era where technological advancements are integral to staying competitive, Intel’s new edge-optimized processors and solutions deliver the capabilities enterprises need to innovate, be efficient and improve time to market. Altera delivers flexibility and re-programmability to accelerate innovators by providing easy-to-design and easy-to-deploy leadership programmable solutions.\\nThese processors, FPGAs and associated solutions allow enterprises to leverage the tremendous amount of data generated at the edge to deploy sophisticated embedded AI devices across a variety of industries to streamline operations, improve customer satisfaction and incorporate advanced visual workloads.\\xa0\\n“The FPGA AI Suite from Altera allowed the Tiami team to rapidly incorporate our IP into an intricate digital signal processing (DSP) pipeline,” said Amitav Mukherjee, CEO at Tiami Networks. “This significantly reduced the time required to integrate AI capabilities with 5G signal processing from an estimated six months to just eight weeks. Our engineering team clearly recognized the value proposition offered by the FPGA in preprocessing wireless signals received from the antenna and performing real-time inference, resulting in a successful demo.”\\nMore Context: Intel Core Ultra Processors for Edge (PDF) | Intel Processers for the Edge | Intel Arc GPU for Edge |\\xa0 Intel Launches Altera, Its New Standalone FPGA Company\\n\\nHow Intel Expands AI to Embedded Edge Devices: Building on its expansive installed base of more than 90,000 edge deployments, Intel delivers a wave of edge-optimized processors and GPUs to power the next generation of AI-enabled edge devices.\\n\\xa0\\n\\xa0\\nAdditionally, the Intel® Arc™ GPU for Edge boosts performance and edge AI capabilities on legacy Intel Core systems as a discrete GPU providing accelerated AI, and media and graphics processing power. Intel Arc GPUs also eliminate vendor lock-in with an open, standards-based software stack to offer choice and flexibility when building high-performance AI applications and solutions.\\xa0\\nHow Altera’s Portfolio Will Accelerate Customer AI Innovations: Following the FPGA Vision Webcast in February, Altera announced additional updates to its FPGA portfolio, providing flexible solutions to help customers solve their challenges from the cloud to network to the intelligent edge.\\n“We announced the launch of the new Altera brand with the goal of bringing leading technologies and innovations more quickly to the FPGA market. Today, we are excited about the next phase in our 10-plus year journey delivering flexible AI solutions,” said Sandra Rivera, Altera chief executive officer. “Altera is leading the new FPGAi era by tightly coupling programmability with tensor capabilities and infusing FPGA and AI tools for a best-in-class developer experience. Agilex 5, the first FPGA with AI-infused throughout the fabric, is now broadly available.”\\nAltera Leads the New Era of FPGAi: Altera helps customers achieve their business goals with new AI capabilities to support high-performance and mid-range FPGA-based solutions, developer usability and workload agility. FPGA AI Suite adds support for Agilex™ 5 SoC FPGAs. The AI tool flow allows developers to use existing and popular AI frameworks, along with the Intel® OpenVINO™ toolkit and the FPGA AI Suite, to create AI intellectual property (IP) blocks and easily drop them into the FPGA design. More information is available at the FPGA AI Suite website.\\n\\xa0\\n\\xa0\\nWhy It Matters for Altera FPGAs: In an era where technological advancements are integral to staying competitive, Intel’s new edge-optimized processors and solutions deliver the capabilities enterprises need to innovate, be efficient and improve time to market. Altera delivers flexibility and re-programmability to accelerate innovators by providing easy-to-design and easy-to-deploy leadership programmable solutions.\\nThese processors, FPGAs and associated solutions allow enterprises to leverage the tremendous amount of data generated at the edge to deploy sophisticated embedded AI devices across a variety of industries to streamline operations, improve customer satisfaction and incorporate advanced visual workloads.\\xa0\\n“The FPGA AI Suite from Altera allowed the Tiami team to rapidly incorporate our IP into an intricate digital signal processing (DSP) pipeline,” said Amitav Mukherjee, CEO at Tiami Networks. “This significantly reduced the time required to integrate AI capabilities with 5G signal processing from an estimated six months to just eight weeks. Our engineering team clearly recognized the value proposition offered by the FPGA in preprocessing wireless signals received from the antenna and performing real-time inference, resulting in a successful demo.”\\nMore Context: Intel Core Ultra Processors for Edge (PDF) | Intel Processers for the Edge | Intel Arc GPU for Edge |\\xa0 Intel Launches Altera, Its New Standalone FPGA Company\\nThe Small Print:\\xa0\\nAltera, the Altera logo, and other Altera marks are trademarks of Altera.\\xa0\\r\\nOther names and brands may be claimed as the property of others.\\n1 Performance varies by use, configuration, and other factors. Learn more at intel.com/processorclaims: Intel® Core™ Ultra processors, Edge. Results may vary.\\xa0\\xa0\\n2\\xa0Intel® Arc™ GPU\\xa0is only available on select H-Series, Intel® Core™ Ultra processor-powered\\xa0systems with at least 16GB of system memory in a dual-channel configuration.\\xa0OEM enablement\\xa0is\\xa0required; check with OEM for system configuration details.\\xa0\\n3\\xa0Intel® AI Boost enablement limited at launch.\\xa0\\n4\\xa0Performance varies by use, configuration, and other factors. Learn more at intel.com/processorclaims: Intel® Core™\\xa0processors, Edge.\\xa0Results may vary.\\xa0\\n5\\xa0Support for Intel® Thread Director is expected in Windows 11 IoT Enterprise LTSC and Linux\\xa0\\n6 Performance varies by use, configuration, and other factors. Learn more at intel.com/processorclaims:\\xa0Intel Atom® Processors. Results may vary.\\xa0\\n7\\xa0FPGA performance per watt:\\xa0\\xa0https://edc.intel.com/content/www/us/en/products/performance/benchmarks/agilex-fpga/. Results may vary.\\xa0\\xa0\\n\\nThe Small Print:\\xa0\\nAltera, the Altera logo, and other Altera marks are trademarks of Altera.\\xa0\\r\\nOther names and brands may be claimed as the property of others.\\n1 Performance varies by use, configuration, and other factors. Learn more at intel.com/processorclaims: Intel® Core™ Ultra processors, Edge. Results may vary.\\xa0\\xa0\\n2\\xa0Intel® Arc™ GPU\\xa0is only available on select H-Series, Intel® Core™ Ultra processor-powered\\xa0systems with at least 16GB of system memory in a dual-channel configuration.\\xa0OEM enablement\\xa0is\\xa0required; check with OEM for system configuration details.\\xa0\\n3\\xa0Intel® AI Boost enablement limited at launch.\\xa0\\n4\\xa0Performance varies by use, configuration, and other factors. Learn more at intel.com/processorclaims: Intel® Core™\\xa0processors, Edge.\\xa0Results may vary.\\xa0\\n5\\xa0Support for Intel® Thread Director is expected in Windows 11 IoT Enterprise LTSC and Linux\\xa0\\n6 Performance varies by use, configuration, and other factors. Learn more at intel.com/processorclaims:\\xa0Intel Atom® Processors. Results may vary.\\xa0\\n7\\xa0FPGA performance per watt:\\xa0\\xa0https://edc.intel.com/content/www/us/en/products/performance/benchmarks/agilex-fpga/. Results may vary.\\xa0\\xa0\\n\\nAltera, \\nInternet of Things, \\nArtificial Intelligence\\n\\nAbout Intel\\nIntel (Nasdaq: INTC) is an industry leader, creating world-changing technology that enables global progress and enriches lives. Inspired by Moore’s Law, we continuously work to advance the design and manufacturing of semiconductors to help address our customers’ greatest challenges. By embedding intelligence in the cloud, network, edge and every kind of computing device, we unleash the potential of data to transform business and society for the better. To learn more about Intel’s innovations, go to newsroom.intel.com and intel.com.\\n© Intel Corporation. Intel, the Intel logo and other Intel marks are trademarks of Intel Corporation or its subsidiaries. Other names and brands may be claimed as the property of others.\\nIntel technologies may require enabled hardware, software or service activation. // No product or component can be absolutely secure. // Your costs and results may vary. // Performance varies by use, configuration and other factors. // See our complete legal Notices and Disclaimers. //\\xa0Intel is committed to respecting human rights and avoiding causing or contributing to adverse impacts on human rights. See Intel’s Global Human Rights Principles. Intel’s products and software are intended only to be used in applications that do not cause or contribute to adverse impacts on human rights.\"},\n",
              " {'title': 'Sandra Rivera on LinkedIn: #women4ew #womenintech #wearealtera #ai | 13 comments',\n",
              "  'text': '\\n                Agree & Join LinkedIn\\n              \\n\\n      By clicking Continue to join or sign in, you agree to LinkedIn‚Äôs User Agreement, Privacy Policy, and Cookie Policy.\\n    \\nA great #women4ew event at embedded world Exhibition&Conference today covering various topics from addressing gender bias in AI algorithms to discussing the critical role diversity plays in innovation.\\nAt Altera we create a culture that positively impacts the work experience and development of women. So, it has filled me with hope and optimism to see so many women in this industry come together to share their experience and pave the way for the next generation of #womenintech #WeAreAltera #AI\\n\\nLoved the insights on gender bias & diversity in AI! Plato said wisdom begins in wonder, reminding us that diversity fuels innovation by widening our perspectives \\uf8ffüåü #womenintech #innovation\\n\\nI love the topic - \"how diversity can impact innovation\"  reminded me of why the military did not put all of the same \"Human Dynamic\" people together on teams ( higher injury rates) and Margaret Heffernan\\'s super chickens TED talk! Martin Curley and I will release our second innovation book in Q4 \"Managing Innovation in a Digital World\"- we will send you a copy! \\nFinancial Cultural Operational and Technical Consultant - Alpha Sense Financial Consulting\\nHere\\'s a remedy to the tribal feminism agenda...\\n\\nThe solution is to unite around a common set of principles and values, and the Gordon Moore ethos and Grove Egalitarian Meritocracy.    Glad to see Pat pushing this;  Will you join him Sandra Rivera and create the One Culture Bob Swan initiated.    There needs to be a lot of follow through. \\n\\nWhat your espousing is antithetical to good solid ethics and practices; don\\'t you think?\\n\\nhttps://www.linkedin.com/article/edit/7117624932322185216/\\n\\n\\nThank you, Sandra Rivera, for being an incredible part of #women4ew!¬†\\uf8ffüí™ \\nWe are absolutely honoured to have such amazing women like you in the #embeddedworld!\\nAssembly Test Manufacturing GM Communications & Chief of Staff Support | Senior Technical Leader | IDM 2.0 & Foundry Programs | Lean Six Sigma Blackbelt | Multicultural ERG Alliance Chair at Intel Corporation\\nThis is way too important thank you for being a leader in this. Bias of any kind in AI algorithms at this critical juncture of machine learning is a continuation of status quo, which is not good enough. Change can only happen with real actions beyond intentions. Thanks for making it real and hearing, supporting and hopefully responding to these issues.\\nDigital Marketing | Social Media Management | Content Creation\\nIt\\'s truly empowering to see initiatives like #women4ew fostering discussions on crucial topics like gender bias in AI and the importance of diversity in innovation. \\n\\nGreat to see you pushing this. It\\'s really needed and hitting a chord. I know of one tech startup that had 10 men originally with no women. Now it\\'s up to 22 with 12 women and 10 men. But web talks are still all men.\\nI help ambitious leaders build strong Executive Presence so that they get rapid career growth and coveted CXO roles I Executive & Leadership Coach I Learning and Development | Training | Talent Management\\nThat\\'s fantastic to hear about your experience! It\\'s encouraging to see women coming together to support each other and advocate for positive change.\\nFinancial Cultural Operational and Technical Consultant - Alpha Sense Financial Consulting\\nA picture of true unity and diversity.   A place where diverse talents thinking and experience makes the best and highest use of scarce Human Resources...    \\n\\nThe Gordon Moore ethos of Intels first 3 decades was a place where everyone rallied around a common purpose and a shared sense of identity.\\nSolving digital challenges for U.S companies @ RKTech | Dreamer who does @ Rikkeisoft | Forbes Tech Council Member\\nKudos to Altera for fostering a culture that supports and develops women in the tech industry! \\n\\n        To view or add a comment, sign in\\n\\n\\n                Financial Cultural Operational and Technical Consultant - Alpha Sense Financial Consulting\\n            \\nHere\\'s a remedy to the tribal feminism agenda...\\n\\nThe solution is to unite around a common set of principles and values, and the Gordon Moore ethos and Grove Egalitarian Meritocracy.    Glad to see Pat pushing this;  Will you join him Sandra Rivera and create the One Culture Bob Swan initiated.    There needs to be a lot of follow through. \\n\\nWhat your espousing is antithetical to good solid ethics and practices; don\\'t you think?\\n\\nhttps://lnkd.in/gg6wt2fU\\n\\nHere\\'s our pitch for Intel to live out the true spirit of the Open Door culture, and regain its position as the cultural standard bearer for Silicon Valley.\\n\\nhttps://lnkd.in/gbckTSTV\\nA great #women4ew event at embedded world Exhibition&Conference today covering various topics from addressing gender bias in AI algorithms to discussing the critical role diversity plays in innovation.\\nAt Altera we create a culture that positively impacts the work experience and development of women. So, it has filled me with hope and optimism to see so many women in this industry come together to share their experience and pave the way for the next generation of #womenintech #WeAreAltera #AI\\n\\n        To view or add a comment, sign in\\n\\n\\n                1,230 followers\\n            \\nEmpowering Women in AI: A Journey of Inclusivity & Innovation \\uf8ffüöÄ\\n\\nAt Resonant Consulting, we believe in the transformative power of artificial intelligence (AI) and its potential to enrich lives when inclusivity is at the forefront. \\n\\nOur latest carousel celebrates the journey towards gender inclusivity in AI, spotlighting the essential role of male allies and the untapped potential of women in shaping the future of technology. \\uf8ffüåü\\n\\nWe\\'re calling on everyone, especially our male counterparts, to join us in this movement. Your support is crucial in creating an environment where women can excel and contribute to AI\\'s limitless possibilities. Together, let\\'s ensure the AI journey is inclusive, empowering, and beneficial for all. Dive into our carousel to learn more and be part of the change. \\n\\n#WomenInAI #InclusiveTech #ResonantConsulting #WomenInAI\\n#InclusiveAI #AIForAll #GenderInclusivityInTech #EmpowerHerAI #AIInnovationForAll #DiversityInAI #FutureIsFemaleAI #MaleAlliesForAI #EmpoweringWomenInTech #TechForGood #AIEquality\\n\\n\\n        To view or add a comment, sign in\\n\\n\\n                100,536 followers\\n            \\nGenerative AI is rapidly transforming the world as we know it, with C-suite executives anticipating that nearly half of workers on average will require reskilling within the next three years.\\n\\nA recent BCG report underscores that senior women in tech are leading the way in #GenAI adoption, utilizing the #technology at rates 14 percentage points higher than their male counterparts. However, women in non-technical roles and junior women across all functions are not keeping pace.\\n\\nWhat drives these gender disparities in GenAI adoption and how can leaders narrow the gap? Find out here:¬†https://on.bcg.com/4b98ld0\\n#GenerativeAI #WomenInTech #ArtificialIntelligence\\n\\n\\n        To view or add a comment, sign in\\n\\n\\n                Digital Content Manager | Strategist | Gen AI | Ex Adani Digital Labs, Ogilvy, Wunderman Thompson, FCB | Social Stars Gold, Digies Gold\\n            \\nThis research says senior managers are adopting Gen AI fast. But why don\\'t I see this happening in advertising and marketing? I hear people talking about using AI and individuals flaunting their knwoledge about it. But no effort to make AI a part of daily jobs. Will this change? Hopefully, it will trickle down from the senior managers to their teams soon enough.\\n\\n                100,536 followers\\n            \\nGenerative AI is rapidly transforming the world as we know it, with C-suite executives anticipating that nearly half of workers on average will require reskilling within the next three years.\\n\\nA recent BCG report underscores that senior women in tech are leading the way in #GenAI adoption, utilizing the #technology at rates 14 percentage points higher than their male counterparts. However, women in non-technical roles and junior women across all functions are not keeping pace.\\n\\nWhat drives these gender disparities in GenAI adoption and how can leaders narrow the gap? Find out here:¬†https://on.bcg.com/4b98ld0\\n#GenerativeAI #WomenInTech #ArtificialIntelligence\\n\\n\\n        To view or add a comment, sign in\\n\\n\\n                3,072 followers\\n            \\nthe vital role of women in Artificial Intelligence (AI)!\\n\\uf8ffüåü Why Female Representation in AI Matters:\\n1. Diverse Perspectives\\n2. Ethical Considerations\\n3. Inclusive Design\\n4. Inspiration and Mentorship\\nDon\\'t miss this chance to connect with AI experts and innovators.\\n#WomenInAI #AIInnovation #womenempowerment #gwf23 \\n\\n                3,072 followers\\n            \\n\\uf8ffüì£ Exciting News! GLOBAL WOMEN FORUM (GWF) Welcomes New Supporter: International Group of Artificial Intelligence highlighting the crucial role of women in #ArtificialIntelligence. \\nJoin us on Nov 15th in Berlin as we empower female #AI innovators, break gender barriers, and shape ethical AI. Let\\'s drive the AI industry toward inclusivity and progress! \\n\\nBe part of the happening: https://lnkd.in/eAe4Y_KG\\nDr. Jassim Haji #WomenInAI #DiversityInTech #womeninstem #womenintechnology #womenempowerment #gwf23\\n\\n\\n        To view or add a comment, sign in\\n\\n\\n                CMO at amdocs\\n            \\nIn my corner of the universe, yes, we really Gen! \\uf8ffüí™\\nLeveling the playing field is essential for winning the game, especially for women, and especially in the tech and generative AI fields. With GenAI at the crossroads of the future, it offers immense potential for women to use the benefits and capabilities of this technology to close the gender gap. I want to encourage all women to seize this opportunity. The flip side, of course, is that inaction will actually increase the gap.\\n\\nSo, it\\'s my call to action for women everywhere: dive into the AI wave, shape it, own it. Let\\'s use AI not just to imagine a world of equality but to create it.\\n#promptyourfuture\\n\\n        To view or add a comment, sign in\\n\\n\\n                Global Leader - People & Organization Practice, Senior Partner and Managing Director at Boston Consulting Group (BCG)\\n            \\nAs we commemorate International Women‚Äôs Day, it\\'s a moment of reflection on our journey and a celebration of progress in the realm of technology and leadership. I\\'m proud to share a glimpse into @BCG‚Äôs latest report on GenAI‚Äôs integration within the tech sector highlighting promising trends in gender diversity.  \\n \\nThis report isn\\'t just numbers; it\\'s a narrative of change. It shows that women in senior tech roles are not just pioneering the adoption of GenAI, but they are setting the pace, outperforming male counterparts in GenAI adoption by 14 percentage points.\\n \\nDespite these gains, we acknowledge the persisting obstacles women continue to face. Bridging this adoption gap is not just a tech issue; it\\'s a business priority that demands a concerted effort across all levels of an organization. \\n \\nThank you to my colleagues who drove this research: @Neveen Awad, @Maria Barisano, @Adriana Dahik, @Julie Bedard, @Uche Monu, and @Gunjan Mundhra. Their dedication echoes our shared mission‚Äîto build a culture where every woman\\'s potential is realized, and their contributions are valued. \\n \\nLet\\'s commit to the advancement of women and build a more inclusive future together. \\n  \\n#InternationalWomensday #GenerativeAI #WomeninTech \\n\\n        To view or add a comment, sign in\\n\\n\\n                5 followers\\n            \\n\\uf8ffüìå \"Overcoming AI‚Äôs Stark Gender Imbalance: Time For A Fresh Approach\" \\uf8ffüåê\\n\\n\\uf8ffüë©\\uf8ffüíº Championing Women in AI: Building a Balanced Future in Technology \\uf8ffüë®\\uf8ffüíª\\n\\n\\uf8ffüí° In this insightful article, we explore the gender imbalance in the field of Artificial Intelligence (AI) and shed light on the urgent need for a fresh approach in addressing this issue.\\n\\n\\uf8ffüë©\\uf8ffüî¨ Despite the increasing popularity and impact of AI, women continue to be underrepresented in this field. This disparity not only hampers inclusivity but also limits the diversity of perspectives in developing AI solutions.\\n\\n\\uf8ffüöÄ It\\'s time to change the narrative and actively empower women to pursue AI careers. By providing mentorship programs, promoting diversity and inclusivity, and creating a supportive environment, we can bridge the gender gap and build a brighter, more balanced future in technology. \\n\\n\\uf8ffüåü Let\\'s work together to overcome AI\\'s stark gender imbalance and unlock the full potential of women in shaping the future of AI! \\uf8ffüí™\\uf8ffüèº\\uf8ffüí°\\n\\n#AI #GenderDiversity #WomenInTech #Inclusivity #Empowerment  Link:https://buff.ly/3HmUwdE\\n\\n        To view or add a comment, sign in\\n\\n\\n                2,227 followers\\n            \\n\\uf8ffüí° Dive into the weekend with our must-read, as we take a look at a recent article by The Guardian, https://t.ly/kKO8A. \\n\\nThe AI landscape is evolving rapidly, presenting incredible opportunities and challenges. \\uf8ffüå± One challenge we must actively address is the gender gap. The article addresses the lack of women in the field, while key figures like Sam Altman at OpenAI dominate the conversation. \\n\\nShare your thoughts in the comments about possible solutions to close the gender gap and generate greater opportunities for women!\\n\\n#AI #ArtificialIntelligence #DiversityInTech #WomenInAI #Innovation #TechCommunity #FutureOfWork #GenderEquality\\n\\n        To view or add a comment, sign in\\n\\n\\n                75 followers\\n            \\nAI for Women is launching a brand new website - We are now a professional networking platform for women AI enthusiasts! The objective of this website is to promote networking among like-minded women who can inspire, mentor, and help one another. \\n\\nAs a part of the pre-launch campaign, I have decided to do a deep dive into how we can achieve equality in AI for women. I will be sharing my findings over the next 3 days in the form of blog posts. \\n\\nToday\\'s article talks about \\'Gender Bias and Stereotyping\\'. You can find it here: https://lnkd.in/g3me3upH\\n\\nDo you agree with the article? Have you experienced / overcome similar challenges? Feel free to share your thoughts! \\uf8ffüñã \\n\\n#AI #GenerativeAI #WomenEmpowerment #AIforWomen #WomeninAI #WomeninTech #WomeninSTEM #DataScience\\n\\n        To view or add a comment, sign in\\n\\n\\n            49,341 followers\\n          \\n\\n                Create your free account or sign in to continue your search\\n              \\n\\n\\n\\n              or\\n            \\n\\n      By clicking Continue to join or sign in, you agree to LinkedIn‚Äôs User Agreement, Privacy Policy, and Cookie Policy.\\n    \\n\\n                New to LinkedIn? Join now\\n\\n\\n                  or\\n                \\n\\n      By clicking Continue to join or sign in, you agree to LinkedIn‚Äôs User Agreement, Privacy Policy, and Cookie Policy.\\n    \\n\\n              New to LinkedIn? Join now\\n\\n'},\n",
              " {'title': 'Sandra Rivera en LinkedIn: #intelvision #iamintel',\n",
              "  'text': '\\n                Aceptar y unirse a LinkedIn\\n              \\n\\n      Al hacer clic en ¬´Continuar¬ª para unirte o iniciar sesi√≥n, aceptas las Condiciones de uso, la Pol√≠tica de privacidad y la Pol√≠tica de cookies de LinkedIn.\\n    \\nAnother successful #intelvision event this week in Taiwan. Thanks to all the partners and customers who attended. After talking with many of you, I‚Äôm highly inspired about our future collaboration.\\n\\nIntel‚Äôs data center solutions are on the forefront of driving some of the industry‚Äôs biggest technological breakthroughs, including AI, security and sustainability.\\n\\nThrough our partnerships, we will unleash business innovations within cloud, enterprise and hybrid environments. #iamintel\\nCurrently an unaffiliated independent researcher with precision focus-centered research activity. Looking for a mutually agreed-upon faculty role in Electrical Engineering in a private university in Dhaka, Bangladesh.\\nTaiwan is integral for USA\\'s semiconductor companies\\' success.  Thank you author for this wonderful post with the participants in the events beaming with smile, so adoring. \\nCommercialize technology dreams / visions / innovations into revenue\\nCool for Taiwan. Someday it will be nice to see such investment in America‚Äôs own population.\\nHelping Your High Value Products Arrive Safely | Sr. Account Executive | Outdoor Enthusiast | Avid Coursera Student \\uf8ffü§ì\\nSandra Rivera Great to see Intel Corporation producing so many smiling faces in trying times!\\n\\nThe semi-conductor and Data Center industry is booming! #taiwan #usa #datacenters \\nSenior Manager, Sales and Business Development\\nIntel is clearly A FOLLOWER now, following AMD and Nvidia. No exception \\n\\nInicia sesi√≥n para ver o a√±adir un comentario.\\n    \\nOur goal is to be the world‚Äôs #1 FPGA provider by delivering leading-edge programmable solutions that scale - from the cloud to embedded applications - based on our customers‚Äô requirements. It‚Äôs an ambitious goal that I have full confidence we‚Äôll achieve by listening to customers, continuing to deliver value, and always be learning.\\nhttps://lnkd.in/gKuqA8iy\\n\\nInicia sesi√≥n para ver o a√±adir un comentario.\\n    \\nIce cream and volleyball. What a great afternoon at Altera\\'s San Jose campus. I continue to be inspired by the Altera technologists driving the industry‚Äôs next generation of #FPGA innovations. \\n\\nCongratulations to our winning volleyball team. Pat Gelsinger\\'s serve proved to be too much.¬†\\n\\nInicia sesi√≥n para ver o a√±adir un comentario.\\n    \\nToday is a day when we recognize and celebrate the strength and resilience of Black Americans. As we reflect on the meaning of #Juneteenth, I encourage you to commit yourself to building a more just and equitable society for everyone.\\n\\nInicia sesi√≥n para ver o a√±adir un comentario.\\n    \\nGrateful for the opportunity to recharge and connect with brilliant minds. Thank you #Altera San Jose employees. #wearealtera\\n\\nInicia sesi√≥n para ver o a√±adir un comentario.\\n    \\nI‚Äôm thrilled to join Thomas Sohmers, Thomas Catalino, and Dr. Rania Hussein for this LinkedIn Live event, where we will discuss the rapidly evolving AI market, and how the programmability of FPGAs are accelerating innovation. I hope you can join us on June 11 at 9:00 a.m. Pacific.¬†\\nhttps://lnkd.in/gCZZQKBJ\\n\\n                63.838 seguidores\\n            \\n\\uf8ffüìÖJoin us on June 11th for our LinkedIn Live event, \"Unleashing Limitless AI Possibilities with FPGAs‚Äú hosted by Bernard Marr, and hear industry leaders discuss the future of AI. \\n¬†\\nMeet Our Panelists:\\n - Sandra Rivera, CEO of Altera\\n - Thomas Catalino, VP, Critical Link\\n - Dr. Rania Hussein, Associate Teaching Professor, University Of Washington\\n - Thomas Sohmers, CEO, Positron.ai\\n¬†\\nWhat we‚Äôll be discussing:\\n- Real-world success stories: Innovative AI solutions in action\\n- FPGAi: What is it? And how will it revolutionize how innovators design AI applications?\\n- Future Trends: Insights into Altera‚Äôs technology roadmap and ecosystem collaborations.\\n\\nInicia sesi√≥n para ver o a√±adir un comentario.\\n    \\nAs part of our effort to accelerate innovation, we are expanding our high performance team with the addition of two high performing leaders. Congratulations to Premal Buch on his expanded role as Altera\\'s Head of Engineering and Jeni Barovian Panhorst on her appointment as Head of Market Development.\\n\\n#WeAreAltera #AcceleratingInnovators \\n\\n                63.838 seguidores\\n            \\nWe are delighted to announce that we have two new additions to Altera‚Äôs leadership team - Jeni Barovian Panhorst as Head of Market Development and Premal Buch as Head of Engineering. A warm welcome to the team!\\n\\n#WeAreAltera #AcceleratingInnovators #AlteraTeam\\n\\nInicia sesi√≥n para ver o a√±adir un comentario.\\n    \\nAn exciting industry first and milestone for Intel Corporation that will benefit Altera and our customers by accelerating innovation for cutting edge solutions with emerging technologies like #AI. ¬†\\n\\n\\nInicia sesi√≥n para ver o a√±adir un comentario.\\n    \\nAt Altera, we are driven by innovation and commitment to our customers. Team Malaysia embodies these principles with passion. #WeareAltera\\n\\nInicia sesi√≥n para ver o a√±adir un comentario.\\n    \\nAt Altera, we focus on providing our customers the right hardware and software solutions to solve some of their most complex problems. ¬†Our AI-infused Agilex 5 FPGA is opening up new possibilities for innovators - and it‚Äôs available now, along with software tools to help get your designs to market faster. ¬†#AcceleratingInnovators #FPGAi\\n\\n\\nInicia sesi√≥n para ver o a√±adir un comentario.\\n    \\n\\n            49.341 seguidores\\n          \\n\\n                Crea tu cuenta gratuita o inicia sesi√≥n para continuar tu b√∫squeda\\n              \\n\\n\\n\\n              o\\n            \\n\\n      Al hacer clic en ¬´Continuar¬ª para unirte o iniciar sesi√≥n, aceptas las Condiciones de uso, la Pol√≠tica de privacidad y la Pol√≠tica de cookies de LinkedIn.\\n    \\n\\n                ¬øEst√°s empezando a usar LinkedIn? √önete ahora\\n\\n\\n                  o\\n                \\n\\n      Al hacer clic en ¬´Continuar¬ª para unirte o iniciar sesi√≥n, aceptas las Condiciones de uso, la Pol√≠tica de privacidad y la Pol√≠tica de cookies de LinkedIn.\\n    \\n\\n              ¬øEst√°s empezando a usar LinkedIn? √önete ahora\\n\\n'}]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fTbWZRxK3oar"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Function to save results to text file in Google Drive\n",
        "def save_results_to_text(results, filename=file_path):\n",
        "    try:\n",
        "        with open(filename, mode='w', encoding='utf-8') as file:\n",
        "            for result in results:\n",
        "                file.write(f\"Text: {result['text']}\\n\")\n",
        "        # Check if the file was created and is not empty\n",
        "        if os.path.exists(filename) and os.path.getsize(filename) > 0:\n",
        "            print(f\"File '{filename}' created successfully.\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"File '{filename}' not created or is empty.\")\n",
        "            return False\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "U4_amMD25fBJ"
      },
      "outputs": [],
      "source": [
        "# Stores the results in results.txt file in a GDrive folder titled 'KG'\n",
        "def store_extracted_info(results):\n",
        "\n",
        "  stored_result=save_results_to_text(results)\n",
        "  folder_path = '/content/drive/My Drive/KG'\n",
        "  files = os.listdir(folder_path)\n",
        "  print(files)\n",
        "  # Commenting the following line of code because the graph has already been constructed for the demo\n",
        "  # construct_knowledge_graph()\n",
        "  run_async_function()\n",
        "  if stored_result:\n",
        "    return 200\n",
        "  else:\n",
        "    return 400"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hrJxKb9yP3xg"
      },
      "outputs": [],
      "source": [
        "# Load all the text files in the folder to construct knowledge graph\n",
        "\"\"\"\n",
        "Reads documents from the KG directory (GDrive) and creates KnowledgeGraphIndex with triplets,\n",
        "and the embeddings. The graph is stored in SimpleGraphStore\n",
        "\"\"\"\n",
        "def construct_knowledge_graph():\n",
        "  documents = SimpleDirectoryReader(\n",
        "    \"/content/drive/My Drive/KG\"\n",
        "  ).load_data()\n",
        "  llm = OpenAI(temperature=0, model=\"gpt-4\")\n",
        "  Settings.llm = llm\n",
        "  Settings.chunk_size = 512\n",
        "  graph_store = SimpleGraphStore()\n",
        "  storage_context = StorageContext.from_defaults(graph_store=graph_store)\n",
        "  # Considering embeddings\n",
        "  global new_index\n",
        "  new_index = KnowledgeGraphIndex.from_documents(\n",
        "      documents,\n",
        "      max_triplets_per_chunk=2,\n",
        "      include_embeddings=True,\n",
        "  )\n",
        "  global query_engine\n",
        "  query_engine = new_index.as_query_engine(\n",
        "      include_text=True, response_mode=\"tree_summarize\"\n",
        "    )\n",
        "  print(\"Knowledge graph constructed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "FB4Q7AZWcTnc"
      },
      "outputs": [],
      "source": [
        "# As the knowledge graph construction takes a longer time, and HTTP requests time out shortly, the knowledge graph function is called async\n",
        "import threading\n",
        "import time\n",
        "\n",
        "def run_async_function():\n",
        "    thread = threading.Thread(target=construct_knowledge_graph)\n",
        "    thread.start()\n",
        "    print(\"Sync function has been called\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFfA3fk3U4Lq"
      },
      "outputs": [],
      "source": [
        "# Do not run now  : Note: This code block is for testing if the responses are received as expected\n",
        "# Expecting a correct response for this question\n",
        "query_engine = new_index.as_query_engine(\n",
        "    include_text=False, response_mode=\"tree_summarize\"\n",
        ")\n",
        "response = query_engine.query(\n",
        "    \"What is machine learning\",\n",
        ")\n",
        "display(Markdown(f\"{response}\"))\n",
        "# No information about this query will be received as the data doesn't exist in the document\n",
        "response = query_engine.query(\n",
        "    \"What is Jyothi studying\",\n",
        ")\n",
        "display(Markdown(f\"{response}\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "CN4vAWPRu4Ci"
      },
      "outputs": [],
      "source": [
        "def fn_query_engine(question):\n",
        "  global query_engine\n",
        "  query_engine = new_index.as_query_engine(\n",
        "      include_text=False, response_mode=\"tree_summarize\"\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "EXwG5kgyAq1o"
      },
      "outputs": [],
      "source": [
        "# The chatbot accesses these APIs\n",
        "# Creating a FastAPI application\n",
        "from fastapi import FastAPI,Query\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=['*'],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=['*'],\n",
        "    allow_headers=['*'],\n",
        ")\n",
        "\n",
        "@app.get('/')\n",
        "async def root():\n",
        "    return {'hello': 'world'}\n",
        "\n",
        "# Called when the user logs in to the application and wants to talk to the chatbot\n",
        "@app.get('/answer_questions')\n",
        "async def answer_questions(question: str = Query(..., description=\"The question to be answered\")):\n",
        "    query_engine = new_index.as_query_engine(\n",
        "      include_text=False, response_mode=\"tree_summarize\"\n",
        "    )\n",
        "    response = query_engine.query(\n",
        "        question,\n",
        "    )\n",
        "    print(str(response))\n",
        "    return {'question': question, 'response': str(response)}\n",
        "\n",
        "# Get info from the user for the topic to generate a knowledge graph about\n",
        "@app.get('/generate_knowledge_graph')\n",
        "async def generate_knowledge_graph(kg_query: str = Query(..., description=\"Topic to generate the knowledge graph on\")):\n",
        "    print(\"generate knowledge graph\")\n",
        "    results = user_input_kg(kg_query)\n",
        "    print(results)\n",
        "    status = store_extracted_info(results)\n",
        "    print(status)\n",
        "    return {'question': kg_query, 'response': str(status)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOe_-kKFAtSU",
        "outputId": "75c40eea-0b37-4aef-816f-f5b453a88f2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "URL:  https://bd76-34-19-111-194.ngrok-free.app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [1500]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intel Core Ultra processors offer significant efficiency in image processing. They provide up to 5.02 times better image classification inference performance. This means they can process and classify images much faster and more accurately than other processors. This high level of performance can be particularly beneficial in fields such as artificial intelligence and machine learning, where rapid and accurate image classification is crucial.\n",
            "INFO:     73.162.97.244:0 - \"GET /answer_questions?question=can%20you%20talk%20about%20efficiency%20in%20image%20processing HTTP/1.1\" 200 OK\n",
            "The information provided does not specify the increase in power efficiency for image processing.\n",
            "INFO:     73.162.97.244:0 - \"GET /answer_questions?question=What%20is%20the%20increase%20in%20power%20efficiency%20for%20image%20processing%3F HTTP/1.1\" 200 OK\n",
            "The increase in efficiency for image processing offered by Intel core ultra processors is up to 5.02x better image classification inference performance.\n",
            "INFO:     73.162.97.244:0 - \"GET /answer_questions?question=What%20is%20the%20increase%20in%20efficiency%20for%20image%20processing%3F HTTP/1.1\" 200 OK\n"
          ]
        }
      ],
      "source": [
        "# Set up a local web server to make it accessible over the internet, the APIs will be called by the React.js application\n",
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('URL: ', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "WMSAh6Rs8ly-"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}